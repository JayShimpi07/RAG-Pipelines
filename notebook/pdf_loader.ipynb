{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "714ed2da",
      "metadata": {},
      "source": [
        "RAG Pipelines - Data Ingestion to Vector DB Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "288fce98",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Anaconda\\envs\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter  \n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b0252450",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3 PDF files to process.\n",
            "Processing file: attention.pdf\n",
            "Loaded 11 pages from attention.pdf\n",
            "Processing file: embeddings.pdf\n",
            "Loaded 83 pages from embeddings.pdf\n",
            "Processing file: object_detection.pdf\n",
            "Loaded 88 pages from object_detection.pdf\n",
            "Total documents loaded: 182\n"
          ]
        }
      ],
      "source": [
        "# Read all the PDFs inside a directory\n",
        "def process_all_pdfs(pdf_directory):\n",
        "    all_documents = []\n",
        "    pdf_dir = Path(pdf_directory)\n",
        "\n",
        "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
        "    print(f\"Found {len(pdf_files)} PDF files to process.\")\n",
        "\n",
        "    for pdf_file in pdf_files:\n",
        "        print(f\"Processing file: {pdf_file.name}\")\n",
        "        try:\n",
        "            loader = PyMuPDFLoader(str(pdf_file))\n",
        "            documents = loader.load()\n",
        "            \n",
        "            for doc in documents:\n",
        "                doc.metadata['source_file'] = pdf_file.name\n",
        "                doc.metadata['file_type'] = 'pdf'\n",
        "\n",
        "            all_documents.extend(documents)\n",
        "            print(f\"Loaded {len(documents)} pages from {pdf_file.name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {pdf_file.name}: {e}\")\n",
        "    print(f\"Total documents loaded: {len(all_documents)}\")\n",
        "    return all_documents\n",
        "\n",
        "all_pdf_documents = process_all_pdfs('../data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f657a690",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 0, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1\\nIntroduction\\nRecurrent neural networks, long short-term memory [12] and gated recurrent [7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [29, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 1, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Recurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsigniﬁcant improvements in computational efﬁciency through factorization tricks [18] and conditional\\ncomputation [26], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 16]. In all but a few cases [22], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2\\nBackground\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[20], ByteNet [15] and ConvS2S [8], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difﬁcult to learn dependencies between distant positions [11]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 22, 23, 19].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [28].\\nTo the best of our knowledge, however, the Transformer is the ﬁrst transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [14, 15] and [8].\\n3\\nModel Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 29].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\\n[9], consuming the previously generated symbols as additional input when generating the next.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1\\nEncoder and Decoder Stacks\\nEncoder:\\nThe encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position-\\n2'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 2, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Figure 1: The Transformer - model architecture.\\nwise fully connected feed-forward network. We employ a residual connection [10] around each of\\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder:\\nThe decoder is also composed of a stack of N = 6 identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3.2\\nAttention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1\\nScaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\n3'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 3, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Scaled Dot-Product Attention\\nMulti-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V ) = softmax(QKT\\n√dk\\n)V\\n(1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof\\n1\\n√dk . Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efﬁcient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by\\n1\\n√dk .\\n3.2.2\\nMulti-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneﬁcial to linearly project the queries, keys and values h times with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\noutput values. These are concatenated and once again projected, resulting in the ﬁnal values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = Pdk\\ni=1 qiki, has mean 0 and variance dk.\\n4'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 4, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='MultiHead(Q, K, V ) = Concat(head1, ..., headh)W O\\nwhere headi = Attention(QW Q\\ni , KW K\\ni , V W V\\ni )\\nWhere the projections are parameter matrices W Q\\ni\\n∈Rdmodel×dk, W K\\ni\\n∈Rdmodel×dk, W V\\ni\\n∈Rdmodel×dv\\nand W O ∈Rhdv×dmodel.\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3\\nApplications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[31, 2, 8].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation ﬂow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3\\nPosition-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0, xW1 + b1)W2 + b2\\n(2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4\\nEmbeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [24]. In the embedding layers, we multiply those weights by √dmodel.\\n3.5\\nPositional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\n5'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 5, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\\nLayer Type\\nComplexity per Layer\\nSequential\\nMaximum Path Length\\nOperations\\nSelf-Attention\\nO(n2 · d)\\nO(1)\\nO(1)\\nRecurrent\\nO(n · d2)\\nO(n)\\nO(n)\\nConvolutional\\nO(k · n · d2)\\nO(1)\\nO(logk(n))\\nSelf-Attention (restricted)\\nO(r · n · d)\\nO(1)\\nO(n/r)\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and ﬁxed [8].\\nIn this work, we use sine and cosine functions of different frequencies:\\nPE(pos,2i) = sin(pos/100002i/dmodel)\\nPE(pos,2i+1) = cos(pos/100002i/dmodel)\\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any ﬁxed offset k, PEpos+k can be represented as a linear function of\\nPEpos.\\nWe also experimented with using learned positional embeddings [8] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4\\nWhy Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [11]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\nlength n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[31] and byte-pair [25] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\\n6'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 6, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='the input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k < n does not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [15], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [6], however, decrease the complexity\\nconsiderably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side beneﬁt, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5\\nTraining\\nThis section describes the training regime for our models.\\n5.1\\nTraining Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [31]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2\\nHardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3\\nOptimizer\\nWe used the Adam optimizer [17] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate = d−0.5\\nmodel · min(step_num−0.5, step_num · warmup_steps−1.5)\\n(3)\\nThis corresponds to increasing the learning rate linearly for the ﬁrst warmup_steps training steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps = 4000.\\n5.4\\nRegularization\\nWe employ three types of regularization during training:\\nResidual Dropout\\nWe apply dropout [27] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\n7'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 7, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU\\nTraining Cost (FLOPs)\\nEN-DE\\nEN-FR\\nEN-DE\\nEN-FR\\nByteNet [15]\\n23.75\\nDeep-Att + PosUnk [32]\\n39.2\\n1.0 · 1020\\nGNMT + RL [31]\\n24.6\\n39.92\\n2.3 · 1019\\n1.4 · 1020\\nConvS2S [8]\\n25.16\\n40.46\\n9.6 · 1018\\n1.5 · 1020\\nMoE [26]\\n26.03\\n40.56\\n2.0 · 1019\\n1.2 · 1020\\nDeep-Att + PosUnk Ensemble [32]\\n40.4\\n8.0 · 1020\\nGNMT + RL Ensemble [31]\\n26.30\\n41.16\\n1.8 · 1020\\n1.1 · 1021\\nConvS2S Ensemble [8]\\n26.36\\n41.29\\n7.7 · 1019\\n1.2 · 1021\\nTransformer (base model)\\n27.3\\n38.1\\n3.3 · 1018\\nTransformer (big)\\n28.4\\n41.0\\n2.3 · 1019\\nLabel Smoothing\\nDuring training, we employed label smoothing of value ϵls = 0.1 [30]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6\\nResults\\n6.1\\nMachine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The conﬁguration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty α = 0.6 [31]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [31].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of ﬂoating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision ﬂoating-point capacity of each GPU 5.\\n6.2\\nModel Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 8, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN\\ndmodel\\ndff\\nh\\ndk\\ndv\\nPdrop\\nϵls\\ntrain\\nPPL\\nBLEU\\nparams\\nsteps\\n(dev)\\n(dev)\\n×106\\nbase\\n6\\n512\\n2048\\n8\\n64\\n64\\n0.1\\n0.1\\n100K\\n4.92\\n25.8\\n65\\n(A)\\n1\\n512\\n512\\n5.29\\n24.9\\n4\\n128\\n128\\n5.00\\n25.5\\n16\\n32\\n32\\n4.91\\n25.8\\n32\\n16\\n16\\n5.01\\n25.4\\n(B)\\n16\\n5.16\\n25.1\\n58\\n32\\n5.01\\n25.4\\n60\\n(C)\\n2\\n6.11\\n23.7\\n36\\n4\\n5.19\\n25.3\\n50\\n8\\n4.88\\n25.5\\n80\\n256\\n32\\n32\\n5.75\\n24.5\\n28\\n1024\\n128\\n128\\n4.66\\n26.0\\n168\\n1024\\n5.12\\n25.4\\n53\\n4096\\n4.75\\n26.2\\n90\\n(D)\\n0.0\\n5.77\\n24.6\\n0.2\\n4.95\\n25.5\\n0.0\\n4.67\\n25.3\\n0.2\\n5.47\\n25.7\\n(E)\\npositional embedding instead of sinusoids\\n4.92\\n25.7\\nbig\\n6\\n1024\\n4096\\n16\\n0.3\\n300K\\n4.33\\n26.4\\n213\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneﬁcial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-ﬁtting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [8], and observe nearly identical\\nresults to the base model.\\n7\\nConclusion\\nIn this work, we presented the Transformer, the ﬁrst sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efﬁciently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements\\nWe are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\n9'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 9, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='References\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[9] Alex Graves.\\nGenerating sequences with recurrent neural networks.\\narXiv preprint\\narXiv:1308.0850, 2013.\\n[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770–778, 2016.\\n[11] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient ﬂow in\\nrecurrent nets: the difﬁculty of learning long-term dependencies, 2001.\\n[12] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735–1780, 1997.\\n[13] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[14] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[15] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[16] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[17] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[18] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[19] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[20] Samy Bengio Łukasz Kaiser. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n10'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 10, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='[21] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n[22] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing, 2016.\\n[23] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[24] Oﬁr Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[25] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[26] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.\\n[27] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overﬁtting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.\\n[28] Sainbayar Sukhbaatar, arthur szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\\nInc., 2015.\\n[29] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[30] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\\n[31] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.\\n[32] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n11'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 0, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='What are embeddings\\nVicki Boykis'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 1, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Abstract\\nOver the past decade, embeddings — numerical representations of\\nmachine learning features used as input to deep learning models — have\\nbecome a foundational data structure in industrial machine learning\\nsystems. TF-IDF, PCA, and one-hot encoding have always been key tools\\nin machine learning systems as ways to compress and make sense of\\nlarge amounts of textual data. However, traditional approaches were\\nlimited in the amount of context they could reason about with increasing\\namounts of data. As the volume, velocity, and variety of data captured\\nby modern applications has exploded, creating approaches specifically\\ntailored to scale has become increasingly important.\\nGoogle’s Word2Vec paper made an important step in moving from\\nsimple statistical representations to semantic meaning of words. The\\nsubsequent rise of the Transformer architecture and transfer learning, as\\nwell as the latest surge in generative methods has enabled the growth\\nof embeddings as a foundational machine learning data structure. This\\nsurvey paper aims to provide a deep dive into what embeddings are,\\ntheir history, and usage patterns in industry.\\nColophon\\nThis paper is typeset with LATEX. The cover art is Kandinsky’s \"Circles in a\\nCircle\" , 1923. ChatGPT was used to generate some of the figures.\\nCode, LATEX, and Website\\nThe latest version of the paper and code examples are available here. The\\nwebsite for this project is here.\\nAbout the Author\\nVicki Boykis is a machine learning engineer. Her website is vickiboykis.com\\nand her semantic search side project is viberary.pizza.\\nAcknowledgements\\nI’m grateful to everyone who has graciously offered technical feedback but\\nespecially to Nicola Barbieri, Peter Baumgartner, Luca Belli, James Kirk, and\\nRavi Mody. All remaining errors, typos, and bad jokes are mine. Thank you to\\nDan for your patience, encouragement, for parenting while I was in the latent\\nspace, and for once casually asking, \"How do you generate these ’embeddings’,\\nanyway?\"\\nLicense\\nThis work is licensed under a Creative Commons\\n“Attribution-NonCommercial-ShareAlike 3.0 Un-\\nported” license.\\n2'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 2, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Contents\\n1\\nIntroduction\\n4\\n2\\nRecommendation as a business problem\\n9\\n2.1\\nBuilding a web app . . . . . . . . . . . . . . . . . . . . . . . . .\\n11\\n2.2\\nRules-based systems versus machine learning\\n. . . . . . . . .\\n13\\n2.3\\nBuilding a web app with machine learning\\n. . . . . . . . . . .\\n15\\n2.4\\nFormulating a machine learning problem . . . . . . . . . . . .\\n17\\n2.4.1\\nThe Task of Recommendations . . . . . . . . . . . . . .\\n20\\n2.4.2\\nMachine learning features . . . . . . . . . . . . . . . . .\\n22\\n2.5\\nNumerical Feature Vectors . . . . . . . . . . . . . . . . . . . . .\\n23\\n2.6\\nFrom Words to Vectors in Three Easy Pieces . . . . . . . . . . .\\n24\\n3\\nHistorical Encoding Approaches\\n25\\n3.1\\nEarly Approaches . . . . . . . . . . . . . . . . . . . . . . . . . .\\n26\\n3.2\\nEncoding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n26\\n3.2.1\\nIndicator and one-hot encoding . . . . . . . . . . . . . .\\n27\\n3.2.2\\nTF-IDF . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n31\\n3.2.3\\nSVD and PCA . . . . . . . . . . . . . . . . . . . . . . . .\\n37\\n3.3\\nLDA and LSA . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n38\\n3.4\\nLimitations of traditional approaches . . . . . . . . . . . . . . .\\n39\\n3.4.1\\nThe curse of dimensionality . . . . . . . . . . . . . . . .\\n39\\n3.4.2\\nComputational complexity\\n. . . . . . . . . . . . . . . .\\n40\\n3.5\\nSupport Vector Machines . . . . . . . . . . . . . . . . . . . . . .\\n41\\n3.6\\nWord2Vec . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n42\\n4\\nModern Embeddings Approaches\\n50\\n4.1\\nNeural Networks . . . . . . . . . . . . . . . . . . . . . . . . . .\\n51\\n4.1.1\\nNeural Network architectures . . . . . . . . . . . . . . .\\n51\\n4.2\\nTransformers . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n53\\n4.2.1\\nEncoders/Decoders and Attention . . . . . . . . . . . .\\n54\\n4.3\\nBERT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n59\\n4.4\\nGPT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n60\\n5\\nEmbeddings in Production\\n60\\n5.1\\nEmbeddings in Practice\\n. . . . . . . . . . . . . . . . . . . . . .\\n62\\n5.1.1\\nPinterest . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n62\\n5.1.2\\nYouTube and Google Play Store . . . . . . . . . . . . . .\\n63\\n5.1.3\\nTwitter . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n66\\n5.2\\nEmbeddings as an Engineering Problem . . . . . . . . . . . . .\\n69\\n5.2.1\\nEmbeddings Generation . . . . . . . . . . . . . . . . . .\\n71\\n5.2.2\\nStorage and Retrieval\\n. . . . . . . . . . . . . . . . . . .\\n72\\n5.2.3\\nDrift Detection, Versioning, and Interpretability . . . .\\n74\\n5.2.4\\nInference and Latency . . . . . . . . . . . . . . . . . . .\\n75\\n5.2.5\\nOnline and Offline Model Evaluation . . . . . . . . . .\\n76\\n5.2.6\\nWhat makes embeddings projects successful . . . . . .\\n76\\n6\\nConclusion\\n76\\n3'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 3, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nIntroduction\\nImplementing deep learning models has become an increasingly important\\nmachine learning strategy1 for companies looking to build data-driven prod-\\nucts. In order to build and power deep learning models, companies collect and\\nfeed hundreds of millions of terabytes of multimodal2 data into deep learning\\nmodels. As a result, embeddings — deep learning models’ internal represen-\\ntations of their input data — are quickly becoming a critical component of\\nbuilding machine learning systems.\\nFor example, they make up a significant part of Spotify’s item recom-\\nmender systems [27], YouTube video recommendations of what to watch [11],\\nand Pinterest’s visual search [31]. Even if they are not explicitly presented\\nto the user through recommendation system UIs, embeddings are also used\\ninternally at places like Netflix to make content decisions around which shows\\nto develop based on user preference popularity.\\nFigure 1: Left to right: Products that use embeddings used to generate recommended items:\\nSpotify Radio, YouTube Video recommendations, visual recommendations at Pinterest, BERT\\nEmbeddings in suggested Google search results\\nThe usage of embeddings to generate compressed, context-specific repre-\\nsentations of content exploded in popularity after the publication of Google’s\\nWord2Vec paper [47].\\n1Check out the machine learning industrial view Matt Turck puts together every year, which\\nhas exploded in size.\\n2Multimodal means a variety of data usually including text, video, audio, and more recently\\nas shown in Meta’s ImageBind, depth, thermal, and IMU.\\n4'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 4, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 2: Embeddings papers in arXiv by month. It’s interesting to note the decline in\\nfrequency of embeddings-specific papers, possibly in tandem with the rise of deep learning\\narchitectures like GPT source\\nBuilding and expanding on the concepts in Word2Vec, the Transformer\\n[66] architecture, with its self-attention mechanism, a much more specialized\\ncase of calculating context around a given word, has become the de-facto\\nway to learn representations of growing multimodal vocabularies, and its rise\\nin popularity both in academia and in industry has caused embeddings to\\nbecome a staple of deep learning workflows.\\nHowever, the concept of embeddings can be elusive because they’re neither\\ndata flow inputs or output results - they are intermediate elements that live\\nwithin machine learning services to refine models. So it’s helpful to define\\nthem explicitly from the beginning.\\nAs a general definition, embeddings are data that has been transformed\\ninto n-dimensional matrices for use in deep learning computations. The\\nprocess of embedding (as a verb):\\n• Transforms multimodal input into representations that are easier to\\nperform intensive computation on, in the form of vectors, tensors, or\\ngraphs [51]. For the purpose of machine learning, we can think of\\nvectors as a list (or array) of numbers.\\n• Compresses input information for use in a machine learning task — the\\ntype of methods available to us in machine learning to solve specific\\nproblems — such as summarizing a document or identifying tags or\\nlabels for social media posts or performing semantic search on a large\\ntext corpus. The process of compression changes variable feature\\ndimensions into fixed inputs, allowing them to be passed efficiently\\ninto downstream components of machine learning systems.\\n• Creates an embedding space that is specific to the data the embeddings\\nwere trained on but that, in the case of deep learning representations,\\ncan also generalize to other tasks and domains through transfer\\nlearning — the ability to switch contexts — which is one of the\\nreasons embeddings have exploded in popularity across machine\\nlearning applications\\n5'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 5, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='What do embeddings actually look like? Here is one single embedding,\\nalso called a vector, in three dimensions. We can think of this as a repre-\\nsentation of a single element in our dataset. For example, this hypothetical\\nembedding represents a single word \"fly\", in three dimensions. Generally, we\\nrepresent individual embeddings as row vectors.\\n\\x02\\n1\\n4\\n9\\n\\x03\\n(1)\\nAnd here is a tensor, also known as a matrix3, which is a multidimensional\\ncombination of vector representations of multiple elements. For example, this\\ncould be the representation of \"fly\", and \"bird.\"\\n\\x141\\n4\\n9\\n4\\n5\\n6\\n\\x15\\n(2)\\nThese embeddings are the output of the process of learning embeddings,\\nwhich we do by passing raw input data into a machine learning model. We\\ntransform that multidimensional input data by compressing it, through the\\nalgorithms we discuss in this paper, into a lower-dimensional space. The\\nresult is a set of vectors in an embedding space.\\nWord\\nSentence\\nImage\\nMultimodal data\\n[1, 4, 9]\\n[1, 4, 7]\\n[12, 0, 3]\\nEmbedding Space\\nAlgorithm\\nFigure 3: The process of embedding.\\nWe often talk about item embeddings being in X dimensions, ranging\\nanywhere from 100 to 1000, with diminishing returns in usefulness somewhere\\nbeyond 768 in the context of using them for machine learning problems4. This\\nmeans that each item (image, song, word, etc) is represented by a vector of\\nlength X, where each value is a coordinate in an X-dimensional space. For\\nmore on growing embedding context sizes, see this addendum post written in\\n2025.\\nWe just made up an embedding for \"bird\", but let’s take a look at what a\\nreal one for the word \"hold\" would look like in the quote, as generated by the\\nBERT deep learning model,\\n\"Hold fast to dreams, for if dreams die, life is a broken-winged bird that\\ncannot fly.\" — Langston Hughes\\nWe’ve highlighted this quote because we’ll be working with this sentence\\nas our input example throughout this text.\\n3The difference between a matrix and a tensor is that it’s a matrix if you’re doing linear\\nalgebra and a tensor if you’re an AI researcher.\\n4Embedding size is tunable as a hyperparameter but so far there have only been a few\\npapers on optimal embedding size, with most of the size of embeddings set through magic and\\nguesswork\\n6'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 6, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nimport torch\\n2\\nfrom transformers import BertTokenizer, BertModel\\n3\\n4\\n# Load pre-trained model tokenizer (vocabulary)\\n5\\ntokenizer = BertTokenizer.from_pretrained(\\'bert-base-uncased\\')\\n6\\n7\\ntext = \"\"\"Hold fast to dreams, for if dreams die, life is a broken-winged bird\\nthat cannot fly.\"\"\"\\n,→\\n8\\n9\\n# Tokenize the sentence with the BERT tokenizer.\\n10\\ntokenized_text = tokenizer.tokenize(text)\\n11\\n12\\n# Print out the tokens.\\n13\\nprint (tokenized_text)\\n14\\n15\\n[\\'[CLS]\\', \\'hold\\', \\'fast\\', \\'to\\', \\'dreams\\', \\',\\', \\'for\\', \\'if\\', \\'dreams\\', \\'die\\',\\n\\',\\', \\'life\\', \\'is\\', \\'a\\', \\'broken\\', \\'-\\', \\'winged\\', \\'bird\\', \\'that\\', \\'cannot\\',\\n\\'fly\\', \\'.\\', \\'[SEP]\\']\\n,→\\n,→\\n16\\n17\\n# BERT code truncated to show the final output, an embedding\\n18\\n19\\n[tensor([-3.0241e-01, -1.5066e+00, -9.6222e-01,\\n1.7986e-01, -2.7384e+00,\\n20\\n-1.6749e-01,\\n7.4106e-01,\\n1.9655e+00,\\n4.9202e-01,\\n-2.0871e+00,\\n,→\\n21\\n-5.8469e-01,\\n1.5016e+00,\\n8.2666e-01,\\n8.7033e-01,\\n8.5101e-01,\\n,→\\n22\\n5.5919e-01, -1.4336e+00,\\n2.4679e+00,\\n1.3920e+00,\\n-3.9291e-01,\\n,→\\n23\\n-1.2054e+00,\\n1.4637e+00,\\n1.9681e+00,\\n3.6572e-01,\\n3.1503e+00,\\n,→\\n24\\n-4.4693e-01, -1.1637e+00,\\n2.8804e-01, -8.3749e-01,\\n1.5026e+00,\\n,→\\n25\\n-2.1318e+00,\\n1.9633e+00, -4.5096e-01, -1.8215e+00,\\n3.2744e+00,\\n,→\\n26\\n5.2591e-01,\\n1.0686e+00,\\n3.7893e-01, -1.0792e-01,\\n5.1342e-01,\\n,→\\n27\\n-1.0443e+00,\\n1.7513e+00,\\n1.3895e-01, -6.6757e-01,\\n-4.8434e-01,\\n,→\\n28\\n-2.1621e+00, -1.5593e+01,\\n1.5249e+00,\\n1.6911e+00,\\n-1.2916e+00,\\n,→\\n29\\n1.2339e+00, -3.6064e-01, -9.6036e-01,\\n1.3226e+00,\\n1.6427e+00,\\n,→\\n30\\n1.4588e+00, -1.8806e+00,\\n6.3620e-01,\\n1.1713e+00,\\n1.1050e+00, ...\\n,→\\n31\\n2.1277e+00])\\n32\\nFigure 4: Analyzing Embeddings with BERT. See full notebook source\\nWe can see that this embedding is a PyTorch tensor object, a multidimen-\\n7'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 7, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='sional matrix containing multiple levels of embeddings, and that’s because\\nin BERT’s embedding representation, we have 13 different layers. One em-\\nbedding layer is computed for each layer of the neural network. Each level\\nrepresents a different view of our given token — or simply a sequence of\\ncharacters. We can get the final embedding by pooling several layers, details\\nwe’ll get into as we work our way up to understanding embeddings generated\\nusing BERT.\\nWhen we create an embedding for a word, sentence, or image that rep-\\nresents the artifact in the multidimensional space, we can do any number\\nof things with this embedding. For example, for tasks that focus on content\\nunderstanding in machine learning, we are often interested in comparing two\\ngiven items to see how similar they are. Projecting text as a vector allows us\\nto do so with mathematical rigor and compare words in a shared embedding\\nspace.\\nx\\ny\\nbird\\ndog\\nfly\\nFigure 5: Projecting words into a shared embedding space\\nFigure 6: Embeddings in the context of an application.\\nEngineering systems based on embeddings can be computationally ex-\\npensive to build and maintain [61]. The need to create, store, and manage\\nembeddings has also recently resulted in the explosion of an entire ecosystem\\nof related products. For example, the recent rise in the development of vector\\ndatabases to facilitate production-ready use of nearest neighbors semantic\\nqueries in machine learning systems5, and the rise of embeddings as a service6.\\nAs such, it’s important to understand their context both as end-consumers,\\nproduct management teams, and as developers who work with them. But in\\nmy deep-dive into the embeddings reference material, I found that there are\\ntwo types of resources: very deeply technical academic papers, for people who\\n5For a survey of the vector database space today, refer to this article\\n6Embeddings now are a key differentiator in pricing between on-demand ML services\\n8'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 8, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='are already NLP experts, and surface-level marketing spam blurbs for people\\nlooking to buy embeddings-based tech, and that neither of these overlap in\\nwhat they cover.\\nIn Systems Thinking, Donella Meadows writes, “You think that because\\nyou understand ’one’ that you must therefore understand ’two’ because one\\nand one make two. But you forget that you must also understand ’and.’\"\\n[45] In order to understand the current state of embedding architectures and\\nbe able to decide how to build them, we must understand how they came\\nto be. In building my own understanding, I wanted a resource that was\\ntechnical enough to be useful enough to ML practitioners, but one that also\\nput embeddings in their correct business and engineering contexts as they\\nbecome more often used in ML architecture stacks. This is, hopefully, that text.\\nIn this text, we’ll examine embeddings from three perspectives, working\\nour way from the highest level view to the most technical. We’ll start with\\nthe business context, followed by the engineering implementation, and finally\\nlook at the machine learning theory, focusing on the nuts and bolts of how\\nthey work. On a parallel axis, we’ll also travel through time, surveying the\\nearliest approaches and moving towards modern embedding approaches.\\nIn writing this text, I strove to balance the need to have precise technical\\nand mathematical definitions for concepts and my desire to stay away from\\nexplanations that make people’s eyes glaze over. I’ve defined all technical\\njargon when it appears for the first time to build context. I include code as\\na frame of reference for practitioners, but don’t go as deep as a code tutorial\\nwould7. So, it would be helpful for the reader to have some familiarity with\\nprogramming and machine learning basics, particularly after the sections that\\ndiscuss business context. But, ultimately the goal is to educate anyone who is\\nwilling to sit through this, regardless of level of technical understanding.\\nIt’s worth also mentioning what this text does not try to be: it does not try\\nto explain the latest advancements in GPT and generative models, it does not\\ntry to explain transformers in their entirety, and it does not try to cover all\\nof the exploding field of vector databases and semantic search. I’ve tried my\\nbest to keep it simple and focus on really understanding the core concept of\\nembeddings.\\n2\\nRecommendation as a business problem\\nLet’s step back and look at the larger context with a concrete example before\\ndiving into implementation details. Let’s build a social media network, Flutter,\\nthe premier social network for all things with wings. Flutter is a web and\\nmobile app where birds can post short snippets of text, videos, images, and\\nsounds, to let other birds, insects and bats in the area know what’s up. Its\\nbusiness model is based on targeted advertising, and its app architecture\\nincludes a \"home\" feed based on birds that you follow, made up of small\\npieces of multimedia content called “flits”, which can be either text, videos,\\nor photos. The home feed itself is by default in reverse chronological order\\n7In other words, I wanted to straddle the \"explanation\" and \"reference\" quadrants of the\\nDiátaxis framework\\n9'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 9, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='that is curated by the user. But we also would like to offer personalized,\\nrecommended flits so that the user finds interesting content on our platform\\nthat they might have not known about before.\\nFigure 7: Flutter’s content timeline in a social feed with a blend of organic followed content,\\nadvertising, and recommendations.\\nHow do we solve the problem of what to show in the timeline here so that\\nour users find the content relevant and interesting, and balance the needs of\\nour advertisers and business partners?\\nIn many cases, we can approach engineering solutions without involving\\nmachine learning. In fact, we should definitely start without it [76] because\\nmachine learning adds a tremendous amount of complexity to our working\\napplication [57]. In the case of the Flutter home feed, though, machine learning\\nforms a business-critical function part of the product offering. From the\\nbusiness product perspective, the objective is to offer Flutter’s users content\\nthat is relevant8, interesting, and novel so they continue to use the platform.\\nIf we do not build discovery and personalization into our content-centric\\nproduct, Flutter users will not be able to discover more content to consume\\nand will disengage from the platform.\\nThis is the case for many content-based businesses, all of which have feed-\\nlike surface areas for recommendations, including Netflix, Pinterest, Spotify,\\nand Reddit. It also covers e-commerce platforms, which must surface relevant\\n8The specific definition of a relevant item in the recommendations space varies and is under\\nintense academic and industry debate, but generally it means an item that is of interest to the\\nuser\\n10'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 10, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='items to the user, and information retrieval platforms like search engines,\\nwhich must provide relevant answers to users upon keyword queries. There\\nis a new category of hybrid applications involving question-and-answering\\nin semantic search contexts that is arising as a result of work around the GPT\\nseries of models, but for the sake of simplicity, and because that landscape\\nchanges every week, we’ll stick to understanding the fundamental underlying\\nconcepts.\\nIn subscription-based platforms9, there is clear business objective that’s\\ntied directly to the bottom line, as outlined in this 2015 paper [64] about\\nNetflix’s recsys:\\nThe main task of our recommender system at Netflix is to help\\nour members discover content that they will watch and enjoy\\nto maximize their long-term satisfaction. This is a challenging\\nproblem for many reasons, including that every person is unique,\\nhas a multitude of interests that can vary in different contexts, and\\nneeds a recommender system most when they are not sure what\\nthey want to watch. Doing this well means that each member gets\\na unique experience that allows them to get the most out of Netflix.\\nAs a monthly subscription service, member satisfaction is tightly\\ncoupled to a person’s likelihood to retain with our service, which\\ndirectly impacts our revenue.\\nKnowing this business context, and given that personalized content is\\nmore relevant and generally gets higher rates of engagement [30] than non-\\npersonalized forms of recommendation on online platforms,10 how and why\\nmight we use embeddings in machine learning workflows in Flutter to show\\nusers flits that are interesting to them personally? We need to first understand\\nhow web apps work and where embeddings fit into them.\\n2.1\\nBuilding a web app\\nMost of the apps we use today — Spotify, Gmail, Reddit, Slack, and Flutter\\n— are all designed based on the same foundational software engineering\\npatterns. They are all apps available on web and mobile clients. They all have\\na front-end where the user interacts with the various product features of the\\napplications, an API that connects the front-end to back-end elements, and a\\ndatabase that processes data and remembers state.\\n9In ad-based services, the line between retention and revenue is a bit murkier, and we have\\noften what’s known as a multi-stakeholder problem, where the actual optimized function is a\\nbalance between meeting the needs of the user and meeting the needs of the advertiser [75]. In\\nreal life, this can often result in a process of enshittification [15] of the platform that leads to\\nextremely suboptimal end-user experiences. So, when we create Flutter, we have to be very\\ncareful to balance these concerns, and we’ll also assume for the sake of simplification that\\nFlutter is a Good service that loves us as users and wants us to be happy.\\n10For more, see this case study on personalized recommendations as well as the intro section\\nof this paper which covers many personalization use-cases.\\n11'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 11, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='As an important note, features have many different definitions in machine\\nlearning and engineering. In this specific case, we mean collections of\\ncode that make up some front-end element, such as a button or a panel of\\nrecommendations. We’ll refer to these as product features, in contrast with\\nmachine learning features, which are input data into machine learning\\nmodels.\\nThis application architecture is commonly known as model-view-\\ncontroller pattern [20], or in common industry lingo, a CRUD app, named for\\nthe basic operations that its API allows to manage application state: create,\\nread, update, and delete.\\nFigure 8: Typical CRUD web app architecture\\nWhen we think of structural components in the architectures of these ap-\\nplications, we might think first in terms of product features. In an application\\nlike Slack, for example, we have the ability to post and read messages, man-\\nage notifications, and add custom emojis. Each of these can be seen as an\\napplication feature. In order to create features, we have to combine common\\nelements like databases, caches, and web services. All of this happens as\\nthe client talks to the API, which talks to the database to process data. At a\\nmore granular, program-specific level, we might think of foundational data\\nstructures like arrays or hash maps, and lower still, we might think about\\nmemory management and network topologies. These are all foundational\\nelements of modern programming.\\nAt the feature level, though, we see that it not only includes the typical\\nCRUD operations, such as the ability to post and read Slack messages, but\\nalso elements that are more than operations that alter database state. Some\\nfeatures such as personalized channel suggestions, returning relevant results\\nthrough search queries, and predicting Slack connection invites necessitates\\nthe use of machine learning.\\n12'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 12, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 9: CRUD App with Machine learning service\\n2.2\\nRules-based systems versus machine learning\\nTo understand where embeddings fit into these systems, it first makes sense to\\nunderstand where machine learning fits in at Flutter, or any given company,\\nas a whole. In a typical consumer company, the user-facing app is made up\\nof product features written in code, typically written as services or parts of\\nservices. To add a new web app feature, we write code based on a set of\\nbusiness logic requirements. This code acts on data in the app to develop our\\nnew feature.\\nIn a typical data-centric software development lifecycle, we start with the\\nbusiness logic. For example, let’s take the ability to post messages. We’d like\\nusers to be able to input text and emojis in their language of choice, have the\\nmessages sorted chronologically, and render correctly on web and mobile.\\nThese are the business requirements. We use the input data, in this case, user\\nmessages, and format them correctly and sort chronologically, at low latency,\\nin the UI.\\nFigure 10: A typical application development lifecycle\\nMachine learning-based systems are typically also services in the backend\\nof web applications. They are integrated into production workflows. But, they\\nprocess data much differently. In these systems, we don’t start with business\\nlogic. We start with input data that we use to build a model that will suggest\\nthe business logic for us. For more on the specifics of how to think about these\\ndata-centric engineering systems, see Kleppmann[35].\\nThis requires thinking about application development slightly differently,\\nand when we write an application that includes machine learning models as\\ninput, however, we’re inverting the traditional app lifecycle. What we have\\ninstead, is data plus our desired outcome. The data is combined into a model,\\nand it is this model which instead generates our business logic that builds\\nfeatures.\\nFigure 11: ML Development lifecycle\\n13'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 13, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='In short, the difference between programming and machine learning de-\\nvelopment is that we are not generating answers through business rules, but\\nbusiness rules through data. These rules are then re-incorporated into the\\napplication.\\nFigure 12: Generating answers via machine learning. The top chart shows a classical\\nprogramming approach with rules and data as inputs, while the bottom chart shows a machine\\nlearning approach with data and answers as inputs. [8]\\nAs an example, with Slack, for the channel recommendations product\\nfeature, we are not hard-coding a list of channels that need to be called from\\nthe organization’s API. We are feeding in data about the organization’s users\\n(what other channels they’ve joined, how long they’ve been users, what\\nchannels the people they’ve interacted the most with Slack in), and building a\\nmodel on that data that recommends a non-deterministic, personalized list of\\nchannels for each user that we then surface through the UI.\\n14'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 14, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 13: Traditional versus ML architecture and infra\\n2.3\\nBuilding a web app with machine learning\\nAll machine learning systems can be examined through how they accomplish\\nthese four steps. When we build models, our key questions should be, \"what\\nkind of input do we have and how is it formatted\", and \"what do we get as a\\nresult.\" We’ll be asking this for each of the approaches we look at. When we\\nbuild a machine learning system, we start by processing data and finish by\\nserving a learned model artifact.\\nThe four components of a machine learning system are11:\\n• Input data - processing data from a database or streaming from a\\nproduction application for use in modeling\\n• Feature Engineering and Selection - The process of examining the\\ndata and cleaning it to pick features. In this case, we mean features\\nas attributes of any given element that we use as inputs into machine\\nlearning. Examples of features are: user name, geographic location,\\nhow many times they’ve clicked on a button for the past 5 days, and\\nrevenue. This piece always takes the longest in any given machine\\nlearning system, and is also known as finding representations [4] of\\nthe data that best fit the machine learning algorithm. This is where,\\nin the new model architectures, we use embeddings as input.\\n• Model Building - We select the features that are important and train\\nour model, iterating on different performance metrics over and over\\nagain until we have an acceptable model we can use. Embeddings\\nare also the output of this step that we can use in other, downstream\\nsteps.\\n11There are infinitely many layers of horror in ML systems [37]. These are still the founda-\\ntional components.\\n15'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 15, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• Model Serving - Now that we have a model we like, we serve it to\\nproduction, where it hits a web service, potentially cache, and our\\nAPI where it then propagates to the front-end for the user to consume\\nas part of our web app\\nFigure 14: CRUD app with ML\\nWithin machine learning, there are many approaches we can use to fit\\ndifferent tasks. Machine learning workflows that are most effective are formu-\\nlated as solutions to both a specific business need and a machine learning task.\\nTasks can best be thought of as approaches to modeling within the categorized\\nsolution space. For example, learning a regression model is a specific case\\nof a task. Others include clustering, machine translation, anomaly detection,\\nsimilarity matching, or semantic search. The three highest-level types of ML\\ntasks are supervised, where we have training data that can tell us whether the\\nresults the model predicted are correct according to some model of the world.\\nThe second is unsupervised, where there is not a single ground-truth answer.\\nAn example here is clustering of our customer base. A clustering model can\\ndetect patterns in your data but won’t explicitly label what those patterns are.\\nThe third is reinforcement learning which is separate from these two cate-\\ngories and formulated as a game theory problem: we have an agent moving\\nthrough an environment and we’d like to understand how to optimally move\\nthem through a given environment using explore-exploit techniques. We’ll\\nfocus on supervised learning, with a look at unsupervised learning with PCA\\nand Word2Vec.\\n16'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 16, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Machine Learning\\nSupervised Machine Learning\\nSVM\\nRegression\\nNeural\\nNetworks\\nUnsupervised\\nMachine\\nLearning\\nClustering\\nDimensionality\\nReduction\\nPCA\\nReinforcement\\nLearning\\nFigure 15: Machine learning task solution space and model families\\n2.4\\nFormulating a machine learning problem\\nAs we saw in the last section, machine learning is a process that takes data\\nas input to produce rules for how we should classify something or filter it\\nor recommend it, depending on the task at hand. In any of these cases, for\\nexample, to generate a set of potential candidates, we need to construct a\\nmodel.\\nA machine learning model is a set of instructions for generating a given\\noutput from data. The instructions are learned from the features of the input\\ndata itself. For Flutter, an example of a model we’d like to build is a candidate\\ngenerator that picks flits similar to flits our birds have already liked, because\\nwe think users will like those, too. For the sake of building up the intuition\\nfor a machine learning workflow, let’s pick a super-simple example that is not\\nrelated to our business problem, linear regression, which gives us a continuous\\nvariable as output in response.\\nFor example, let’s say, given the number of posts a user has made and how\\nmany posts they’ve liked, we’d like to predict how many days they’re likely to\\ncontinue to stay on Flutter. For traditional supervised modeling approaches\\nusing tabular data, we start with our input data, or a corpus as it’s generally\\nknown in machine learning problems that deal with text in the field known as\\nNLP (natural language processing).\\nWe’re not doing NLP yet, though, so our input data may look something\\nlike this, where we have a UID (userid) and some attributes of that user, such\\nas the number of times they’ve posted and number of posts they’ve liked.\\nThese are our machine learning features.\\n17'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 17, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Table 1: Tabular Input Data for Flutter Users\\nbird_id\\nbird_posts\\nbird_likes\\n012\\n2\\n5\\n013\\n0\\n4\\n056\\n57\\n70\\n612\\n0\\n120\\nWe’ll need part of this data to train our model, part of it to test the accuracy\\nof the model we’ve trained, and part to tune meta-aspects of our model. These\\nare known as hyperparameters.\\nWe take two parts of this data as holdout data that we don’t feed into the\\nmodel. The first part, the test set, we use to validate the final model on data\\nit’s never seen before. We use the second split, called the validation set, to\\ncheck our hyperparameters during the model training phase. In the case of\\nlinear regression, there are no true hyperparameters, but we’ll need to keep in\\nmind that we will need to tune the model’s metadata for more complicated\\nmodels.\\nLet’s assume we have 100 of these values. A usual accepted split is to use\\n80% of data for training and 20% for testing. The reasoning is we want our\\nmodel to have access to as much data as possible so it learns a more accurate\\nrepresentation.\\nIn general, our goal is to feed our input into the model, through a function\\nthat we pick, and get some predicted output, f (X) →y.\\nFigure 16: How inputs map to outputs in ML functions [34]\\nFor our simple dataset, we can use the linear regression equation:\\ny = x1β1 + x2β2 + ε\\n(3)\\nThis tells us that the output, y, can be predicted by two input variables, x1\\n(bird posts) and x2 (bird likes) with their given weights, β1 and β2, plus an\\nerror term ε, or the distance between each data point and the regression line\\ngenerated by the equation. Our task is to find the smallest sum of squared\\n18'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 18, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='differences between each point and the line, in other words to minimize the\\nerror, because it will mean that, at each point, our predicted y is as close to our\\nactual y as we can get it, given the other points.\\ny = x1β1 + x2β2 + ε\\n(4)\\nThe heart of machine learning is this training phase, which is the process of\\nfinding a combination of model instructions and data that accurately represent\\nour real data, which, in supervised learning, we can validate by checking the\\ncorrect \"answers\" from the test set.\\nFigure 17: The cycle of machine learning model development\\nAs the first round of training starts, we have our data. We train — or\\nbuild — our model by initializing it with a set of inputs, X. These are from the\\ntraining data. β1 and β2 are either initialized by setting to zero or initialized\\nrandomly (depending on the model, different approaches work best), and we\\ncalculate ˆy, our predicted value for the model. ϵ is derived from the data and\\nthe estimated coefficients once we get an output.\\ny = 2β1 + 5β2 + ε\\n(5)\\nHow do we know our model is good? We initialize it with some set of\\nvalues, weights, and we iterate on those weights, usually by minimizing a cost\\nfunction. The cost function is a function that models the difference between\\nour model’s predicted value and the actual output for the training data. The\\nfirst output may not be the most optimal, so we iterate over the model space\\nmany times, optimizing for the specific metric that will make the model as\\nrepresentative of reality as possible and minimize the difference between the\\nactual and predicted values. So in our case, we compare ˆy to y. The average\\nsquared difference between an observation’s actual and predicted values is\\nthe cost, otherwise known as MSE - mean squared error.\\nMSE = 1\\nN\\nn\\n∑\\ni=1\\n(yi −(mxi + b))2\\n(6)\\nWe’d like to minimize this cost, and we do so with gradient descent. When\\nwe say that the model learns, we mean that we can learn what the correct\\ninputs into a model are through an of iterative process where we feed the\\nmodel data, evaluate the output, and to see if the predictions it generates\\n19'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 19, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='improve through the process of gradient descent. We’ll know because our loss\\nshould incrementally decrease in every training iteration.\\nWe have finally trained our model. Now, we test the model’s predictions\\non the 20 values that we’ve used as a hold-out set; i.e. the model has not seen\\nthese before and we can confidently assume that they won’t influence the\\ntraining data. We compare how many elements of the hold-out set the model\\nwas able to predict correctly to see what the model’s accuracy was.\\n2.4.1\\nThe Task of Recommendations\\nWe just saw a simple example of machine learning as it relates to predicting\\ncontinuous response variables. When our business question is, \"What would\\nbe good content to show our users,\" we are facing the machine learning task for\\nrecommendation. Recommender systems are systems set up for information\\nretrieval, a field closely related to NLP that’s focused on finding relevant in-\\nformation in large collections of documents. The goal of information retrieval\\nis to synthesize large collections of unstructured text documents. Within infor-\\nmation retrieval, there are two complementary solutions in how we can offer\\nusers the correct content in our app: search, and recommendations.\\nSearch is the problem of directed [17] information seeking, i.e. the user\\noffers the system a specific query and would like a set of refined results.\\nSearch engines at this point are a well-established traditional solution in\\nthe space.\\nRecommendation is a problem where \"man is the query.\" [58] Here,\\nwe don’t know what the person is looking for exactly, but we would like\\nto infer what they like, and recommend items based on their learned tastes\\nand preferences.\\nThe first industrial recommender systems were created to filter messages\\nin email and newsgroups [22] at the Xerox Palo Alto Research Center based\\non a growing need to filter incoming information from the web. The most\\ncommon recommender systems today are those at Netflix, YouTube, and other\\nlarge-scale platforms that need a way to surface relevant content to users.\\nThe goal of recommender systems is surface items that are relevant to the\\nuser. Within the framework of machine learning approaches for recommenda-\\ntion, the main machine learning task is to determine which items to show to a\\nuser in a given situation. [5]. There are several common ways to approach the\\nrecommendation problem.\\n• Collaborative filtering - The most common approach for creating\\nrecommendations is to formulate our data as a problem of finding\\nmissing user-item interactions in a given set of user-item interaction\\nhistory. We start by collecting either explicit (ratings) data or implicit\\nuser interaction data like clicks, pageviews, or time spent on items,\\nand compute. The simplest form of interactions are neighborhood\\nmodels, where ratings are predicted initially by finding users similar\\nto our given target user. We use similarity functions to compute the\\n20'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 20, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='closeness of users. Another common approach is using methods\\nsuch matrix factorization, the process of representing users and\\nitems in a feature matrix made up of low-dimensional factor vectors,\\nwhich in our case, are also known as embeddings, and learning those\\nfeature vectors through the process of minimizing a cost function.\\nThis process can be thought of as similar to Word2Vec [43], a deep\\nlearning model which we’ll discuss in depth in this document. There\\nare many different approaches to collaborative filtering, including\\nmatrix factorization and factorization machines.\\n• Content filtering - This approach uses metadata available about our\\nitems (for example in movies or music, the title, year released, genre,\\nand so on) as initial or additional features input into models and\\nwork well when we don’t have much information about user activ-\\nity, although they are often used in combination with collaborative\\nfiltering approaches. Many embeddings architectures fall into this\\ncategory since they help us model the textual features for our items.\\n• Learn to Rank - Learn to rank methods focus on ranking items in\\nrelation to each other based on a known set of preferred rankings\\nand the error is the number of cases when pairs or lists of items\\nare ranked incorrectly. Here, the problem is not presenting a single\\nitem, but a set of items and how they interplay. This step normally\\ntakes place after candidate generation, in a filtering step, because it’s\\ncomputationally expensive to rank extremely large lists.\\n• Neural Recommendations - The process of using neural networks to\\ncapture the same relationships that matrix factorization does without\\nexplicitly having to create a user/item matrix and based on the shape\\nof the input data. This is where deep learning networks, and recently,\\nlarge language models, come into play. Examples of deep learning\\narchitectures used for recommendation include Word2Vec and BERT,\\nwhich we’ll cover in this document, and convolutional and recurrent\\nneural networks for sequential recommendation (such as is found\\nin music playlists, for example). Deep learning allows us to better\\nmodel content-based recommendations and give us representations\\nof our items in an embedding space. [73]\\nRecommender systems have evolved their own unique architectures12,\\nand they usually include constructing a four-stage recommender system that’s\\nmade up of several machine learning models, each of which perform a differ-\\nent machine learning task.\\nFigure 18: Recommender systems as a machine learning problem\\n12For a good survey on the similarities and difference between search and recommendations,\\nread this great post on system design\\n21'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 21, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• Candidate Generation - First, we ingest data from the web app. This\\ndata goes into the initial piece, which hosts our first-pass model\\ngenerating candidate recommendations. This is where collaborative\\nfiltering takes place, and we whittle our list of potential candidates\\ndown from millions to thousands or hundreds.\\n• Ranking - Finally, we need a way to order the filtered list of recom-\\nmendations based on what we think the user will prefer the most, so\\nthe next stage is ranking, and then we serve them out in the timeline\\nor the ML product interface we’re working with.\\n• Filtering - Once we have a generated list of candidates, we want to\\ncontinue to filter them, using business logic (i.e. we don’t want to\\nsee NSFW content, or items that are not on sale, for example.). This\\nis generally a heavily heuristic-based step.\\n• Retrieval - This is the piece where the web application usually hits\\na model endpoint to get the final list of items served to the user\\nthrough the product UI.\\nDatabases have become the fundamental tool in building backend in-\\nfrastructure that performs data lookups. Embeddings have become similar\\nbuilding blocks in the creation of many modern search and recommendation\\nproduct architectures. Embeddings are a type of machine learning feature —\\nor model input data — that we use first as input into the feature engineering\\nstage, and the first set of results that come from our candidate generation\\nstage, that are then incorporated into downstream processing steps of ranking\\nand retrieval to produce the final items the user sees.\\n2.4.2\\nMachine learning features\\nNow that we have a high-level conceptual view of how machine learning and\\nrecommender systems work, let’s build towards a candidate generation model\\nthat will offer relevant flits.\\nLet’s start by modeling a traditional machine learning problem and con-\\ntrast it with our NLP problem. For example, let’s say that one of our business\\nproblems is predicting whether a bird is likely to continue to stay on Flutter or\\nto churn13 — disengage and leave the platform.\\nWhen we predict churn, we have a given set of machine learning feature\\ninputs for each user and a final binary output of 1 or 0 from the model, 1 if the\\nbird is likely to churn, or 0 if the user is likely to stay on the platform.\\nWe might have the following inputs:\\n• How many posts the bird has clicked through in the past month (we’ll\\ncall this bird_posts in our input data)\\n• The geographical location of the bird from the browser headers\\n(bird_geo)\\n• How many posts the bird has liked over the past month (bird_likes)\\n13An extremely common business problem to solve in almost every industry where either\\ncustomer population or subscription based on revenues is important\\n22'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 22, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Table 2: Tabular Input Data for Flutter Users\\nbird_id\\nbird_posts\\nbird_geo\\nbird_likes\\n012\\n2\\nUS\\n5\\n013\\n0\\nUK\\n4\\n056\\n57\\nNZ\\n70\\n612\\n0\\nUK\\n120\\nWe start by selecting our model features and arranging them in tabular\\nformat. We can formulate this data as a table (which, if we look closely, is also\\na matrix) based on rows of the bird id and our bird features.\\nTabular data is any structured data. For example, for a given Flutter user\\nwe have their user id, how many posts they’ve liked, how old the account\\nis, and so on. This approach works well for what we consider traditional\\nmachine learning approaches which deal with tabular data. As a general rule,\\nthe creation of the correct formulation of input data is perhaps the heart of\\nmachine learning. I.e. if we have bad input, we will get bad output. So in\\nall cases, we want to spend our time putting together our input dataset and\\nengineering features very carefully.\\nThese are all discrete features that we can feed into our model and learn\\nweights from, and is fairly easy as long as we have numerical features. But,\\nsomething important to note here is that, in our bird interaction data, we have\\nboth numerical and textual features (bird geography). So what do we do with\\nthese textual features? How do we compare \"US\" to \"UK\"?\\nThe process of formatting data correctly to feed into a model is called fea-\\nture engineering. When we have a single continuous, numerical feature, like\\n“the age of the flit in days”, it’s easy to feed these features into a model. But,\\nwhen we have textual data, we need to turn it into numerical representations\\nso that we can compare these representations.\\n2.5\\nNumerical Feature Vectors\\nWithin the context of working with text in machine learning, we represent\\nfeatures as numerical vectors. We can think of each row in our tabular feature\\ndata as a vector. And a collection of features, or our tabular representation,\\nis a matrix. For example, in the vector for our first user, [012, 2, \\'US\\', 5],\\nwe can see that this particular value is represented by four features. When\\nwe create vectors, we can run mathematical computations over them and use\\nthem as inputs into ML models in the numerical form we require.\\nMathematically, vectors are collections of coordinates that tell us where\\na given point is in space among many dimensions. For example, in two\\ndimensions, we have a point [2, 5], representing bird_posts and bird_likes.\\nIn three dimensions, with three features including the bird id, we would\\nhave a vector\\n\\x02\\n12\\n2\\n5\\n\\x03\\n(7)\\nwhich tells us where that user falls on all three axes.\\nBut how do we represent \"US\" or \"UK\" in this space? Because modern\\nmodels converge by performing operations on matrices [39], we need to\\n23'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 23, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='x\\ny\\nz\\n(.12, 0, 0)\\n(0, .2, 0)\\n(0, 0, .5)\\nFigure 19: Projecting a vector into the 3d space\\nencode geography as some sort of numerical value so that the model can\\ncalculate them as inputs14. So, once we have a combination of vectors, we can\\ncompare it to other points. So in our case, each row of data tells us where to\\nposition each bird in relation to any other given bird based on the combination\\nof features. And that’s really what our numerical features allow us to do.\\n2.6\\nFrom Words to Vectors in Three Easy Pieces\\nIn \"Operating Systems: Three Easy Pieces\", the authors write, \"Like any system\\nbuilt by humans, good ideas accumulated in operating systems over time,\\nas engineers learned what was important in their design.\" [3] Today’s large\\nlanguage models were likewise built on hundreds of foundational ideas over\\nthe course of decades. There are, similarly, several fundamental concepts that\\nmake up the work of transforming words to numerical representations.\\nThese show up over and over again, in every deep learning architecture\\nand every NLP-related task15:\\n• Encoding - We need to represent our non-numerical, multimodal\\ndata as numbers so we can create models out of them. There are\\nmany different ways of doing this.\\n• Vectors - we need a way to store the data we have encoded and\\nhave the ability to perform mathematical functions in an optimized\\nway on them. We store encodings as vectors, usually floating-point\\nrepresentations.\\n• Lookup matrices - Often times, the end-result we are looking for\\nfrom encoding and embedding approaches is to give some approxi-\\nmation about the shape and format of our text, and we need to be\\nable to quickly go from numerical to word representations across\\nlarge chunks of text. So we use lookup tables, also known as hash\\n14There are some models, specifically decision trees, where you don’t need to do text encoding\\nbecause the tree learns the categorical variables out of the box, however implementations differ,\\nfor example the two most popular implementations, scikit-learn and XGBoost [1], can’t.\\n15When we talk about tasks in NLP-based machine learning, we mean very specifically, what\\nthe machine learning problem is formulated to do. For example, we have the task of ranking,\\nrecommendation, translation, text summarization, and so on.\\n24'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 24, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='tables, also known as attention, to help us map between the words\\nand the numbers.\\nAs we go through the historical context of embeddings, we’ll build our\\nintuition from encoding to BERT and beyond16. What we’ll find as we go\\nfurther into the document is that the explanations for each concept get succes-\\nsively shorter, because we’ve already done the hard work of understanding\\nthe building blocks at the beginning.\\nFigure 20: Pyramid of fundamental concepts building to BERT\\n3\\nHistorical Encoding Approaches\\nCompressing content into lower dimensions for compact numerical repre-\\nsentations and calculations is not a new idea. For as long as humans have\\nbeen overwhelmed by information, we’ve been trying to synthesize it so that\\nwe can make decisions based on it. Early approaches have included one-hot\\nencoding, TF-IDF, bag-of-words, LSA, and LDA.\\nThe earlier approaches were count-based methods. They focused on count-\\ning how many times a word appeared relative to other words and generating\\nencodings based on that. LDA and LSA can be considered statistical ap-\\nproaches, but they are still concerned with inferring the properties of a dataset\\nthrough heuristics rather than modeling. Prediction-based approaches came\\nlater and instead learned the properties of a given text through models such\\nas support vector machines, Word2Vec, BERT, and the GPT series of models,\\nall of which use learned embeddings instead.\\n16Original diagram from this excellent guide on BERT\\n25'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 25, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Embedding Methods\\nCount-based Methods\\nTF-IDF\\nOne-Hot Encoding\\nBag-of-words\\nLSA\\nLDA\\nPrediction-based Methods\\nSVM\\nWord2Vec\\nBERT family\\nGPT family\\nFigure 21: Embedding Method Solution Space\\nA Note on the Code In looking at these approaches programmatically,\\nwe’ll start by using scikit-learn, the de-facto standard machine learning\\nlibrary for smaller datasets, with some implementations in native Python\\nfor clarity in understanding functionality that scikit-learn wraps. As we\\nmove into deep learning, we’ll move to PyTorch, a deep learning library\\nthat’s quickly becoming industry-standard for deep learning implemen-\\ntation. There are many different ways of implementing the concepts we\\ndiscuss here, these are just the easiest to illustrate using Python’s ML\\nlingua franca libraries.\\n3.1\\nEarly Approaches\\nThe first approaches to generating textual features were count-based, relying\\non simple counts or high-level understanding of statistical properties: they\\nwere descriptive instead of models, which are predictive and attempt to guess\\na value based on a set of input values. The first methods were encoding\\nmethods, a precursor to embedding. Encoding is often a process that still\\nhappens as the first stage of data preparation for input into more complex\\nmodeling approaches. There are several methods to create text features using\\na process known as encoding so that we can map the geography feature into\\nthe vector space:\\n• Ordinal encoding\\n• Indicator encoding\\n• One-Hot encoding\\nIn all these cases, what we are doing is creating a new feature that maps\\nto the text feature column but is a numerical representation of the variable so\\nthat we can project it into that space for modeling purposes. We’ll motivate\\nthese examples with simple code snippets from scikit-learn, the most common\\nlibrary for demonstrating basic ML concepts. We’ll start with count-based\\napproaches.\\n3.2\\nEncoding\\nOrdinal encoding Let’s again come back to our dataset of flits. We encode our\\ndata using sequential numbers. For example, \"1\" is \"finch\", \"2\" is \"bluejay\" and\\nso on. We can use this method only if the variables have a natural ordered\\nrelationship to each other. For example, in this case \"bluejay\" is not \"more\"\\n26'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 26, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='than \"finch\" and so would be incorrectly represented in our model. The case is\\nthe same, if, in our flit data, we encode \"US\" as 1 and \"UK\" as 2.\\nTable 3: Bird Geographical Location Encoding\\nbird_id\\nbird_posts\\nbird_geo\\nbird_likes\\nenc_bird_geo\\n012\\n2\\nUS\\n5\\n2\\n013\\n0\\nUK\\n4\\n1\\n056\\n57\\nNZ\\n70\\n0\\n612\\n0\\nUK\\n120\\n1\\n1\\nfrom sklearn.preprocessing import OrdinalEncoder\\n2\\n3\\ndata = [[\\'US\\'], [\\'UK\\'], [\\'NZ\\']]\\n4\\n>>> print(data)\\n5\\n[[\\'US\\']\\n6\\n[\\'UK\\']\\n7\\n[\\'NZ\\']]\\n8\\n9\\n# our label features\\n10\\nencoder = OrdinalEncoder()\\n11\\nresult = encoder.fit_transform(data)\\n12\\n>>> print(result)\\n13\\n[[2.]\\n14\\n[1.]\\n15\\n[0.]]\\nFigure 22: Ordinal Encoding in Scikit-Learn source\\n3.2.1\\nIndicator and one-hot encoding\\nIndicator encoding, given n categories (i.e. \"US\", \"UK\", and \"NZ\"), encodes\\nthe variables into n −1 categories, creating a new feature for each category.\\nSo, if we have three variables, indicator encoding encodes into two indicator\\nvariables. Why would we do this? If the categories are mutually exclusive,\\nas they usually are in point-in-time geolocation estimates, if someone is in\\nthe US, we know for sure they’re not in the UK and not in NZ, so it reduces\\ncomputational overhead.\\nIf we instead use all the variables and they are very closely correlated,\\nthere is a chance we’ll fall into something known as the indicator variable\\ntrap. We can predict one variable from the others, which means we no longer\\nhave feature independence. This generally isn’t a risk for geolocation since\\nthere are more than 2 or 3 and if you’re not in the US, it’s not guaranteed that\\nyou’re in the UK. So, if we have US = 1, UK = 2, and NZ = 3, and prefer more\\ncompact representations, we can use indicator encoding. However, many\\nmodern ML approaches don’t require linear feature independence and use L1\\nregularization17 to prune feature inputs that don’t minimize the error, and as\\n17Regularization is a way to prevent our model from overfitting. Overfitting means our\\n27'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 27, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content=\"such only use one-hot encoding.\\nOne-hot encoding is the most commonly-used of the count-based methods.\\nThis process creates a new variable for each feature that we have. Everywhere\\nthe element is present in the sentence, we place a “1” in the vector. We are\\ncreating a mapping of all the elements in the feature space, where 0 indicates a\\nnon-match and 1 indicates a match, and comparing how similar those vectors\\nare.\\n1\\nfrom sklearn.preprocessing import OneHotEncoder\\n2\\nimport numpy as np\\n3\\n4\\nenc = OneHotEncoder(handle_unknown='ignore')\\n5\\ndata = np.asarray([['US'], ['UK'], ['NZ']])\\n6\\nenc.fit(data)\\n7\\nenc.categories_\\n8\\n>>> [array(['NZ', 'UK', 'US'], dtype='<U2')]\\n9\\nonehotlabels = enc.transform(data).toarray()\\n10\\nonehotlabels\\n11\\n>>>\\n12\\narray([[0., 0., 1.],\\n13\\n[0., 1., 0.],\\n14\\n[1., 0., 0.]])\\nFigure 23: One-Hot Encoding in scikit-learnsource\\nTable 4: Our one-hot encoded data with labels\\nbird_id\\nUS\\nUK\\nNZ\\n012\\n1\\n0\\n0\\n013\\n0\\n1\\n0\\n056\\n0\\n0\\n1\\nNow that we’ve encoded our textual features as vectors, we can feed them\\ninto the model we’re developing to predict churn. The function we’ve been\\nlearning will minimize the loss of the model, or the distance between the\\nmodel’s prediction and the actual value, by predicting correct parameters for\\neach of these features. The learned model will then return a value from 1\\nto 0 that is a probability that the event, either churn or no-churn, has taken\\nplace, given the input features of our particular bird. Since this is a supervised\\nmodel, we then evaluate this model for accuracy by feeding our test data\\ninto the model and comparing the model’s prediction against the actual data,\\nwhich tells us whether the bird has churned or not.\\nWhat we’ve built is a standard logistic regression model. Generally these\\ndays the machine learning community has converged on using gradient-\\nboosted decision tree methods for dealing with tabular data, but we’ll see\\nmodel can exactly predict outcomes based on the training data, but it can’t learn new inputs\\nthat we show it, which means it can’t generalize\\n28\"),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 28, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='that neural networks build on simple linear and logistic regression models to\\ngenerate their output, so it’s a good starting point.\\nEmbeddings as larger feature inputs\\nOnce we have encoded our feature data, we can use this input for any type\\nof model that accepts tabular features. In our machine learning task, we\\nwere looking for output that indicated whether a bird was likely to leave the\\nplatform based on their location and some usage data. Now, we’d like to focus\\nspecifically on surfacing flits that are similar to other flits the user has already\\ninteracted with so we’ll need feature representations of either/or our users or\\nour content.\\nLet’s go back to the original business question we posed at the beginning\\nof this document: how do we recommend interesting new content for Flutter\\nusers given that we know that past content they consumed (i.e. liked and\\nshared)?\\nIn the traditional collaborative filtering approach to recommendations,\\nwe start by constructing a user-item matrix based on our input data that, when\\nfactored, gives us the latent properties of each flit and allows us to recommend\\nsimilar ones.\\nIn our case, we have Flutter users who might have liked a given flit. What\\nother flits would we recommend given the textual properties of that one?\\nHere’s an example. We have a flit that our bird users liked.\\n\"Hold fast to dreams, for if dreams die, life is a broken-winged bird that\\ncannot fly.\"\\nWe also have other flits we may or may not want to surface in our bird’s\\nfeed.\\n\"No bird soars too high if he soars with his own wings.\"\\n“A bird does not sing because it has an answer, it sings because it has a\\nsong.”\\nHow would we turn this into a machine learning problem that takes\\nfeatures as input and a prediction as an output, knowing what we know about\\nhow to do this already? First, in order to build this matrix, we need to turn\\neach word into a feature that’s a column value and each user remains a row\\nvalue.\\nThe best way to think of the difference between tabular and free-form\\nrepresentations as model inputs is that a row of tabular data looks like\\nthis, [012,2,\"US\", 5], and a \"row\" or document of text data looks like this,\\n[\"No bird soars too high if he soars with his own wings.\"] In both\\ncases, each of these are vectors, or a list of values that represents a single bird.\\n29'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 29, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='In traditional machine learning, rows are our user data about a single bird\\nand columns are features about the bird. In recommendation systems, our\\nrows are the individual data about each user, and our column data represents\\nthe given data about each flit. If we can factor this matrix, that is decompose it\\ninto two matrices (Q and PT) that, when multiplied, the product is our original\\nmatrix (R), we can learn the \"latent factors\" or features that allow us to group\\nsimilar users and items together to recommend them.\\nAnother way to think about this is that in traditional ML, we have to\\nactively engineer features, but they are then available to us as matrices. In\\ntext and deep-learning approaches, we don’t need to do feature engineering,\\nbut need to perform the extra step of generating valuable numeric features\\nanyway.\\n1\\n3\\n5\\n5\\n4\\n5 4\\n4\\n2 1 3\\n2 4\\n1 2\\n3\\n4 3 5\\n2 4\\n5\\n4\\n2\\n4 3 4 2\\n2 5\\n1\\n3\\n3\\n2\\n4\\nR\\nusers\\nwords\\n≈\\nusers\\nlatent factors\\nQ\\n×\\nlatent factors\\nwords\\nPT\\nThe factorization of our feature matrix into these two matrices, where the\\nrows in Q are actually embeddings [43] for users and the rows in matrix P\\nare embeddings for flits, allows us to fill in values for flits that Flutter users\\nhave not explicitly liked, and then perform a search across the matrix to find\\nother words they might be interested in. The end-result is our generated\\nrecommendation candidates, which we then filter downstream and surface to\\nthe user because the core of the recommendation problem is to recommend\\nitems to the user.\\nIn this base-case scenario, each column could be a single word in the entire\\nvocabulary of every flit we have and the vector we create, shown in the matrix\\nfrequency table, would be an insanely large, sparse vector that has a 0 of\\noccurrence of words in our vocabulary. The way we can build toward this\\nrepresentation is to start with a structure known as a bag of words, or simply\\nthe frequency of appearance of text in a given document (in our case, each flit\\nis a document.) This matrix is the input data structure for many of the early\\napproaches to embedding.\\nIn scikit-learn, we can create an initial matrix of our inputs across docu-\\nments using ‘CountVectorizer‘.\\n30'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 30, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nfrom sklearn.feature_extraction.text import CountVectorizer\\n2\\nimport pandas as pd\\n3\\n4\\nvect = CountVectorizer(binary=True)\\n5\\nvects = vect.fit_transform(flits)\\n6\\n7\\nresponses = [\"Hold fast to dreams, for if dreams die, life is a broken-winged\\nbird that cannot fly.\", \"No bird soars too high if he soars with his own\\nwings.\", \"A bird does not sing because it has an answer, it sings because\\nit has a song.\"]\\n,→\\n,→\\n,→\\n8\\n9\\ndoc = pd.DataFrame(list(zip(responses)))\\n10\\n11\\ntd = pd.DataFrame(vects.todense()).iloc[:5]\\n12\\ntd.columns = vect.get_feature_names_out()\\n13\\nterm_document_matrix = td.T\\n14\\nterm_document_matrix.columns = [\\'flit \\'+str(i) for i in range(1, 4)]\\n15\\nterm_document_matrix[\\'total_count\\'] = term_document_matrix.sum(axis=1)\\n16\\n17\\nprint(term_document_matrix.drop(columns=[\\'total_count\\']).head(10))\\n18\\n19\\nflit_1\\nflit_2\\nflit_3\\n20\\nan\\n0\\n0\\n1\\n21\\nanswer\\n0\\n0\\n1\\n22\\nbecause\\n0\\n0\\n1\\n23\\nbird\\n1\\n1\\n1\\n24\\nbroken\\n1\\n0\\n0\\n25\\ncannot\\n1\\n0\\n0\\n26\\ndie\\n1\\n0\\n0\\n27\\ndoes\\n0\\n0\\n1\\n28\\ndreams\\n1\\n0\\n0\\n29\\nfast\\n1\\n0\\n0\\n30\\n31\\nFigure 24: Creating a matrix frequency table to create a user-item matrix source\\n3.2.2\\nTF-IDF\\nOne-hot encoding just deals with presence and absence of a single term in\\na single document. However, when we have large amounts of data, we’d\\nlike to consider the weights of each term in relation to all the other terms in a\\ncollection of documents.\\nTo address the limitations of one-hot encoding, TF-IDF, or term frequency-\\ninverse document frequency was developed. TF-IDF was introduced in the\\n1970s18 as a way to create a vector representation of a document by averaging\\nall the document’s word weights. It worked really well for a long time and\\n18By Karen Spärck Jones, whose paper, \"Synonymy and semantic classification\" is fundamen-\\ntal to the field of NLP\\n31'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 31, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='still does in many cases. For example, one of the most-used search functions,\\nBM25, uses TF-IDF as a baseline [56] as a default search strategy in Elastic-\\nsearch/Opensearch 19. It extends TF-IDF to develop a probability associated\\nwith the probability of relevance for each pair of words in a document and it\\nis still being applied in neural search today [65].\\nTF-IDF will tell you how important a single word is in a corpus by assign-\\ning it a weight and, at the same time, down-weight common words like, \"a\",\\n\"and\", and \"the\". This calculated weight gives us a feature for a single word\\nTF-IDF, and also the relevance of the features across the vocabulary.\\nWe take all of our input data that’s structured in sentences and break it up\\ninto individual words, and perform counts on its values, generating the bag\\nof words. TF is term frequency, or the number of times a term appears in a\\ndocument relative to the other terms in the document.\\ntf(t, d) =\\nft,d\\n∑t′∈d ft′,d\\n(8)\\nAnd IDF is the inverse frequency of the term across all documents in our\\nvocabulary.\\nidf(t, D) = log\\nN\\n|{d ∈D : t ∈d}|\\n(9)\\nLet’s take a look at how to implement it from scratch:\\n19You can read about how Elasticsearch implements BM25 here\\n32'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 32, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\n2\\nimport math\\n3\\n4\\n# Process documents into individual words\\n5\\ndocumentA\\n= [\\'Hold\\',\\'fast\\',\\'to\\',\\'dreams\\',\\'for\\',\\'if\\',\\'dreams\\',\\'die,\\'\\n,\\'life\\',\\'is\\',\\'a\\',\\'broken-winged\\',\\'bird\\',\\'that\\',\\'cannot\\',\\'fly\\']\\n,→\\n6\\ndocumentB =\\n[\\'No\\',\\'bird\\',\\'soars\\',\\'too\\',\\'high\\',\\'if\\',\\n\\'he\\',\\'soars\\',\\'with\\',\\'his\\',\\'own\\',\\'wings\\']\\n,→\\n7\\n8\\ndef tf(doc_dict: dict, doc_elements: list[str]) -> dict:\\n9\\n\"\"\"Term frequency of a word in a document\\nover total words in\\ndocument\"\"\"\\n,→\\n10\\ntf_dict = {}\\n11\\ncorpus_count = len(doc_elements)\\n12\\nfor word, count in doc_dict.items():\\n13\\ntf_dict[word] = count / float(corpus_count)\\n14\\nreturn tf_dict\\n15\\n16\\ndef idf(doc_list: list[str]) -> dict:\\n17\\n\"\"\"The number of documents in which the term appears per term\"\"\"\\n18\\nidf_dict = {}\\n19\\nN = len(doc_list)\\n20\\nidf_dict = dict.fromkeys(doc_list[0].keys(), 0)\\n21\\nfor word, val in idf_dict.items():\\n22\\nidf_dict[word] = math.log10(N / (float(val) + 1))\\n23\\nreturn idf_dict\\n24\\n25\\n# inverse document frequencies for all words\\n26\\n# dicts are frequency counts of words per doc e.g. dict.fromkeys(corpus, 0)\\n27\\nidfs = idf([dict_a, dict_b])\\n28\\n29\\ndef tfidf(doc_elements: list[str], idfs)-> dict:\\n30\\n\"\"\"TF * IDF per word given a word and number of docs the term appears\\nin\"\"\"\\n,→\\n31\\ntfidf_dict = {}\\n32\\nfor word, val in doc_elements.items():\\n33\\ntfidf_dict[word] = val * idfs[word]\\n34\\nreturn tfidf_dict\\n35\\n36\\n# Calculate the term frequency for each document individually\\n37\\ntf_a = tf(dict_a, document_a)\\n38\\ntf_b = tf(dict_b, document_b)\\n39\\n40\\n# Calculate the inverse document frequency given each term frequency\\n41\\ntfidf_a = tfidf(tf_a, idfs)\\n42\\ntfidf_b = tfidf(tf_b, idfs)\\n43\\n44\\n# Return weight of each word in each document wrt to the total corpus\\n45\\ndocument_tfidf = pd.DataFrame([tfidf_a, tfidf_b])\\n46\\ndocument_tfidf.T\\n47\\n#\\ndoc 0\\ndoc 1\\n48\\na\\n0.018814\\n0.000000\\n49\\ndreams\\n0.037629\\n0.000000\\n50\\nNo\\n0.000000\\n0.025086\\nFigure 25: Truncated implementation of TF-IDF, see full source\\n33'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 33, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Once we understand the underlying fundamental concept, we can use the\\nscikit-learn implementation which does the same thing, and also surfaces the\\nTF-IDF of each word in the vocabulary.\\n1\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n2\\nimport pandas as pd\\n3\\n4\\ncorpus = [\\n5\\n\"Hold fast to dreams, for if dreams die, life is a broken-winged bird\\nthat cannot fly.\",\\n,→\\n6\\n\"No bird soars too high if he soars with his own wings.\",\\n7\\n]\\n8\\n9\\n# langston hughes and william blake\\n10\\ntext_titles = [\"quote_lh\", \"quote_wb\"]\\n11\\n12\\nvectorizer = TfidfVectorizer()\\n13\\nvector = vectorizer.fit_transform(corpus)\\n14\\ndict(zip(vectorizer.get_feature_names_out(), vector.toarray()[0]))\\n15\\n16\\ntfidf_df = pd.DataFrame(vector.toarray(), index=text_titles,\\ncolumns=vectorizer.get_feature_names_out())\\n,→\\n17\\n18\\ntfidf_df.loc[\\'doc_freq\\'] = (tfidf_df > 0).sum()\\n19\\ntfidf_df.T\\n20\\n21\\n# How common or unique a word is in a given document wrt to the vocabulary\\n22\\nquote_lh\\nquote_wb\\ndoc_freq\\n23\\nbird\\n0.172503\\n0.197242\\n2.0\\n24\\nbroken\\n0.242447\\n0.000000\\n1.0\\n25\\ncannot\\n0.242447\\n0.000000\\n1.0\\n26\\ndie\\n0.242447\\n0.000000\\n1.0\\nFigure 26: Implementation of TF-IDF in scikit-learn source\\nGiven that inverse document frequency is a measure of whether the word\\nis common or not across the documents, we can see that \"dreams\" is important\\nbecause they are rare across the documents and therefore interesting to us\\nmore so than \"bird.\" We see that the tf-idf for a given word, \"dreams\", is slightly\\ndifferent for each of these implementations, and that’s because Scikit-learn\\nnormalizes the denominator and uses a slightly different formula. You’ll also\\nnote that in the first implementation we separate the corpus words ourselves,\\ndon’t remove any stop words, and don’t lowercase everything. Many of these\\nsteps are done automatically in scikit-learn or can be set as parameters into\\nthe processing pipeline. We’ll see later that these are critical NLP steps that\\nwe perform each time we work with text.\\nTF-IDF enforces several important ordering rules on our text corpus:\\n• Uprank term frequency when it occurs many times in a small number of\\ndocuments\\n34'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 34, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• Downrank term frequency when it occurs many times in many docu-\\nments, aka is not relevant\\n• Really downrank the term when it appears across your entire document\\nbase [56].\\nThere are numerous ways to calculate and create weights for individual\\nwords in TF-IDF. In each case, we calculate a score for each word that tells\\nus how important that word is in relation to each other word in our corpus,\\nwhich gives it a weight. Once we figure out how common each word is in\\nthe set of all possible flits and get a weighted score for the entire sentence in\\nrelation to other sentences.\\nGenerally, when we work with textual representations, we’re trying to\\nunderstand which words, phrases, or concepts are similar to each other. Within\\nour specific recommendations task, we are trying to understand which pieces\\nof content are similar to each other, so that we can recommend content that\\nusers will like based on either their item history or the user history of users\\nsimilar to them.\\nSo, when we perform embedding in the context of recommender systems,\\nwe are looking to create neighborhoods from items and users, based on the\\nactivity of those users on our platform. This is the initial solution to the\\nproblem of “how do we recommend flits that are similar to flit that the user\\nhas liked.” This is the process of collaborative filtering.\\nThere are many approaches to collaborative filtering including a\\nneighborhood-based approach, which looks at weighted averages of user\\nratings and computes cosine similarity, between users. It then finds groups,\\nor neighborhoods of users which are similar to each other.\\nA key problem that makes up the fundamental problem in collaborative\\nfiltering and in recommendation systems in general is the ability to find similar\\nsets of items among very large collections [42].\\nMathematically, we can do this by looking at the distance metric between\\nany two given sets of items, and there are a number of different approaches,\\nincluding Euclidean distance, edit distance (more specifically, Levenshtein\\ndistance and Hamming distance), cosine distance, and more advanced com-\\npression approaches like minhashing.\\nThe most commonly used approach in most models where we’re trying\\nto ascertain the semantic closeness of two items is cosine similarity, which is\\nthe cosine of the angle between two objects represented as vectors, bounded\\nbetween -1 and 1. -1 means the two items are completely \"opposite\" of each\\nother and 1 means they are completely the same item, assuming unit length.\\nZero means that you should probably use a distance measure other than cosine\\nsimilarity because the vectors are completely orthogonal to each other. One\\npoint of clarification here is that cosine distance is the actual distance measure\\nand is calculated as 1 −similarity(⃗a,⃗b).\\nsimilarity(⃗a,⃗b) = ⃗a ·⃗b\\n|⃗a||⃗b|\\n=\\nn\\n∑\\ni=1\\naibi\\ns\\nn\\n∑\\ni=1\\na2\\ni\\ns\\nn\\n∑\\ni=1\\nb2\\ni\\n(10)\\n35'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 35, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content=\"We use cosine similarity over other measures like Euclidean distance for\\nlarge text corpuses, for example, because in very large, sparse spaces, the\\ndirection of the vectors is just as, and even more important, than the actual\\nvalues.\\nThe higher the cosine similarity is for two words or documents, the better.\\nWe can use TF-IDF as a way to look at cosine similarity. Once we’ve given\\neach of our words a tf-idf score, we can also assign a vector to each word in\\nour sentence, and create a vector out of each quote to assess how similar they\\nare.\\nx\\ny\\nbird\\nwings\\nθ\\nθ\\nϕ\\nFigure 27: Illustration of cosine similarity between bird and wings vectors.\\nLet’s take a look at the actual equation for cosine similarity. We start with\\nthe dot product between two vectors, which is just the sum of each value\\nmultiplied by the corresponding value in our second vector, and then we\\ndivide by the normalized dot product.\\n1\\nv1 = [0,3,4,5,6]\\n2\\nv2 = [4,5,6,7,8]\\n3\\n4\\ndef dot(v1, v2):\\n5\\ndot_product = sum((a * b) for a,b in zip(v1,v2))\\n6\\nreturn dot_product\\n7\\n8\\ndef cosine_similarity(v1, v2):\\n9\\n'''\\n10\\n(v1 dot v2)/||v1|| *||v2||)\\n11\\n'''\\n12\\nproducts = dot(v1,v2)\\n13\\ndenominator = ( (dot(v1,v1) **.5) * (dot(v2,v2) ** .5) )\\n14\\nsimilarity = products / denominator\\n15\\nreturn similarity\\n16\\n17\\nprint(cosine_similarity(v1, v2))\\n18\\n# 0.9544074144996451\\nFigure 28: Implementation of cosine similarity from scratch source\\nOr, once again, in scikit-learn, as a pairwise metric:\\n36\"),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 36, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nfrom sklearn.metrics import pairwise\\n2\\n3\\nv1 = [0,3,4,5,6]\\n4\\nv2 = [4,5,6,7,8]\\n5\\n6\\n# need to be in numpy data format\\n7\\npairwise.cosine_similarity([v1],[v2])\\n8\\n# array([[0.95440741]])\\n9\\nFigure 29: Implementation of cosine similarity in scikitsource\\nOther commonly-used distance measures in semantic similarity and rec-\\nommendations include:\\n• Euclidean distance - calculates the straight-line distance between two\\npoints\\n• Manhattan Distance - Measures the distance between two points by\\nsumming the absolute differences of their coordinates\\n• Jaccard Distance - Computes the dissimilarity between two sets by\\ndividing the size of their intersection by the size of their union.\\n• Hamming Distance - Measures the dissimilarity between two strings\\nby counting the positions in which they differ\\n3.2.3\\nSVD and PCA\\nThere is a problem with the vectors we created in one-hot encoding and TF-\\nIDF: they are sparse. A sparse vector is one that is mostly populated by zeroes.\\nThey are sparse because most sentences don’t contain all the same words as\\nother sentences. For example, in our flit, we might encounter the word \"bird\"\\nin two sentences simultaneously, but the rest of the words will be completely\\ndifferent.\\n1\\nsparse_vector = [1,0,0,0,0,0,0,0,0,0]\\n2\\ndense_vector = [1,2,2,3,0,4,5,8,8,5]\\nFigure 30: Two types of vectors in text processing\\nSparse vectors result in a number of problems, among these cold start—the\\nidea that we don’t know to recommend items that haven’t been interacted with,\\nor for users who are new. What we’d like, instead, is to create dense vectors,\\nwhich will give us more information about the data, the most important of\\nwhich is accounting for the weight of a given word in proportion to other\\nwords. This is where we leave one-hot encodings and TD-IDF to move into\\napproaches that are meant to solve for this sparsity. Dense vectors are just\\nvectors that have mostly non-zero values. We call these dense representations\\ndynamic representations [68].\\n37'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 37, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Several other related early approaches were used in lieu of TF-IDF for\\ncreating compact representations of items: principal components analysis\\n(PCA) and singular value decomposition (SVD).\\nSVD and PCA are both dimensionality reduction techniques that, applied\\nthrough matrix transformations to our original text input data, show us the\\nlatent relationship between two items by breaking items down into latent\\ncomponents through matrix transformations.\\nSVD is a type of matrix factorization that represents a given input feature\\nmatrix as the product of three matrices. It then uses the component matrices\\nto create linear combinations of features that are the largest differences from\\neach other and which are directionally different based on the variance of the\\nclusters of points from a given line. Those clusters represent the “feature\\nclusters” of the compressed features.\\nIn the process of performing SVD and decomposing these matrices, we\\ngenerate a matrix representation that includes the eigenvectors and eigenvalue\\npairs or the sample covariance pairs.\\nPCA uses the same initial input feature matrix, but whereas one-hot en-\\ncoding simply converts the text features into numerical features that we can\\nwork with, PCA also performs compression and projects our items into a\\ntwo-dimensional feature space. The first principal component is the scaled\\neigenvector of the data, the weights of the variables that describe your data\\nbest, and the second is the weights of the next set of variables that describe\\nyour data best.\\nThe resulting model is a projection of all the words, clustered into a single\\nspace based on these dimensions. While we can’t get individual meanings\\nof all these components, it’s clear that the clusters of words, aka features, are\\nsemantically similar, that is they are close to each other in meaning20.\\nThe difference between the two is often confusing (people admitted as\\nmuch in the 80s [21] when these approaches were still being worked out),\\nand for the purposes of this survey paper we’ll say that PCA can often be\\nimplemented using SVD 21.\\n3.3\\nLDA and LSA\\nBecause PCA performs computation on each combination of features to gen-\\nerate the two dimensions, it becomes immensely computationally expensive\\nas the number of features grows. Many of these early methods, like PCA,\\nworked well for smaller datasets, like many of the ones used in traditional\\nNLP research, but as datasets continued to grow, they didn’t quite scale.\\nOther approaches grew out of TF-IDF and PCA to address their limitations,\\nincluding latent semantic analysis (LSA) and latent Dirichlet allocation\\n(LDA) [12]. Both of these approaches start with the input document matrix\\nthat we built in the last section. The underlying principle behind both of\\n20There are many definitions of semantic similarity - what does it mean for \"king\" and\\n\"queen\" to be close to each other? - but a high-level approach involves using original sources\\nlike thesauri and dictionaries to create a structured knowledge base and offer a structured\\nrepresentation of terms and concepts based on nodes and edges, aka how often they appear\\nnear each other. [6]\\n21This is how it’s implemented in the scikit-learn package\\n38'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 38, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='these models is that words that occur close together more frequently have\\nmore important relationships. LSA uses the same word weighting that we\\nused for TF-IDF and looks to combine that matrix into a lower rank matrix,\\na cosine similarity matrix. In the matrix, the values for the cells range from\\n[-1,1], where -1 represents documents that are complete opposites and 1 means\\nthe documents are identical. LSA then runs over the matrix and groups items\\ntogether.\\nLDA takes a slightly different approach. Although it uses the same matrix\\nfor input, it instead outputs a matrix where the rows are words and columns\\nare documents. The distance measure, instead of cosine similarity, is the\\nnumerical value for the topic that the intersection of the word and document\\nprovide. The assumption is that any sentence we input will contain a collection\\nof topics, based on proportions of representation in relation to the input\\ncorpus, and that there are a number of topics that we can use to classify\\na given sentence. We initialize the algorithm by assuming that there is a\\nnon-zero probability that each word could appear in a topic. LDA initially\\nassigns words to topics at random, and then iterates until it converges to a\\npoint where it maximizes the probability for assigning a current word to a\\ncurrent topic. In order to do the word-to-topic mapping, LDA generates an\\nembedding that creates a space of clusters of words or sentences that work\\ntogether semantically.\\n3.4\\nLimitations of traditional approaches\\nAll of these traditional methods look to address the problem of generating\\nrelationships between items in our corpus in various ways in the latent space -\\nthe relationships between words that are not explicitly stated but that we can\\ntease out based on how we model the data.\\nHowever, in all these cases, as our corpus starts to grow, we start to run\\ninto two problems: the curse of dimensionality and compute scale.\\n3.4.1\\nThe curse of dimensionality\\nAs we one-hot encode more features, our tabular data set grows. Going\\nback to our churn model, what happens once we have 181 instead of two\\nor three countries? We’ll have to encode each of them into their own vector\\nrepresentations. What happens if we have millions of vocabulary words, for\\nexample thousands of birds posting millions of messages every day? Our\\nsparse matrix for tf-idf becomes computationally intensive to factor.\\nWhereas our input vectors for tabular machine learning and naive text\\napproaches is only three entries because we only use three features, multi-\\nmodal data effectively has a dimensionality of the number of written words\\nin existence and image data has a dimensionality of height times width in\\npixels, for each given image. Video and audio data have similar exponential\\nproperties. We can profile the performance of any code we write using Big\\nO notation, which will classify an algorithm’s runtime. There are programs\\nthat perform worse and those that perform better based on the number of\\nelements the program processes. This means that one-hot encodings, in terms\\nof computing performance, are O(n) in the worst case complexity. So, if our\\n39'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 39, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='text is a corpus of a million unique words, we’ll get to a million columns, or\\nvectors, each of which will be sparse, since most sentences will not contain the\\nwords of other sentences.\\nLet’s take a more concrete case. Even in our simple case of our initial\\nbird quote, we have 28 features, one for each word in the sentence, assuming\\nwe don’t remove and process the most common stop words — extremely\\ncommon words like \"the\", \"who\", and \"is\" that appear in most texts but don’t\\nadd semantic meaning. How can we create a model that has 28 features?\\nThat’s fairly simple if tedious - we encode each word as a numerical value.\\nTable 5: One-hot encoding and the growing curse of dimensionality for our flit\\nflit_id\\nbird_id\\nhold\\nfast\\ndreams\\ndie\\nlife\\nbird\\n9823420\\n012\\n1\\n1\\n1\\n1\\n1\\n1\\n9823421\\n013\\n1\\n0\\n0\\n0\\n0\\n1\\nNot only will it be hard to run computations over a linearly increasing\\nset, once we start generating a large number of features (columns), we start\\nrunning into the curse of dimensionality, which means that, the more features\\nwe accumulate, the more data we need in order to accurately statistically\\nconfidently say anything about them, which results in models that may not\\naccurately represent our data [29] if we have extremely sparse features, which\\nis generally the case in user/item interactions in recommendations.\\n3.4.2\\nComputational complexity\\nIn production machine learning systems, the statistical properties of our al-\\ngorithm are important. But just as critical is how quickly our model returns\\ndata, or the system’s efficiency. System efficiency can be measured in many\\nways, and it is critical in any well-performing system to find the performance\\nbottleneck that leads to latency, or the time spent waiting before an operation\\nis performed [26]. If you have a recommendation system in production, you\\ncannot risk showing the user an empty feed or a feed that takes more than\\na few milliseconds to render. If you have a search system, you cannot risk\\nthe results taking more than a few milliseconds to return, particularly in e-\\ncommerce settings [2]. From the holistic systems perspective then, we can also\\nhave latency in how long it takes to generate data for a model, read in data,\\nand train the model.\\nThe two big drivers of latency are:\\n• I/O processing - We can only send as many items over the network as\\nour network speed allows\\n• CPU processing - We can only process as many items as we have memory\\navailable to us in any given system22\\nGenerally, TF-IDF performs well in terms of identifying key terms in the\\ndocument. However, since the algorithm processes all the elements in a\\n22there has been discussion over the past few years on whether IO or CPU are really the\\nbottleneck in any modern data-intensive application.\\n40'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 40, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='given corpus, the time complexity grows for both the numerator and the\\ndenominator in the equation and overall, the time-complexity of computing\\nthe TF-IDF weights for all the terms in all the documents is O(Nd), where N\\nis the total number of terms in the corpus and d is the number of documents\\nin the corpus. Additionally, because TF-IDF creates a matrix as output, what\\nwe end up doing is processing enormous state matrices. For example, if you\\nhave 100k documents and need to store frequency counts and features for the\\ntop five thousand words appearing in those documents, we get a matrix of\\nsize 100000 ∗5000. This complexity only grows.\\nThis linear time complexity growth becomes an issue when we’re trying\\nto process millions or hundreds of millions of tokens – usually a synonym\\nfor words but can also be sub-words such as syllables. This is a problem that\\nbecame especially prevalent as, over time in industry, storage became cheap.\\nFrom newsgroups to emails, and finally, to public internet text, we began\\nto generate a lot of digital exhaust and companies collected it in the form of\\nappend-only logs [36], a sequence of records ordered by time, that’s configured\\nto continuously append records.23 .\\nCompanies started emitting, keeping, and using these endless log streams\\nfor data analysis and machine learning. All of a sudden, the algorithms that\\nhad worked well on a collection of less than a million documents struggled to\\nkeep up.\\nCapturing log data at scale began the rise of the Big Data era, which\\nresulted in a great deal of variety, velocity, and volume of data movement.\\nThe rise in data volumes coincided with data storage becoming much cheaper,\\nenabling companies to store everything they collected on racks of commodity\\nhardware.\\nCompanies were already retaining analytical data needed to run critical\\nbusiness operations in relational databases, but access to that data was struc-\\ntured and processed in batch increments on a daily or weekly basis. This new\\nlogfile data moved quickly, and with a level of variety absent from traditional\\ndatabases.\\nThe resulting corpuses for NLP, search, and recommendation problems\\nalso exploded in size, leading people to look for more performant solutions.\\n3.5\\nSupport Vector Machines\\nThe first modeling approaches were shallow models — models that perform\\nmachine learning tasks using only one layer of weights and biases [9]. Support\\nvector machines (SVM), developed at Bell Laboratories in the mid-1990s,\\nwere used in high-dimensional spaces for NLP tasks like text categorization\\n[32]. SVMs separate data clusters into points that are linearly separable by a\\nhyperplane, a decision boundary that separates elements into separate classes.\\nIn a two-dimensional vector space, the hyperplane is a line, in a three or more\\ndimensional space, the separator also comes in many dimensions.\\nThe goal of the SVM is to find the optimal hyperplane such that the dis-\\ntance between new projections of objects (words in our case) into the space\\n23Jay Kreps’ canonical posts on how logging works are a must-read\\n41'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 41, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='maximizes the distance between the plane and the elements so there’s less\\nchance of mis-classifying them.\\nw · x + b > 1\\nw · x + b = 0\\nw · x + b < −1\\nMargin\\nFigure 31: Example of points in the vector space in an SVM separated by a hyperplane\\nExamples of supervised machine learning tasks performed with SVMs\\nincluded next word prediction, predicting the missing word in a given se-\\nquence, and predicting words that occur in a window. As an example, the\\nclassical word embedding inference task is autocorrect when we’re typing on\\nour phones. We type a word, and it’s the job of the autocorrect to predict the\\ncorrect word based on both the word itself and the surrounding context in the\\nsentence. It therefore needs to learn a vocabulary of embeddings that will give\\nit probabilities that it is selecting the correct word.\\nHowever, as in other cases, when we reach high dimensions, SVMs com-\\npletely fail to work with sparse data because they rely on computing distances\\nbetween points to determine the decision boundaries. Because in our sparse\\nvector representations of elements most of the distances are zero, the hyper-\\nplane will fail to cleanly separate the boundaries and classify words incorrectly.\\n3.6\\nWord2Vec\\nTo get around the limitations of earlier textual approaches and keep up with\\ngrowing size of text corpuses, in 2013, researchers at Google came up with an\\nelegant solution to this problem using neural networks, called Word2Vec [47].\\nSo far, we’ve moved from simple heuristics like one-hot encoding, to\\nmachine learning approaches like LSA and LDA that look to learn a dataset’s\\nmodeled features. Previously, like our original one-hot encodings, all the\\napproaches to embedding focused on generating sparse vectors that can give\\nan indication that two words are related, but not that there is a semantic\\nrelationship between them. For example, “The dog chased the cat” and “the\\ncat chased the dog” would have the same distance in the vector space, even\\nthough they’re two completely different sentences.\\nWord2Vec is a family of models that has several implementations, each\\nof which focus on transforming the entire input dataset into vector represen-\\n42'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 42, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='tations and, more importantly, focusing not only on the inherent labels of\\nindividual words, but on the relationship between those representations.\\nThere are two modeling approaches to Word2Vec - continuous bag of\\nwords (CBOW) and skipgrams, both of which generate dense vectors of\\nembeddings but model the problem slightly differently. The end-goal of the\\nWord2Vec model in either case is to learn the parameters that maximize that\\nprobability of a given word or group of words being an accurate prediction\\n[23].\\nIn training skipgrams, we take a word from the initial input corpus and\\npredict the probability that a given set of words surround it. In the case of\\nour initial flit quote, \"Hold fast to dreams for if dreams die, life is a broken-\\nwinged bird that cannot fly\", the model’s intermediate steps generate a set of\\nembeddings that’s the distance between all the words in the dataset and fill\\nin the next several probabilities for the entire phrase, using the word \"fast\" as\\ninput.\\nFigure 32: Word2Vec Architecture\\nIn training CBOW, we do the opposite: we remove a word from the middle\\nof a phrase known as the context window and train a model to predict the\\nprobability that a given word fills the blank, shown in the equation below\\nwhere we attempt to maximize.\\narg max\\nθ\\n∏\\nw∈Text\\n\"\\n∏\\nc∈C(w)\\np(c|w; θ)\\n#\\n(11)\\nIf we optimize these parameters - theta - and maximize the probability that\\n43'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 43, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='the word belongs in the sentences, we’ll learn good embeddings for our input\\ncorpus.\\nLet’s focus on a detailed implementation of CBOW to better understand\\nhow this works. This time, for the code portion, we’ll move on from scikit-\\nlearn, which works great for smaller data, to PyTorch for neural net operations.\\nAt a high level, we have a list of input words that are processed through a\\nsecond layer, the embedding layer, and then through the output layer, which\\nis just a linear model that returns probabilities.\\nWord #1\\nWord #2\\nWord #3\\nWord #4\\nOutput Probability\\nEmbeddings\\nInput\\nCorpus\\nLinear\\nRegression\\nFigure 33: Word2Vec CBOW Neural Network architecture\\nWe’ll run this implementation in PyTorch, the popular library for building\\nneural network models. The best way to implement Word2Vec, especially if\\nyou’re dealing with smaller datasets, is using Gensim, but Gensim abstracts\\naway the layers into inner classes, which makes for a fantastic user experi-\\nence. But, since we’re just learning about them, we’d like to see a bit more\\nexplicitly how they work, and PyTorch, although it does not have a native\\nimplementation of Word2Vec, lets us see the inner workings a bit more clearly.\\nTo model our problem in PyTorch, we’ll use the same approach as with\\nany problem in machine learning:\\n• Inspect and clean our input data.\\n• Build the layers of our model. (For traditional ML, we’ll have only\\none)\\n• Feed the input data into the model and track the loss curve\\n• Retrieve the trained model artifact and use it to make predictions on\\nnew items that we analyze\\n44'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 44, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 34: Steps for creating Word2Vec model\\nLet’s start from our input data. In this case, our corpus is all of the flits\\nwe’ve collected. We first need to process them as input into our model.\\n1\\nresponses = [\"Hold fast to dreams, for if dreams die, life is a broken-winged\\nbird that cannot fly.\", \"No bird soars too high if he soars with his own\\nwings.\", \"A bird does not sing because it has an answer, it sings because\\nit has a song.\"]\\n,→\\n,→\\n,→\\nFigure 35: Our Word2Vec input dataset\\nLet’s start with our input training data, which is our list of flits. To prepare\\ninput data for PyTorch, we can use the DataLoader or Vocab classes, which\\nsplits our text into tokens and tokenizes — or creates smaller, word-level\\nrepresentations of each sentence — for processing. For each line in the file, we\\ngenerate tokens by splitting each line into single words, removing whitespace\\nand punctuation, and lowercasing each individual word.\\nThis kind of processing pipeline is extremely common in NLP and spend-\\ning time to get this step right is extremely critical so that we get clean, correct\\ninput data. It typically includes [48]:\\n• Tokenization - transforming a sentence or a word into its component\\ncharacter by splitting it\\n• Removing noise - Including URLs, punctuation, and anything else in\\nthe text that is not relevant to the task at hand\\n• Word segmentation - Splitting our sentences into individual words\\n• Correcting spelling mistakes\\n45'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 45, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nclass TextPreProcessor:\\n2\\ndef __init__(self) -> None:\\n3\\nself.input_file = input_file\\n4\\n5\\ndef generate_tokens(self):\\n6\\nwith open(self.input_file, encoding=\"utf-8\") as f:\\n7\\nfor line in f:\\n8\\nline = line.replace(\"\\\\\\\\\", \"\")\\n9\\nyield line.strip().split()\\n10\\n11\\ndef build_vocab(self) -> Vocab:\\n12\\nvocab = build_vocab_from_iterator(\\n13\\nself.generate_tokens(), specials=[\"<unk>\"], min_freq=100\\n14\\n)\\n15\\nreturn vocab\\nFigure 36: Processing our input vocabulary and building a Vocabulary object from our\\ndataset in PyTorch\\nNow that we have an input vocabulary object we can work with, the next\\nstep is to create one-hot encodings of each word to a numerical position, and\\neach position back to a word, so that we can easily reference both our words\\nand vectors. The goal is to be able to map back and forth when we do lookups\\nand retrieval.\\nThis occurs in the Embedding layer. Within the Embedding layer of Py-\\nTorch, we initialize an Embedding matrix based on the size we specify and\\nsize of our vocabulary, and the layer indexes the vocabulary into a dictionary\\nfor retrieval. The embedding layer is a lookup table24 that matches a word to\\nthe corresponding word vector on an index by index basis. Initially, we create\\nour one-hot encoded word to term dictionary. Then, we create a mapping of\\neach word to a dictionary entry and a dictionary entry to each word. This\\nis known as bijection. In this way, the Embedding layer is like a one-hot\\nencoded matrix, and allows us to perform lookups. The lookup values in this\\nlayer are initialized to a set of random weights, which we next pass onto the\\nlinear layer.\\nEmbeddings resemble hash maps and also have their performance char-\\nacteristics (O(1) retrieval and insert time), which is why they can scale easily\\nwhen other approaches cannot. In the embedding layer, Word2Vec where each\\nvalue in the vector represents the word on a specific dimension, and more\\nimportantly, unlike many of the other methods, the value of each vector is in\\ndirect relationship to the other words in the input dataset.\\n24Embedding Layer PyTorch documents\\n46'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 46, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nclass CBOW(torch.nn.Module):\\n2\\ndef __init__(self):\\n# we pass in vocab_size and embedding_dim as hyperparams\\n3\\nsuper(CBOW, self).__init__()\\n4\\nself.num_epochs = 3\\n5\\nself.context_size = 2\\n# 2 words to the left, 2 words to the right\\n6\\nself.embedding_dim = 100\\n# Size of your embedding vector\\n7\\nself.learning_rate = 0.001\\n8\\nself.device = torch.device(\\'cuda\\' if torch.cuda.is_available() else \\'cpu\\')\\n9\\n10\\nself.vocab = TextPreProcessor().build_vocab()\\n11\\nself.word_to_ix = self.vocab.get_stoi()\\n12\\nself.ix_to_word = self.vocab.get_itos()\\n13\\nself.vocab_list = list(self.vocab.get_stoi().keys())\\n14\\nself.vocab_size = len(self.vocab)\\n15\\n16\\nself.model = None\\n17\\n18\\n# out: 1 x embedding_dim\\n19\\nself.embeddings = nn.Embedding(\\n20\\nself.vocab_size, self.embedding_dim\\n21\\n)\\n# initialize an Embedding matrix based on our inputs\\n22\\nself.linear1 = nn.Linear(self.embedding_dim, 128)\\n23\\nself.activation_function1 = nn.ReLU()\\n24\\n25\\n# out: 1 x vocab_size\\n26\\nself.linear2 = nn.Linear(128, self.vocab_size)\\n27\\nself.activation_function2 = nn.LogSoftmax(dim=-1)\\nFigure 37: Word2Vec CBOW implementation in Pytorch. source\\nOnce we have our lookup values, we can process all our words. For CBOW,\\nwe take a single word and we pick a sliding window, in our case, two words\\nbefore, and two words after, and try to infer what the actual word is. This is\\ncalled the context vector, and in other cases, we’ll see that it’s called attention.\\nFor example, if we have the phrase \"No bird [blank] too high\", we’re trying to\\npredict that the answer is \"soars\" with a given softmax probability, aka ranked\\nagainst other words. Once we have the context vector, we look at the loss —\\nthe difference between the true word and the predicted word as ranked by\\nprobability — and then we continue.\\nThe way we train this model is through context windows. For each given\\nword in the model, we create a sliding window that includes that word and 2\\nwords before it, and 2 words after it.\\nWe activate the linear layer with a ReLu activation function, which decides\\nwhether a given weight is important or not. In this case, ReLu squashes all the\\nnegative values we initialize our embeddings layer with down to zero since\\nwe can’t have inverse word relationships, and we perform linear regression\\nby learning the weights of the model of the relationship of the words. Then,\\nfor each batch we examine the loss, the difference between the real word and\\nthe word that we predicted should be there given the context window - and\\n47'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 47, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='we minimize it.\\nAt the end of each epoch, or pass through the model, we pass the weights,\\nor backpropagate them, back to the linear layer, and then again, update the\\nweights of each word, based on the probability. The probability is calculated\\nthrough a softmax function, which converts a vector of real numbers into a\\nprobability distribution - that is, each number in the vector, i.e. the value of the\\nprobability of each words, is in the interval between 0 and 1 and all of the word\\nnumbers add up to one. The distance, as backpropagated to the embeddings\\ntable, should converge or shrink depending on the model understanding how\\nclose specific words are.\\n48'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 48, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\n2\\ndef make_context_vector(self, context, word_to_ix) -> torch.LongTensor:\\n3\\n\"\"\"\\n4\\nFor each word in the vocab, find sliding windows of [-2,1,0,1,2] indexes\\n5\\nrelative to the position of the word\\n6\\n:param vocab: list of words in the vocab\\n7\\n:return: torch.LongTensor\\n8\\n\"\"\"\\n9\\nidxs = [word_to_ix[w] for w in context]\\n10\\ntensor = torch.LongTensor(idxs)\\n11\\n12\\n13\\ndef train_model(self):\\n14\\n15\\n# Loss and optimizer\\n16\\nself.model = CBOW().to(self.device)\\n17\\noptimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\\n18\\nloss_function = nn.NLLLoss()\\n19\\n20\\nlogging.warning(\\'Building training data\\')\\n21\\ndata = self.build_training_data()\\n22\\n23\\nlogging.warning(\\'Starting forward pass\\')\\n24\\nfor epoch in tqdm(range(self.num_epochs)):\\n25\\n# we start tracking how accurate our initial words are\\n26\\ntotal_loss = 0\\n27\\n28\\n# for the x, y in the training data:\\n29\\nfor context, target in data:\\n30\\ncontext_vector = self.make_context_vector(context, self.word_to_ix)\\n31\\n32\\n# we look at loss\\n33\\nlog_probs = self.model(context_vector)\\n34\\n35\\n# compare loss\\n36\\ntotal_loss += loss_function(\\n37\\nlog_probs, torch.tensor([self.word_to_ix[target]])\\n38\\n)\\n39\\n40\\n# optimize at the end of each epoch\\n41\\noptimizer.zero_grad()\\n42\\ntotal_loss.backward()\\n43\\noptimizer.step()\\n44\\n45\\n# Log out some metrics to see if loss decreases\\n46\\nlogging.warning(\"end of epoch {} | loss {:2.3f}\".format(epoch, total_loss))\\n47\\n48\\ntorch.save(self.model.state_dict(), self.model_path)\\n49\\nlogging.warning(f\\'Save model to {self.model_path}\\')\\nFigure 38: W\\nord2Vec CBOW implementation in PyTorch\\nsee full implementation here\\n49'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 49, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Once we’ve completed our iteration through our training set, we have\\nlearned a model that retrieves both the probability of a given word being the\\ncorrect word, and the entire embedding space for our vocabulary.\\n4\\nModern Embeddings Approaches\\nWord2Vec became one of the first neural network architectures to use the con-\\ncept of embedding to create a fixed feature vocabulary. But neural networks\\nas a whole were gaining popularity for natural language modeling because\\nof several key factors. First, in the 1980s, researchers made advancements in\\nusing the technique of backpropagation for training neural networks learning\\n[53]. Backpropagation is how a model learns to converge by calculating the\\ngradient of the loss function with respect to the weights of the neural network,\\nusing the chain rule, a concept from calculus which allows us to calculate\\nthe derivative of a function made up of multiple functions. This mechanism\\nallows the model to understand when it’s reached a global minimum for loss\\nand picks the correct weights for the model parameters, but training models\\nthrough gradient descent. Earlier approaches, such as the perceptron learning\\nrule, tried to do this, but had limitations, such as being able to work only\\non simple layer architectures, took a long time to converge, and experienced\\nvanishing gradients, which made it hard to effectively update the model’s\\nweights.\\nThese advances gave rise to the first kinds of multi-level neural networks,\\nfeed-forward neural networks. In 1998, a paper used backpropagation over\\nmultilayer perceptrons to correctly perform the task of recognizing handwrit-\\nten digit images [40], demonstrating a practical use-case practitioners and\\nresearchers could apply. This MNIST dataset is now one of the canonical\\n\"Hello World\" examples of deep learning.\\nSecond, in the 2000s, the rise of petabytes of aggregated log data resulted\\nin the creation of large databases of multimodal input data scraped from the\\ninternet. This made it possible to conduct wide-ranging experiments to prove\\nthat neural networks work on large amounts of data. For example, ImageNet\\nwas developed by researchers at Stanford who wanted to focus on improving\\nmodel performance by creating a gold set of neural network input data, the\\nfirst step in processing. FeiFei Li assembled a team of students and paid\\ngig workers from Amazon Turk to correctly label a set of 3.2 million images\\nscraped from the internet and organized based on categories according to\\nWordNet, a taxonomy put together by researchers in the 1970s [55].\\nResearchers saw the power of using standard datasets. In 2015, Alex\\nKrizhevsky, in collaboration with Ilya Sutskever, who now works at OpenAI\\nas one of the leading researchers behind the GPT series of models that form the\\nbasis of the current generative AI wave, submitted an entry to the ImageNet\\ncompetition called AlexNet. This model was a convolutional neural network\\nthat outperformed many other methods. There were two things that were\\nsignificant about AlexNet. The first was that it had eight stacked layers of\\nweights and biases, which was unusual at the time. Today, 12-layer neural.\\nnetworks like BERT and other transformers are completely normal, but at the\\ntime, more than two layers was revolutionary. The second was that it ran on\\n50'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 50, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='GPUs, a new architectural concept at the time, since GPUs were used mostly\\nfor gaming.\\nNeural networks started to become popular as ways to generate represen-\\ntations of vocabularies. In particular, neural network architectures, such as\\nand recurrent neural networks (RNNs) and later long short-term memory\\nnetworks (LSTMs) also emerged as ways to deal with textual data for all kinds\\nof machine learning tasks from NLP to computer vision.\\n4.1\\nNeural Networks\\nNeural networks are extensions on traditional machine learning models, but\\nthey have a few critical special properties. Let’s think back to our definition\\nof a model when we formalized a machine learning problem. A model is a\\nfunction with a set of learnable input parameters that takes some set of inputs\\nand one set of tabular input features, and gives us an output. In traditional\\nmachine learning approaches, there is one set, or layer, of learnable parameters\\nand one model. If our data doesn’t have complex interactions, our model can\\nlearn the feature space fairly easily and make accurate predictions.\\nHowever, when we start dealing with extremely large, implicit feature\\nspaces, such as are present in text, audio, or video, we will not be able to derive\\nspecific features that wouldn’t be obvious if we were manually creating them.\\nA neural network, by stacking neurons, each of which represent some aspect\\nof the model, can tease out these latent representations. Neural networks\\nare extremely good at learning representations of data, with each level of the\\nnetwork transforming a learned representation of the level to a higher level\\nuntil we get a clear picture of our data [41].\\n4.1.1\\nNeural Network architectures\\nWe’ve already encountered our first neural network, Word2Vec, which seeks to\\nunderstand relationships between words in our text that the words themselves\\nwould not tell us. Within the neural network space, there are several popular\\narchitectures:\\n• Feed-forward networks that extract meaning from fixed-length in-\\nputs. Results of these model are not fed back into the model for\\niteration\\n• Convolutional neural nets (CNNs) - used mainly for image process-\\ning, which involves a convolutional layer made up of a filter that\\nmoves across an image to check for feature representations which\\nare then multiplied via dot product with the filter to pull out specific\\nfeatures\\n• recurrent neural networks, which take a sequence of items and\\nproduce a vector that summarizes the sentence\\nRNNs and CNNs are used mainly in feature extraction - they generally\\ndo not represent the entire modeling flow, but are fed later into feed-forward\\nmodels that do the final work of classification, summarization, and more.\\n51'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 51, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Neural Networks\\nFeedforward\\nSingle-layer\\nMulti-layer\\nRecurrent\\nElman\\nJordan\\nLSTM\\nGRU\\nConvolutional\\nAutoencoder\\nVanilla\\nVariational\\nGenerative Adversarial\\nRadial Basis Function\\nFigure 39: Types of Neural Networks\\nNeural networks are complex to build and manage for a number of reasons.\\nFirst, they require extremely large corpuses of clean, well-labeled data to\\nbe optimized. They also require special GPU architectures for processing,\\nand, as we’ll see in the production section, they have their own metadata\\nmanagement and latency considerations. Finally, within the network itself,\\nwe need to complete a large amount of passes we need to do over the model\\nobject using batches of our training data to get it to converge. The number of\\nfeature matrices that we need to run calculations over25, and, consequently,\\nthe amount of data we have to keep in-memory through the lifecycle of the\\nmodel ends up accumulating and requires a great deal of performance tuning.\\nThese features made developing and running neural networks pro-\\nhibitively expensive until the last fifteen years or so. First, the exponential\\nincrease in storage space provided by the growing size of commodity hard-\\nware both on-prem and in the cloud meant that we could now store that data\\nfor computation, and the explosion of log data gave companies such as Google\\na lot of training data to work with. Second, the rise of the GPU as a tool that\\ntakes advantage of the neural network’s ability to perform embarrassingly\\nparallel computation — a characteristic of computation when it’s easy to sepa-\\nrate steps out into ones that can be performed in parallel, such as word count\\nfor example. In a neural network, we can generally parallelize computation in\\nany given number of ways, including at the level of a single neuron.\\n25There is no good single resource for calculating the computational complexity of a neural\\nnetwork given that there are many wide-ranging architectures but this post does a good job\\nlaying out the case that it’s essentially O(n5)\\n52'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 52, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='While GPUs were initially used for working with computer graphics, in the\\nearly 2000s [49], researchers discovered the potential to use them for general\\ncomputation, and Nvidia made an enormous bet on this kind of computing by\\nintroducing CUDA, an API layer on top of GPUs. This in turn allowed for the\\ncreation and development of high-level popular deep learning frameworks\\nlike PyTorch and Tensorflow.\\nNeural networks could now be trained and experimented with at scale. To\\ncome back to a comparison to our previous approaches, when we calculate TF-\\nIDF, we need to loop over each individual word and perform our computations\\nover the entire dataset in sequence to arrive at a score in proportion to all other\\nwords, which means that our computational complexity will be O(ND) [10].\\nHowever, with a neural network, we can either distribute the model train-\\ning across different GPUs in a process known as model parallelism, or com-\\npute batches — the size of the training data fed into the model and used in a\\ntraining loop before its hyperparameters are updated in parallel and update\\nat the end of each minibatch, which is known as data parallelism. [60].\\n4.2\\nTransformers\\nWord2Vec is a feed-forward network. The model weights and information only\\nflows from the encoding state, to the hidden embedding layer, to the output\\nprobability layer. There is no feedback between the second and third layers,\\nwhich means that each given layer doesn’t know anything about the state of\\nthe layers that follow it. It can’t make inference suggestions longer than the\\ncontext window. This works really well for machine learning problems where\\nwe’re fine with a single, static vocabulary.\\nHowever, it doesn’t work well on long ranges of text that require under-\\nstanding words in context of each other. For example, over the course of a\\nconversation, we might say, \"I read that quote by Langston Hughes. I liked\\nit, but didn’t really read his later work,\" we understand that \"it\" refers to\\nthe quote, context from the previous sentence, and \"his\" refers to \"Langston\\nHughes\", mentioned two sentences ago.\\nOne of the other limitations was that Word2Vec can’t handle out-of-\\nvocabulary words — words that the model has not been trained on and\\nneeds to generalize to. This means that if our users search for a new trending\\nterm or we want to recommend a flit that was written after our model was\\ntrained, they won’t see any relevant results from our model. [14], unless the\\nmodel is retrained frequently.\\nAnother problem is that Word2Vec encounters context collapse around\\npolysemy — the coexistence of many possible meanings for the same phrase:\\nfor example, if you have \"jail cell\" and \"cell phone\" in the same sentence, it\\nwon’t understand that the context of both words is different. Much of the\\nwork of NLP based in deep learning has been in understanding and retaining\\nthat context to propagate through the model and pull out semantic meaning.\\nDifferent approaches were proposed to overcome these limitations. Re-\\nsearchers experimented with recurrent neural networks, RNNs. An RNN\\nbuilds on traditional feed-forward networks, with the difference being that\\nlayers of the model give feedback to previous layers. This allows the model to\\n53'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 53, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='keep memory of the context around words in a sentence.\\nNeuron\\nxt\\nht\\n(a) Feedforward Neural Network\\nNeuron\\nxt\\nht\\n(b) Recurrent Neural Network\\nA problem with traditional RNNs was that because during backpropaga-\\ntion the weights had to be carried through to the previous layers of neurons,\\nthey experienced the problem of vanishing gradients. This occurs when we\\ncontinuously take the derivative such that the partial derivative used in the\\nchain rule during backpropagation approaches zero. Once we approach zero,\\nthe neural network assumes it has reached a local optimum and stops training,\\nbefore convergence.\\nA very popular variation of an RNN that worked around this problem\\nwas the long-short term memory network (LSTM), developed initially by\\nSchmidhuber26 and brought to popularity for use in text applications speech\\nrecognition and image captioning [33]. Whereas our previous model takes only\\na vector at a time as input, RNNs operate on sequences of vectors using GRUs,\\nwhich allows the network to control how much information is passed in for\\nanalysis. While LSTMs worked fairly well, they had their own limitations.\\nBecause they were architecturally complicated, they took much longer to\\ntrain, and at a higher computational cost, because they couldn’t be trained in\\nparallel.\\n4.2.1\\nEncoders/Decoders and Attention\\nTwo concepts allowed researchers to overcome computationally expensive\\nissues with remembering long vectors for a larger context window than\\nwhat was available in RNNs and Word2Vec before it: the encoder/decoder\\narchitecture, and the attention mechanism.\\nThe encoder/decoder architecture is a neural network architecture com-\\nprised of two neural networks, an encoder that takes the input vectors from\\nour data and creates an embedding of a fixed length, and a decoder, also a\\nneural network, which takes the embeddings encoded as input and generates\\n26If you read Schmidhuber, you will come to the understanding that everything in deep\\nlearning was developed initially by Schmidhuber\\n54'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 54, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='a static set of outputs such as translated text or a text summary. In between\\nthe two types of layers is the attention mechanism, a way to hold the state\\nof the entire input by continuously performing weighted matrix multiplica-\\ntions that highlight the relevance of specific terms in relation to each other\\nin the vocabulary. We can think of attention as a very large, complex hash\\ntable that keeps track of the words in the text and how they map to different\\nrepresentations both in the input and the output.\\n-0.2\\n-0.1\\n0.1\\n0.4\\n-0.3\\n1.1\\nDecoder\\nEncoder\\nDecoder\\nTranslated\\ntext\\nInput\\ntext\\nFigure 41: The encoder/decoder architecture\\n55'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 55, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nclass EncoderDecoder(nn.Module):\\n2\\n\"\"\"\\n3\\nDefining the encoder/decoder steps\\n4\\n\"\"\"\\n5\\ndef __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\\n6\\nsuper(EncoderDecoder, self).__init__()\\n7\\nself.encoder = encoder\\n8\\nself.decoder = decoder\\n9\\nself.src_embed = src_embed\\n10\\nself.tgt_embed = tgt_embed\\n11\\nself.generator = generator\\n12\\n13\\ndef forward(self, src, tgt, src_mask, tgt_mask):\\n14\\n\"Take in and process masked src and target sequences.\"\\n15\\nreturn self.decode(self.encode(src, src_mask), src_mask,\\n16\\ntgt, tgt_mask)\\n17\\n18\\ndef encode(self, src, src_mask):\\n19\\nreturn self.encoder(self.src_embed(src), src_mask)\\n20\\n21\\ndef decode(self, memory, src_mask, tgt, tgt_mask):\\n22\\nreturn self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\\n23\\n24\\nclass Generator(nn.Module):\\n25\\n\"Define standard linear + softmax generation step.\"\\n26\\ndef __init__(self, d_model, vocab):\\n27\\nsuper(Generator, self).__init__()\\n28\\nself.proj = nn.Linear(d_model, vocab)\\n29\\n30\\ndef forward(self, x):\\n31\\nreturn F.log_softmax(self.proj(x), dim=-1)\\n32\\nFigure 42: A typical encoder/decoder architecture From the Annotated Transformer\\n\"Attention is All You Need\" [66], released in 2017, combined both of these\\nconcepts into a single architecture. The paper immediately saw a great deal\\nof success, and today Transformers are one of the de-facto models used for\\nnatural language tasks.\\nBased on the success of the original model, a great deal of variations on\\nTransformer architectures have been released, followed by GPT and BERT in\\n2018, Distilbert, a smaller and more compact version of BERT in 2019, and\\nGPT-3 in 202027.\\n27For a complete visual transformer timeline, check out this link\\n56'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 56, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Transformer\\nGPT\\nGPT-2\\nGPT-3\\nDALL-E\\nGPT-4\\nBERT\\nDistilBERT\\nRoBERTa\\nPaLM\\nFigure 43: Timeline of Transformer Models\\nTransformer architectures themselves are not new, but they contain all\\nthe concepts we’ve discussed so far: vectors, encodings, and hash maps.\\nThe goal of a transformer model is to take a piece of multimodal content,\\nand learn the latent relationships by creating multiple views of groups of\\nwords in the input corpus (multiple context windows). The self-attention\\nmechanism, implemented as scaled dot-product attention in the Transformer\\npaper, creates different context windows of the data a number of times through\\nthe six encoder and six decoder layers. The output is the result of the specific\\nmachine learning task — a translated sentence, a summarized paragraph –\\nand the next-to-last layer is the model’s embeddings, which we can use for\\ndownstream work.\\nFigure 44: View into transformer layers, inspired by multiple sources including this diagram\\nThe transformer model described in the paper takes a corpus of text as\\ninput28. We first transform our text to token embeddings by tokenizing and\\nmapping every word or subword to an index. This is the same process as in\\nWord2Vec: we simply assign each word to an element in a matrix. However,\\nthese alone will not help us with context, so, on top of this, we also learn\\na positional embeddings with the help of a sine or cosine function that is\\nmapped and compressed into a matrix considering the position of all the other\\nword in the vocabulary. The final output of this process is the positional vector\\n28In theory you can use any modality for transformers without modifying the input other\\nthan to label the data with the given modality [71], but the early work, such as machine\\ntranslation, focuses on text, so we will as well\\n57'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 57, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='or the word encoding.\\nNext, these positional vectors are passed in parallel to the model. Within\\nthe Transformer paper, the model consists of six layers that perform encod-\\ning and six that perform decoding. We start with the encoder layer, which\\nconsists of two sub-layers: the self-attention layer, and a feed-forward neural\\nnetwork. The self-attention layer is the key piece, which performs the process\\nof learning the relationship of each term in relation to the other through scaled\\ndot-product attention. We can think of self-attention in several ways: as a\\ndifferentiable lookup table, or as a large lookup dictionary that contains both\\nthe terms and their positions, with the weights of each term in relationship to\\nthe other obtained from previous layers.\\nThe scaled dot-product attention is the product of three matrices: key,\\nquery, and value. These are initially all the same values that are outputs of\\nprevious layers - in the first pass through the model, they are initially all the\\nsame, initialized at random and adjusted at each step by gradient descent.\\nFor each embedding, we generate a weighted average value based on these\\nlearned attention weights. We calculate the dot product between query and\\nkey, and finally normalize the weights via softmax. Multi-head attention\\nmeans that we perform the process of calculating the scaled dot product\\nattention multiple times in parallel and concatenate the outcome into one\\nvector.\\nAttention(Q, K, V) = so f tmax(QKT\\n√dk\\n)V\\n(12)\\nWhat’s great about scaled dot-product attention (and about all of the layers\\nof the encoder) is that the work can be done in parallel across all the tokens in\\nour codebase: we don’t need to wait for one word to finish processing as we\\ndo in Word2Vec in order to process the next one, so the number of input steps\\nremains the same, regardless of how big our vocabulary is.\\nThe decoder piece differs slightly from the encoder. It starts with a different\\ninput dataset: in the transformer paper, it’s the target language dataset we’d\\nlike to translate the text into. So for example if we were translating our Flit\\nfrom English to Italian, we’d expect to train on the Italian corpus. Otherwise,\\nwe perform all the same actions: we create indexed embeddings that we then\\nconvert into positional embeddings. We then feed the positional embeddings\\nfor the target text into a layer that has three parts: masked multi-headed\\nattention, multiheaded attention, and a feed-forward neural network. The\\nmasked multi-headed attention component is just like self-attention, with one\\nextra piece: the mask matrix introduced in this step acts as a filter to prevent\\nthe attention head from looking at future tokens, since the input vocabulary\\nfor the decoder are our \"answers\", I.e. what the translated text should be.\\nThe output from the masked multi-head self attention layer is passed to the\\nencoder-decoder attention portion, which accepts the final input from the\\ninitial six encoder layers for the key and value, and uses the input from the\\nprevious decoder layer as the query, and then performs scaled dot-product\\nover this. Each output is then fed into the feed forward layer, to a finalized set\\nof embeddings.\\nOnce we have the hidden state for each token, we can then attach the task\\n58'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 58, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='head. In our case, this is prediction of what a word should be. At each step of\\nthe process, the decoder looks at the previous steps and generates based on\\nthose steps so we form a complete sentence [54]. We then get the predicted\\nword, just like in Word2Vec.\\nTransformers were revolutionary for a number of reasons, because they\\nsolved several problems people had been working on:\\n• Parallelization - Each step in the model is parallelizable, meaning we\\ndon’t need to wait to know the positional embedding of one word in\\norder to work on another, since each embedding lookup matrix focuses\\nattention on a specific word, with a lookup table of all other words in\\nrelationship to that word - each matrix for each word carries the context\\nwindow of the entire input text.\\n• Vanishing gradients - Previous models like RNNs can suffer from van-\\nishing or exploding gradients, which means that the model reaches a\\nlocal minimum before it’s fully-trained, making it challenging to cap-\\nture long-term dependencies. Transformers mitigate this problem by\\nallowing direct connections between any two positions in the sequence,\\nenabling information to flow more effectively during both forward and\\nbackward propagation.\\n• Self-attention - The attention mechanism allows us to learn the context\\nof an entire text that’s longer than a 2 or 3-word sliding context window,\\nallowing us to learn different words in different contexts and predict\\nanswers with more accuracy\\n4.3\\nBERT\\nFigure 45: Encoder-only architecture\\nAfter the explosive success of \"Attention is All you Need\", a variety of trans-\\nformer architectures arose, research and implementation in this architecture\\nexploded in deep learning. The next transformer architecture to be considered\\na significant step forward was BERT. BERT stands for Bi-Directional Encoder\\nand was released 2018 [13], based on a paper written by Google as a way\\nto solve common natural language tasks like sentiment analysis, question-\\nanswering, and text summarization. BERT is a transformer model, also based\\non the attention mechanism, but its architecture is such that it only includes\\nthe encoder piece. Its most prominent usage is in Google Search, where it’s\\nthe algorithm powering surfacing relevant search results. In the blog post\\nthey released on including BERT in search ranking in 2019, Google specifi-\\ncally discussed adding context to queries as a replacement for keyword-based\\n59'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 59, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='methods as a reason they did this.29\\nBERT works as a masked language model. Masking is simply what we\\ndid when we implemented Word2Vec by removing words and building our\\ncontext window. When we created our representations with Word2Vec, we\\nonly looked at sliding windows moving forward. The B in Bert is for bi-\\ndirectional, which means it pays attention to words in both ways through\\nscaled dot-product attention. BERT has 12 transformer layers. It starts by\\nusing WordPiece, an algorithm that segments words into subwords, into\\ntokens. To train BERT, the goal is to predict a token given its context.\\nThe output of BERT is latent representations of words and their context —\\na set of embeddings. BERT is, essentially, an enormous parallelized Word2Vec\\nthat remembers longer context windows. Given how flexible BERT is, it\\ncan be used for a number of tasks, from translation, to summarization, to\\nautocomplete. Because it doesn’t have a decoder component, it can’t generate\\ntext, which paved the way for GPT models to pick up where BERT left off.\\n4.4\\nGPT\\nAround the same time that BERT was being developed, another transformer\\narchitecture, the GPT series, was being developed at OpenAI. GPT differs\\nfrom BERT in that it encodes as well as decodes text from embeddings and\\ntherefore can be used for probabilistic inference.\\nThe original, first GPT model was trained as a 12-layer, 12-headed trans-\\nformer with only a decoder piece, based on data from Book Corpus. Sub-\\nsequent versions built on this foundation to try and improve context under-\\nstanding. The largest breakthrough was in GPT-4, which was trained with\\nreinforcement learning from Human Feedback, a property which allows it\\nto make inferences from text that feels much closer to what a human would\\nwrite.\\nWe’ve now reached the forefront of what’s possible with embeddings\\nin this paper. With the rise of generative methods and methods based on\\nReinforcement Learning with Human Feedback like OpenAI’s ChatGPT, as\\nwell as the nascent open-source Llama, Alpaca, and other models, anything\\nwritten in this paper would already be impossibly out of date by the time it\\nwas published30.\\n5\\nEmbeddings in Production\\nWith the advent of Transformer models, and more importantly, BERT, gen-\\nerating representations of large, multimodal objects for use in all sorts of\\nmachine learning tasks suddenly became much easier, the representations\\nbecame more accurate, and if the company had GPUs available, computations\\ncould now be computed with speed-up in parallel. Now that we understand\\nwhat embeddings are, what should we do with them? After all, we’re not\\n29BERT search announcement\\n30There are already some studies about possible uses of LLMs for recommendations, includ-\\ning conversational recommender systems, but it’s still very early days. For more information\\ncheck out this post\\n60'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 60, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='doing this just as a math exercise. If there is one thing to take away from this\\nentire text, it is this:\\nThe final goal of all industrial machine learning (ML) projects is to develop\\nML products and rapidly bring them into production. [37]\\nThe model that is deployed is always better and more accurate than the\\nmodel that is only ever a prototype. We’ve gone through the process of\\ntraining embeddings end to end here, but there are several modalities for\\nworking with embeddings. We can:\\n• Train our own embeddings model - We can train BERT or some variation\\nof BERT from scratch. BERT uses an enormous amount of training\\ndata, so this is not really advantageous to us, unless we want to better\\nunderstand the internals and have access to a lot of GPUs.\\n• Use pretrained embeddings and fine-tune - There are many variations\\non BERT models and they all Variations of BERT have been used to\\ngenerate embeddings to use as downstream input into many recom-\\nmender and information retrieval systems. One of the largest gifts that\\nthe transformer architecture gives us is the ability to perform transfer\\nlearning.\\nBefore, when we learned embeddings in pre-transformer architectures,\\nour representation of whatever dataset we had at hand was fixed — we\\ncouldn’t change the weights of the words in TF-IDF without regenerating\\nan entire dataset.\\nNow, we have the ability to treat the output of the layers of BERT as input\\ninto the next neural network layer of our own, custom model. In addition to\\ntransfer learning, there are also numerous more compact models for BERT,\\nsuch as Distilbert and RoBERTA and for many of the larger models in places\\nlike the HuggingFace Model Hub31.\\nArmed with this knowledge, we can think of several use cases of embed-\\ndings, given their flexibility as a data structure.\\n• Feeding them into another model - For example, we can now per-\\nform collaborative filtering using both user and item embeddings\\nthat were learned from our data instead of coding the users and items\\nthemselves.\\n• Using them directly - We can use item embeddings directly for\\ncontent filtering - finding items that are closest to other items, a task\\nrecommendation shares with search. There are a host of algorithms\\nused to perform vector similarity lookups by projecting items into our\\nembedding space and performing similarity search using algorithms\\nlike faiss and HNSW.\\n31For a great writeup on the development of open-source machine learning deep learning,\\nsee \"A Call to Build Models Like We Build Open-Source Software\"\\n61'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 61, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='5.1\\nEmbeddings in Practice\\nMany companies are working with embeddings in all of these contexts today,\\nacross areas that span all aspects of information retrieval. Embeddings gen-\\nerated with deep learning models are being generated for use in wide and\\ndeep models for App Store recommendations at Google Play [73], dual em-\\nbeddings for product complementary content recommendations at Overstock\\n[38], personalization of search results at Airbnb via real-time ranking [25], us-\\ning embeddings for content understanding at Netflix [16], for understanding\\nvisual styles at Shutterstock [24], and many other examples.\\n5.1.1\\nPinterest\\nOne notable example is Pinterest. Pinterest as an application has a wide variety\\nof content that needs to be personalized and classified for recommendation to\\nusers across multiple surfaces, particularly the Homefeed and shopping tab.\\nThe scale of generated content - 350 million monthly users and 2 billion items\\n- Pins — or cards with an image described by text — necessitates a strong\\nfiltering and ranking policy.\\nTo represent a user’s interest and surface interesting content, Pinterest\\ndeveloped PinnerSage [50], which represents user interests through multiple\\n256-dimension embeddings that are clustered based on similarity and repre-\\nsented by medioids — an item that is a representative of a center of a given\\ninterest cluster.\\nThe foundation of this system is a set of embeddings developed through an\\nalgorithm called PinSage [72]. Pinsage generates embeddings using a Graph\\nConvolutional neural network, which is a neural net that takes into account the\\ngraph structure of relationships between nodes in the network. The algorithm\\nlooks at the nearest neighbors of a pin and samples from nearby pins based\\non related neighborhood visits. The input is embeddings of a Pin: the image\\nembeddings, and the text embeddings, and finds the nearest neighbors.\\nPinsage embeddings are then passed to Pinnersage, which takes the pins\\nthe user has acted on for the past 90 days and clusters them. It computes the\\nmedioid and takes the top 3 medioids based on importance, and, given a user\\nquery that is a medioid, performs an approximate nearest neighbors search\\nusing HNSW to find the pins closest to the query in the embedding space.\\n62'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 62, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 46: Pinnersage and Pinsage embeddings-based similarity retrieval\\n5.1.2\\nYouTube and Google Play Store\\nYouTube\\nYouTube was one of the first large companies to publicly share their work on\\nembeddings used in the context of a production recommender system with\\n\"Deep Neural Networks for YouTube Recommendations.\"\\nYouTube has over 800 million pieces of content (videos) and 2.6 billion\\nactive users that they’d like to recommend those videos to. The application\\nneeds to recommend existing content to users, while also generalizing to new\\ncontent, which is uploaded frequently. They need to be able to serve these\\nrecommendations at inference time — when the user loads a new page —\\nwith low latency.\\nIn this paper [11], YouTube shares how they created a two-stage recom-\\nmender system for videos based on two deep learning models. The machine\\nlearning task is to predict the correct next video to show the user at a given\\ntime in YouTube recommendations so that they click. The final output is\\nformulated as a classification problem: given a user’s input features and the\\ninput features of a video, can we predict a class for the user that includes the\\npredicted watch time for the user for a specific video with a specific probability.\\nFigure 47: YouTube’s end-to-end video recommender system, including a candidate generator\\nand ranker [11]\\n63'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 63, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='We set this task given a user, U and context C32\\nGiven the size of the input corpus, we need to formulate the problem as\\na two-stage recommender: the first is the candidate generator that reduces\\nthe candidate video set to hundreds of items and a second model, similar in\\nsize and shape, called a ranker that ranks these hundreds of videos by the\\nprobability that the user will click on them and watch.\\nThe candidate generator is a softmax deep learning model with several\\nlayers, all activated with ReLU activation functions – rectified linear unit\\nactivation that outputs the input directly if positive; otherwise, it’s zero. The\\nuses both embedded and tabular learning features, all of which are combined\\nand\\nTo build the model, we use two sets of embeddings as input data: one\\nthat’s the user plus context as features, and a set of video items. The model\\nhas several hundreds of features, both tabular and embeddings-based. For the\\nembeddings-based features, we include elements like:\\n• User watch history - represented by a vector of sparse video ID elements\\nmapped into a dense vector representation\\n• User’s search history - Maps search term to video clicked from the search\\nterm, also in a sparse vector mapped into the same space as the user\\nwatch history\\n• User’s geography, age, and gender - mapped as tabular features\\n• The number of previous impressions a video had, normalized per user\\nover time\\nThese are all combined into a single item embedding, and in the case of\\nthe user, a single embedding that’s a blended map of all the user embedding\\nfeatures, and fed into the models’ softmax layers, which compare the distance\\nbetween the output of the softmax layer, i.e. the probability that the user will\\nclick on an item, and a set of ground truth items, i.e. a set of items that the user\\nhas already interacted with. The log probability of an item is the dot product\\nof two n-dimensional vectors, i.e. the query and item embeddings.\\nWe consider this an example of Implicit feedback - feedback the user did\\nnot explicitly give, such as a rating, but that we can capture in our log data.\\nEach class response, of which there are approximately a million, is given a\\nprobability as output.\\nThe DNN is a generalization of the matrix factorization model we dis-\\ncussed earlier.\\n32In recommender systems, we often think of four relevant items to formulate our recom-\\nmender problem - user, item, context, and query. The context is usually the environment, for\\nexample the time of day or the geography of the user at inference time\\n64'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 64, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 48: YouTube’s multi-step neural network model for video recommendations using\\ninput embeddings [11]\\nGoogle Play App Store\\nSimilar work, although with a different architecture, was done in the App\\nStore in Google Play in \"Wide and Deep Learning for Recommender Systems\"\\n[7]. This one crosses the search and recommendation space because it returns\\ncorrect ranked and personalized app recommendations as the result of a search\\nquery. The input is clickstream data collected when a user visits the app store.\\nFigure 49: Wide and deep [7]\\nThe recommendations problem is formulated here as two jointly-trained\\nmodels. The weights are shared and cross-propagated between the two models\\nbetween epochs.\\nThere are two problems when we try to build models that recommend\\nitems: memorization - the model needs to learn patterns by learning how\\nitems occur together given the historical data, and generalization - the model\\nneeds to be able to give new recommendations the user has not seen before that\\nare still relevant to the user, improving recommendation diversity. Generally,\\none model alone cannot encompass both of these tradeoffs.\\nWide and deep is made up of two models that look to complement each\\nother:\\n65'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 65, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• A wide model which uses traditional tabular features to improve the\\nmodel’s memorization.\\nThis is a general linear model trained on\\nsparse, one-hot encoded features like user_installed_app=netflix\\nacross thousands of apps.\\nMemorization works here by creat-\\ning binary features that are combinations of features, such as\\nAND(user_installed_app=netflix, impression_app_pandora, allow-\\ning us to see different combinations of co-occurrence in relationship\\nto the target, i.e. likelihood to install app Y. However, this model cannot\\ngeneralize if it gets a new value outside of the training data.\\n• A deep model that supports generalization across items that the model\\nhas not seen before, using a feed-forward neural network made up\\nof categorical features that are translated to embeddings, such as user\\nlanguage, device class, and whether a given app has an impression.\\nEach of these embeddings range from 0-100 in dimensionality. They\\nare combined jointly into a concatenated embedding space with dense\\nvectors in 1200 dimensions. and initialized randomly. The embedding\\nvalues are trained to minimize loss of the final function, which is a\\nlogistic loss function common to the deep and wide model.\\nFigure 50: The deep part of the wide and deep model [7]\\nThe model is trained on 500 billion examples, and evaluated offline using\\nAUC and online using app acquisition rate, the rate at which people download\\nthe app. Based on the paper, using this approach improved the app acquisition\\nrate on the main landing page of the app store by 3.9 % relative to the control\\ngroup.\\n5.1.3\\nTwitter\\nAt Twitter, pre-computed embeddings were a critical part recommendations\\nfor many app surface areas including user onboarding topic interest predic-\\ntion, recommended Tweets, home timeline construction, users to follow, and\\n66'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 66, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='recommended ads.\\nTwitter had a number of embeddings-based models but we’ll cover two\\nprojects here: Twice [44], content embeddings for Tweets, which looks to find\\nrich representations of Tweets that include both text and visual data for use in\\nsurfacing Tweets in the home timeline, Notifications and Topics. Twitter also\\ndeveloped TwHIN [18], Twitter Heterogeneous Information Network, a set\\nof graph-based embeddings [18], developed for tasks like personalized ads\\nrankings, account follow-recommendation, offensive content detection, and\\nsearch ranking, based on nodes (such as users and advertisers) and edges that\\nrepresent entity interactions.\\nFigure 51: Twitter’s Twice Embeddings, a trained BERT model [44]\\nTwice is a BERT model trained from scratch on an input corpus of 200\\nmillion Tweets that users engaged with sampled over 90 days and also includes\\nassociations to the users themselves. The objective of the model is to optimize\\non several tasks: topic prediction (aka the topic associated with a Tweet, of\\nwhich there could be multiple), engagement prediction (the likelihood a user\\nis to engage with a Tweet), and language prediction to cluster Tweets of the\\nsame language to be clustered closer together.\\nTwHIN, rather than just focusing on Tweet content, considers all entities in\\nTwitter’s environment (Tweets, users, advertiser entities) as belong together\\nin a joint embedding space graph.\\nJoint embedding is performed by using data from user-Tweet engagement,\\nadvertising, and following data, to create multi-model embeddings. TWHin\\nis used for candidate generation. The candidate generator finds users to\\nfollow or Tweets to engage with an HNSW or Faiss to retrieve candidate items.\\nTWHin embeddings are then used to query candidate items and increase\\ndiversity in the candidate pool.\\n67'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 67, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 52: Twitter’s model of the app’s heterogeneous information network [18]\\nEmbeddings at Flutter\\nOnce we synthesize enough of these architectures, we see some patterns\\nstart to emerge that we can think about adapting for developing our relevant\\nrecommendation system at Flutter.\\nFirst, we need a great deal of input data to make accurate predictions\\nfrom, and that data should have information about either explicit, or, more\\nlikely, implicit data like user clicks and purchases so that we can construct our\\nmodel of user preferences. The reason we need a lot of data is two-fold. First,\\nneural networks are data-hungry and require a large amount of training data\\nto correctly infer relationships in comparison to traditional models. Second,\\nlarge data requires a large pipeline.\\nIf we don’t have a lot of data, a simpler model will work well-enough,\\nso we need to make sure we are actually at the scale where embeddings\\nand neural networks help our business problem. It’s likely the case that we\\ncan start much simpler. And in fact, a recent paper by one of the original\\nresearchers who developed factorization machines, an important approach\\nin recommendations, argues that simple dot products found as the result of\\nmatrix factorization outperform neural networks [52]. Second, in order to get\\ngood embeddings, we will need to spend a great deal of time cleaning and\\nprocessing data and creating features, as we did in the YouTube paper, so the\\noutcome has to be worth the time spent.\\nSecond, we need to be able to understand the latent relationship between\\nusers and items they’ve interacted with. In traditional recommenders, we\\ncould use TF-IDF to find the weighted word features as part of a particular flit\\nand compare across documents, as long as our corpus doesn’t grow too large.\\nIn more advanced recommendation systems, we could perform this same task\\nby looking at either naive association rules, or framing recommendation as\\nan interaction-based collaborative filtering problem not unlike Word2Vec to\\ngenerate latent features, aka embeddings, of our users and items. In fact, this\\n68'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 68, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='is exactly what Levy and Goldberg argued in \"Neural Word Embedding as Im-\\nplicit Matrix Factorization\" [43]. They looked at the skipgram implementation\\nof Word2Vec and found that implicitly it factors a word-context matrix.\\nWe could alternatively still use tabular features as input into our collabo-\\nrative filtering problem but use a neural network [28] instead of simple dot\\nproduct to converge on the correct relationships and the downstream ranking\\nfor the model.\\nGiven our new knowledge about how embeddings and recommender sys-\\ntems work, we can now incorporate embeddings into the recommendations\\nwe serve for flits at Flutter. If we want to recommend relevant content, we\\nmight do it in a number of different ways, depending on our business require-\\nments. In our corpus, we have hundreds of millions of messages that we need\\nto filter down to hundreds to show the user. So we can start with a baseline of\\nWord2Vec or similar and move on to any of the BERT or other neural network\\napproaches to developing model input features, vector similarity search, and\\nranking, through the power of embeddings.\\nEmbeddings are endlessly flexible and endlessly useful, and can empower\\nand improve the performance of our multimodal machine learning workflows.\\nHowever, as we just saw, there are some things to keep in mind if we do\\ndecide to use them.\\n5.2\\nEmbeddings as an Engineering Problem\\nIn general, machine learning workflows add an enormous amount of com-\\nplexity and overhead to our engineering systems, for a number of reasons\\n[57]. First, they blend data that then needs to be monitored for drift down-\\nstream. Second, they are non-deterministic in their outputs, which means they\\nneed to be tracked extremely carefully as artifacts, since we generally don’t\\nversion-control data. Third, they result in processing pipeline jungles.\\nAs a special case of glue code, pipeline jungles often appear in\\ndata preparation. These can evolve organically, as new signals are\\nidentified and new information sources added. Without care, the\\nresulting system for preparing data in an ML-friendly format may\\nbecome a jungle of scrapes, joins, and sampling steps, often with\\nintermediate files output.\\nAs we can see from several system diagrams, including PinnerSage and\\nthe Wide and Deep Model, recommender systems in production utilizing\\nembeddings have many moving components.\\n69'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 69, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 53: PinnerSage model archi-\\ntecture [50]\\nFigure 54: Wide and Deep model\\narchitecture [7]\\nYou may recall that we discussed the simple stages of a recommender\\nsystem in this diagram.\\nFigure 55: Generic system processing embeddings in context\\nGiven all of our production-level requirements for a successful recom-\\nmendation system, our actual production system generally looks more like\\nthis:\\n• Generating embeddings\\n• Storing embeddings\\n• Embedding feature engineering and iteration\\n• Artifact retrieval\\n• updating embeddings\\n• versioning embeddings and data drift\\n• Inference and latency\\n• Online (A/B test) and offline (metric sweep) model evaluation\\nGiven all of our concern space, the diagram of any given production\\nsystem would look more like this\\n70'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 70, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 56: Recommender systems as a machine learning problem\\n5.2.1\\nEmbeddings Generation\\nWe’ve already seen that embeddings are usually generated as a byproduct of\\ntraining neural network models, most often the penultimate layer that’s used\\nbefore a layer to classify or regress is added as the final output. We have two\\nways to build them. We can train our own models, as YouTube, Pinterest, and\\nTwitter have done. In the LLM space, there is also growing interest in being\\nable to train large language models in-house.\\nHowever, one of the large benefits of deep learning models is that we\\ncan also use pre-trained model. A pretrained model is any model that’s like\\nthe one we’re considering for our task that has already been trained on an\\nenormous corpus of training data, and can be used for downstream tasks.\\nBERT is an example of a model that has already been pre-trained and can\\nbe used for any number of machine learning tasks through the process of\\nfine-tuning. In fine-tuning, we take a model that’s already been pre-trained\\non a generic dataset. For example, BERT was trained on BookCorpus, a set of\\n11k books with 800 million words and English Wikipedia, 2.5 billion words.\\nAn aside on training data\\nTraining data is the most important part of any given model. Where does it\\ncome from for pre-trained large language models? Usually scraping large\\nparts of the internet. In the interest of competitive advantage, how these\\ntraining datasets are put together is usually not revealed, and there is a\\nfair amount of reverse-engineering and speculation. For example, \"What’s\\nin my AI\" goes into the training data behind the GPT series of models\\nand finds that GPT-3 was trained on Books1 and Books2. Books1 is likely\\nbookcorpus and books2 is likely libgen. GPT also includes the Common\\nCrawl, a large open-source dataset of indexed websites, WebText2, and\\nWikipedia. This information is important because when we pick a model\\n71'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 71, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='we need to at least understand at a high level what it was trained on to\\nbe a general-purpose model so we can explain what changes when we\\nfine-tune it.\\nIn fine-tuning a model, we perform all the same steps as we do for training\\nfrom scratch. We have training data, we have a model, and we minimize a\\nloss function. However, there are several differences. When we create our\\nnew model, we copy the existing, pre-trained model with the exception of\\nthe final output layer, which we initialize from scratch based on our new task.\\nWhen we train the model, we initialize these parameters at random and only\\ncontinue to adjust the parameters of the previous layers so that they focus on\\nthis task rather than starting to train from scratch. In this way, if we have a\\nmodel like BERT that’s trained to generalize across the whole internet, but our\\ncorpus for Flutter is very sensitive to trending topics and needs to be updated\\non a daily basis, we can refocus the model without having to train a new one\\nwith as few as 10k samples instead of our original hundreds of millions [74].\\nThere are, likewise, BERT embeddings available that we can fine-tune.\\nThere are other generalized corpuses available, such as GloVE, Word2Vec, and\\nFastText (also trained with CBOW). We need to make a decision whether to\\nuse these, train a model from scratch, or a third option, to query embeddings\\navailable from an API as is the case for OpenAI embeddings, although doing\\nso can potentially come at a higher cost, relative to training or fine-tuning our\\nown. Of course, all of this is subject to our particular use-case and is important\\nto evaluate when we start a project.\\n5.2.2\\nStorage and Retrieval\\nOnce we’ve trained our model, we’ll need to extract the embeddings from\\nthe trained object. Generally, when a model is trained, the resulting output is\\na data structure that contains all the parameters of the model, including the\\nmodel’s weights, biases, layers and learning rate. The embeddings are part of\\nthis model object as a layer, and they initially live in-memory. When we write\\nthe model to disk, we propagate them as a model object, which is serialized\\nonto memory and loaded at re-training or inference time.\\nThe simplest form of embedding store can be an in-memory numpy ar-\\nray33.\\nBut if we are iterating on building a model with embeddings, we want to\\nbe able to do a number of things with them:\\n• Access them in batch and one-by-one at inference time\\n• Perform offline analysis on the quality of the embeddings\\n• Embedding feature engineering\\n• Update embeddings with new models\\n• Version embeddings\\n• Encode new embeddings for new documents\\n33From a Tweet by Andrej Karpathy in response to how he stores vector embeddings for a\\nsmall movie recommendations side project in 2023,\"np.array people keep reaching for much\\nfancier things way too fast these days. Tweet\\n72'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 72, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='The most complex and customizable software that handles many of these\\nuse-cases is a vector database, and somewhere in-between vector databases\\nand in-memory storage are vector search plugins for existing stores like Post-\\ngres and SQLite, and caches like Redis.\\nThe most important operation we’d like to perform with embeddings is\\nvector search, which allows us to find embeddings that are similar to a given\\nembedding so we can return item similarity. If we want to search embeddings,\\nwe need a mechanism that is optimized to search through our matrix data\\nstructures and perform nearest-neighbor comparisons in the same way that\\na traditional relational database is optimized to search row-based relations.\\nRelational databases use a b-tree structure to optimize reads by sorting items\\nin ascending order within a hierarchy of nodes, built on top of an indexed\\ncolumn in the database. We can’t perform columnar lookups on our vectors\\nefficiently, so we need to create different structures for them. For example,\\nmany vector stores are based on inverted indices.\\nA general-form embeddings store contains the embeddings themselves, an\\nindex to map them back from the latent space into words, pictures, or text, and\\na way to do similarity comparisons between different types of embeddings\\nusing various nearest neighbors algorithms. We talked before about cosine\\nsimilarity as a staple of comparing latent space representations. This can be-\\ncome computationally expensive over millions of sets of vectors, because we’d\\nneed to do a pairwise comparison over every pair. To solve this, approximate\\nnearest neighbors (ANN) algorithms were developed to, as in recommender\\nsystems, create neighborhoods out of elements of vectors and find a vector’s\\nk-nearest neighbors. The most frequently-used algorithms include HNSW\\n(hierarchical navigable small worlds) and Faiss, both of which are standalone\\nlibraries and also implemented as part of many existing vector stores.\\nThe trade-off between full and nearest neighbor search is that the latter is\\nless precise, but it’s much faster. When we switch between precision and recall\\nin evaluation, we need to be aware of the tradeoffs and think about what our\\nrequirements are with respect to how accurate our embeddings are and their\\ninference latency.\\nHere’s an example of the embeddings storage system that Twitter built for\\nexactly this use case, long before vector databases came into the picture. [62].\\nFigure 57: Twitter’s embeddings pipeline [62]\\n73'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 73, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Given that Twitter uses embeddings in multiple sources as described in\\nthe previous section, Twitter made embeddings \"first class citizens\" by creat-\\ning a centralized platform that reprocesses data and generates embeddings\\ndownstream into the feature registry.\\n5.2.3\\nDrift Detection, Versioning, and Interpretability\\nOnce we’ve trained embeddings, we might think we’re done. But embeddings,\\nlike any machine learning pipeline, need to be refreshed because we might\\nrun into concept drift. Concept drift occurs when the data underlying our\\nmodel changes. For example, let’s say that our model includes, as a binary\\nfeature, people who have landlines or not. In 2023, this would no longer be as\\nrelevant of a feature in most of the world as most people have switched to cell\\nphones as their primary telephones, so the model would lose accuracy.\\nThis phenomenon is even more prevalent with embeddings that are used\\nfor classification. For example, let’s say we use embeddings for trending topic\\ndetection. The model has to generalize, as in the wide and deep model, to\\ndetect new classes, but if our classes change quickly, it may not be able to, so\\nwe need to retrain your embeddings frequently. Or, for example, if we model\\nembeddings in a graph, as Pinterest does, and the relationships between nodes\\nin the graph change, we may have to update them [69]. We could also have an\\ninflux of spam or corrupted content which changes the relationship in your\\nembeddings, in which case we’ll need to retrain.\\nEmbeddings can be hard to understand (so hard that some people have\\neven written entire papers about them) and harder to interpret. What does it\\nmean for a king to be close to queen but far away from the knight? What does\\nit mean for two flits to be close to each other in a projected embedding space?\\nWe have two ways we can think about this, intrinsic and extrinsic evalua-\\ntion. For the embeddings themselves (extrinsic evaluation), we can visualize\\nthem through either UMAP—Uniform Manifold Approximation and Projec-\\ntion for Dimension Reduction or t-sne — t-distributed stochastic neighbor\\nembedding, algorithms that allow us to visualize highly-dimensional data in\\ntwo or three dimensions, much like PCA. Or we can fit embeddings into our\\ndownstream task (for example, summarization, or classification), and analyze\\nthe same way we would with offline metrics. There are many different ap-\\nproaches [67] but the summary is that embeddings can be objectively hard to\\nevaluate and we’ll need to factor the time to perform this evaluation into our\\nmodeling time.\\nOnce we retrain our initial baseline model, we now have a secondary issue:\\nhow do we compare the first set of embeddings to the second; that is, how do\\nwe evaluate whether they are good representations of our data, given the case\\nthat embeddings are often unsupervised; i.e. — how do we know whether\\n\"king\" should be close to \"queen\"? On their own, as a first-pass, embeddings\\ncan be hard to interpret, because in a multidimensional space it’s hard to\\nunderstand which dimension of a vector corresponds to a decision to place\\nitems next to each other [63]. When compared to other sets of embeddings,\\nwe might use the offline metrics of the final model task, precision and recall,\\nor we could measure the distance of the distribution of the embeddings in the\\n74'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 74, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='latent space by comparing the statistical distance between the two probability\\ndistributions using a metric known as Kullback–Leibler divergence.\\nFinally, now let’s say that we have two sets of embeddings, you need to\\nversion them and keep both sets so that, in case your new model doesn’t work\\nas well, you can fall back to the old one. This goes hand-in-hand with the\\nproblem of model versioning in ML operations, except in this case we need to\\nboth version the model and the output data.\\nThere are numerous different approaches to model and data versioning\\nthat involve building a system that tracks both the metadata and the location\\nof the assets that are kept in a secondary data store. Another thing to keep in\\nmind is that embedding layers, particularly for large vocabularies, can balloon\\nin size, so now we have to consider storage costs, as well.\\n5.2.4\\nInference and Latency\\nWhen working with embeddings, we are operating not only in a theoretical,\\nbut practical engineering environment. The most critical engineering part of\\nany machine learning system that works in production is inference time —\\nhow quickly does it take to query the model asset and return a result to an\\nend-user.\\nFor this, we care about latency, which we can roughly define as any time\\nspent waiting and is a critical performance metric in any production system\\n[26]. Generally speaking, it’s the time of any operation to complete – appli-\\ncation request, database query, and so on. Latency at the level of the web\\nservice is generally measured in milliseconds, and every effort is made to\\nreduce this as close to zero as realistically possible. For use-cases like search\\nand loading a feed of content, the experience needs to be instantaneous or the\\nuser experience will degrade and we could even lose revenue. In a study from\\na while back, Amazon found that every 100ms increase in latency cuts profits\\nby 1% [19].\\nGiven this, we need to think about how to reduce the footprint of our\\nmodel and all the layers in serving it so that the response to the user is\\ninstantaneous. We do this by creating observability throughout our machine\\nlearning system, starting with the hardware the system is running on, to\\nCPU and GPU utilization, the performance of our model architecture, and\\nhow that model interacts with other components. For example, when we are\\nperforming nearest neighbor lookup, the way we perform that lookup and the\\nalgorithm we use, the programming language we use to write that algorithm,\\nall compound latency concerns.\\nAs an example, in the wide and deep paper, the recommender ranking\\nmodel scores over 10 million apps per second. The application was initially\\nsingle-threaded, with all candidates taking 31 milliseconds. By implementing\\nmultithreading, they were able to reduce client-side latency to 14 milliseconds\\n[7].\\nOperations of machine learning systems is an entirely other art and craft\\nof study and one that’s best left for another paper [37].\\n75'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 75, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='5.2.5\\nOnline and Offline Model Evaluation\\nWe’ve barely scratched the surface of one of the most critical parts of a model:\\nhow it performs in offline and online testing. When we talk about offline tests,\\nwe mean analyzing the statistical properties of a model to learn whether the\\nmodel is a valid model - i.e. does our loss function converge? Does the model\\noverfit or underfit? What is the precision and recall? Do we experience any\\ndrift? If it’s a recommendation ranker model, are we using metrics like NDCG\\n—normalized discounted cumulative gain— to understand whether our new\\nmodel ranks items better than the previous iteration?\\nThen, there is online evaluation, aka how successful the model actually\\nis in the production context. Usually, this is evaluated through A/B testing\\nwhere one set of users gets the old model or system and a holdout set of users\\ngets the new system, and looking at the statistical significance of metrics like\\nclick-through rate, items served, and time spent on a given area of the site.\\n5.2.6\\nWhat makes embeddings projects successful\\nFinally, once we have all our algorithmic and engineering concerns lined up,\\nthere is the final matter to consider of what will make our project successful\\nfrom a business perspective. We should acknowledge that we might not\\nalways need embeddings for our machine learning problem, or that we might\\nnot need machine learning at all, initially, if our project is based entirely on a\\nhandful of heuristic rules that can be determined and analyzed by humans\\n[76].\\nIf we conclude that we are operating in a data-rich space where automati-\\ncally inferring semantic relationships between entities is correct, we need to\\nask ourselves if we’re willing to put in a great deal of effort into producing\\nclean datasets, the baseline of any good machine learning model, even in cases\\nof large language models. In fact, clean, domain data is so important that\\nmany of the companies discussed here ended up training their own embed-\\ndings models, and, recently companies like Bloomberg [70] and Replit [59] are\\neven training their own large language models to improve accuracy for their\\nspecific business domain.\\nCritically, to get to a stage where we have a machine learning system\\ndealing with embeddings, we need a team that has multilevel alignment\\naround the work that needs to be done. In larger companies, the size of this\\nteam will be larger, but most specifically work with embeddings requires\\nsomeone who can speak to the use case specifically, someone who advocates\\nfor the use case and gets it prioritized, and a technical person who can do the\\nwork [46].\\nIf all of these components come together, we now have an embeddings-\\nbased recommender system in production.\\n6\\nConclusion\\nWe have now walked through an end-to-end example of what embeddings\\nare. We started with a high-level overview of how embeddings fit into the\\n76'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 76, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='context of a machine learning application. We then did a deep dive on early\\napproaches to encoding, built up intuition of embeddings in Word2Vec and\\nthen moving on to transformers and BERT. Although reducing dimensionality\\nas a concept has always been important in machine learning systems to de-\\ncrease computational and storage complexity, compression has become even\\nmore important in the modern explosion of multimodal representations of\\ndata that comes from application log files, images, video, and audio, and the\\nexplosion of Transformer, generative, and diffusion models, combined with\\nthe cheap storage and explosion of data, has amended itself to architectures\\nwhere embeddings are used more and more.\\nWe’ve understood the engineering context of why we might include ma-\\nchine learning models in our application, how they work, how to incorporate\\nthem, and where embeddings —dense representations of deep learning model\\ninput and output data – can be best leveraged. Embeddings are a powerful\\ntool in any machine learning system, but one that comes at a cost of mainte-\\nnance and interpretability. Generating embeddings using the correct method,\\nwith the correct metrics and hardware and software, is a project that takes con-\\nsiderable thought. We now hopefully have a solid grasp of the fundamentals\\nof embedding and can either leverage them – or explain why not to –in our\\nnext project. Good luck navigating embeddings, see you in the latent space!\\n77'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 77, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='References\\n1. Gabriel\\nAltay.\\nCategorical\\nvariables\\nin\\ndecision\\ntrees,\\nMar\\n2020. URL https://www.kaggle.com/code/gabrielaltay/categorical-\\nvariables-in-decision-trees.\\n2. Ioannis Arapakis, Xiao Bai, and B Barla Cambazoglu. Impact of response\\nlatency on user behavior in web search. In Proceedings of the 37th inter-\\nnational ACM SIGIR conference on Research & development in information\\nretrieval, pages 103–112, 2014.\\n3. Remzi H Arpaci-Dusseau and Andrea C Arpaci-Dusseau. Operating sys-\\ntems: Three easy pieces. Arpaci-Dusseau Books, LLC, 2018.\\n4. Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation\\nlearning: A review and new perspectives. IEEE transactions on pattern\\nanalysis and machine intelligence, 35(8):1798–1828, 2013.\\n5. Pablo Castells and Dietmar Jannach. Recommender systems: A primer.\\narXiv preprint arXiv:2302.02579, 2023.\\n6. Dhivya Chandrasekaran and Vijay Mago. Evolution of semantic similar-\\nity—a survey. ACM Computing Surveys (CSUR), 54(2):1–37, 2021.\\n7. Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar\\nChandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai,\\nMustafa Ispir, et al. Wide & deep learning for recommender systems.\\nIn Proceedings of the 1st workshop on deep learning for recommender systems,\\npages 7–10, 2016.\\n8. Francois Chollet. Deep learning with Python. Simon and Schuster, 2021.\\n9. Ronan Collobert and Jason Weston. A unified architecture for natural\\nlanguage processing: Deep neural networks with multitask learning. In\\nProceedings of the 25th international conference on Machine learning, pages\\n160–167, 2008.\\n10. Yingnan Cong, Yao-ban Chan, and Mark A Ragan. A novel alignment-free\\nmethod for detection of lateral genetic transfer based on tf-idf. Scientific\\nreports, 6(1):1–13, 2016.\\n11. Paul Covington, Jay Adams, and Emre Sargin. Deep neural networks for\\nyoutube recommendations. In Proceedings of the 10th ACM conference on\\nrecommender systems, pages 191–198, 2016.\\n12. Toni Cvitanic, Bumsoo Lee, Hyeon Ik Song, Katherine Fu, and David\\nRosen. Lda v. lsa: A comparison of two computational text analysis tools\\nfor the functional categorization of patents. In International Conference on\\nCase-Based Reasoning, 2016.\\n13. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert:\\nPre-training of deep bidirectional transformers for language understand-\\ning. arXiv preprint arXiv:1810.04805, 2018.\\n78'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 78, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='14. Giovanni Di Gennaro, Amedeo Buonanno, and Francesco AN Palmieri.\\nConsiderations about learning word2vec. The Journal of Supercomputing,\\npages 1–16, 2021.\\n15. Author Cory Doctorow.\\nPluralistic: Tiktok’s enshittification (21 jan\\n2023), Feb 2023. URL https://pluralistic.net/2023/01/21/potemkin-\\nai/#hey-guys.\\n16. Melody Dye, Chaitanya Ekandham, Avneesh Saluja, and Ashish Ras-\\ntogi.\\nSupporting content decision makers with machine learning,\\nDec 2020.\\nURL https://netflixtechblog.com/supporting-content-\\ndecision-makers-with-machine-learning-995b7b76006f.\\n17. Michael D Ekstrand and Joseph A Konstan. Recommender systems nota-\\ntion: proposed common notation for teaching and research. arXiv preprint\\narXiv:1902.01348, 2019.\\n18. Ahmed El-Kishky, Thomas Markovich, Serim Park, Chetan Verma, Baekjin\\nKim, Ramy Eskander, Yury Malkov, Frank Portman, Sofía Samaniego,\\nYing Xiao, et al. Twhin: Embedding the twitter heterogeneous information\\nnetwork for personalized recommendation. In Proceedings of the 28th\\nACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages\\n2842–2850, 2022.\\n19. Tobias Flach, Nandita Dukkipati, Andreas Terzis, Barath Raghavan, Neal\\nCardwell, Yuchung Cheng, Ankur Jain, Shuai Hao, Ethan Katz-Bassett,\\nand Ramesh Govindan. Reducing web latency: the virtue of gentle aggres-\\nsion. In Proceedings of the ACM SIGCOMM 2013 conference on SIGCOMM,\\npages 159–170, 2013.\\n20. Martin Fowler. Patterns of Enterprise Application Architecture: Pattern Enterpr\\nApplica Arch. Addison-Wesley, 2012.\\n21. Jan J Gerbrands. On the relationships between svd, klt and pca. Pattern\\nrecognition, 14(1-6):375–381, 1981.\\n22. David Goldberg, David Nichols, Brian M Oki, and Douglas Terry. Using\\ncollaborative filtering to weave an information tapestry. Communications\\nof the ACM, 35(12):61–70, 1992.\\n23. Yoav Goldberg and Omer Levy. word2vec explained: deriving mikolov\\net al.’s negative-sampling word-embedding method.\\narXiv preprint\\narXiv:1402.3722, 2014.\\n24. Raul Gomez Bruballa, Lauren Burnham-King, and Alessandra Sala. Learn-\\ning users’ preferred visual styles in an image marketplace. In Proceedings\\nof the 16th ACM Conference on Recommender Systems, pages 466–468, 2022.\\n25. Mihajlo Grbovic and Haibin Cheng. Real-time personalization using\\nembeddings for search ranking at airbnb. In Proceedings of the 24th ACM\\nSIGKDD international conference on knowledge discovery & data mining, pages\\n311–320, 2018.\\n79'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 79, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='26. Brendan Gregg. Systems performance: enterprise and the cloud. Pearson\\nEducation, 2014.\\n27. Casper Hansen, Christian Hansen, Lucas Maystre, Rishabh Mehrotra,\\nBrian Brost, Federico Tomasi, and Mounia Lalmas. Contextual and sequen-\\ntial user embeddings for large-scale music recommendation. In Proceedings\\nof the 14th ACM Conference on Recommender Systems, pages 53–62, 2020.\\n28. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and\\nTat-Seng Chua. Neural collaborative filtering. In Proceedings of the 26th\\ninternational conference on world wide web, pages 173–182, 2017.\\n29. Michael E Houle, Hans-Peter Kriegel, Peer Kröger, Erich Schubert, and\\nArthur Zimek. Can shared-neighbor distances defeat the curse of dimen-\\nsionality? In Scientific and Statistical Database Management: 22nd Interna-\\ntional Conference, SSDBM 2010, Heidelberg, Germany, June 30–July 2, 2010.\\nProceedings 22, pages 482–500. Springer, 2010.\\n30. Dietmar Jannach, Markus Zanker, Alexander Felfernig, and Gerhard\\nFriedrich. Recommender systems: an introduction. Cambridge University\\nPress, 2010.\\n31. Yushi Jing, David Liu, Dmitry Kislyuk, Andrew Zhai, Jiajing Xu, Jeff\\nDonahue, and Sarah Tavel. Visual search at pinterest. In Proceedings of\\nthe 21th ACM SIGKDD International Conference on Knowledge Discovery and\\nData Mining, pages 1889–1898, 2015.\\n32. Thorsten Joachims. Text categorization with support vector machines:\\nLearning with many relevant features. In Machine Learning: ECML-98: 10th\\nEuropean Conference on Machine Learning Chemnitz, Germany, April 21–23,\\n1998 Proceedings, pages 137–142. Springer, 2005.\\n33. Andrej Karpathy. The unreasonable effectiveness of recurrent neural\\nnetworks, May 2015. URL https://karpathy.github.io/2015/05/21/\\nrnn-effectiveness/.\\n34. P.N. Klein.\\nCoding the Matrix: Linear Algebra Through Applications to\\nComputer Science. Newtonian Press, 2013. ISBN 9780615880990. URL\\nhttps://books.google.com/books?id=3AA4nwEACAAJ.\\n35. Martin Kleppmann. Designing data-intensive applications: The big ideas\\nbehind reliable, scalable, and maintainable systems. \" O’Reilly Media, Inc.\",\\n2017.\\n36. Jay Kreps. I heart logs: Event data, stream processing, and data integration. \"\\nO’Reilly Media, Inc.\", 2014.\\n37. Dominik Kreuzberger, Niklas Kühl, and Sebastian Hirschl.\\nMachine\\nlearning operations (mlops): Overview, definition, and architecture. arXiv\\npreprint arXiv:2205.02302, 2022.\\n38. Giorgi Kvernadze, Putu Ayu G Sudyanti, Nishan Subedi, and Mohammad\\nHajiaghayi. Two is better than one: Dual embeddings for complementary\\nproduct recommendations. arXiv preprint arXiv:2211.14982, 2022.\\n80'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 80, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='39. Valliappa Lakshmanan, Sara Robinson, and Michael Munn.\\nMachine\\nlearning design patterns. O’Reilly Media, 2020.\\n40. Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-\\nbased learning applied to document recognition. Proceedings of the IEEE,\\n86(11):2278–2324, 1998.\\n41. Yann LeCun, Yoshua Bengio, Geoffrey Hinton, et al. Deep learning. nature,\\n521 (7553), 436-444. Google Scholar Google Scholar Cross Ref Cross Ref, page 25,\\n2015.\\n42. Jure Leskovec, Anand Rajaraman, and Jeffrey David Ullman. Mining of\\nmassive data sets. Cambridge university press, 2020.\\n43. Omer Levy and Yoav Goldberg. Neural word embedding as implicit\\nmatrix factorization. Advances in neural information processing systems, 27,\\n2014.\\n44. Xianjing Liu, Behzad Golshan, Kenny Leung, Aman Saini, Vivek Kulkarni,\\nAli Mollahosseini, and Jeff Mo. Twice-twitter content embeddings. In\\nCIKM 2022, 2022.\\n45. Donella H Meadows. Thinking in systems: A primer. chelsea green publish-\\ning, 2008.\\n46. Doug Meil. Ai in the enterprise. Communications of the ACM, 66(6):6–7,\\n2023.\\n47. Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient\\nestimation of word representations in vector space.\\narXiv preprint\\narXiv:1301.3781, 2013.\\n48. Usman Naseem, Imran Razzak, Shah Khalid Khan, and Mukesh Prasad.\\nA comprehensive survey on word representation models: From classical\\nto state-of-the-art word representation language models. Transactions on\\nAsian and Low-Resource Language Information Processing, 20(5):1–35, 2021.\\n49. Bogdan Oancea, Tudorel Andrei, and Raluca Mariana Dragoescu. Gpgpu\\ncomputing. arXiv preprint arXiv:1408.6923, 2014.\\n50. Aditya Pal, Chantat Eksombatchai, Yitong Zhou, Bo Zhao, Charles Rosen-\\nberg, and Jure Leskovec. Pinnersage: Multi-modal user embedding frame-\\nwork for recommendations at pinterest. In Proceedings of the 26th ACM\\nSIGKDD International Conference on Knowledge Discovery & Data Mining,\\npages 2311–2320, 2020.\\n51. Delip Rao and Brian McMahan. Natural language processing with PyTorch:\\nbuild intelligent language applications using deep learning. \" O’Reilly Media,\\nInc.\", 2019.\\n52. Steffen Rendle, Walid Krichene, Li Zhang, and John Anderson. Neural\\ncollaborative filtering vs. matrix factorization revisited. In Proceedings of\\nthe 14th ACM Conference on Recommender Systems, pages 240–248, 2020.\\n81'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 81, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='53. David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning\\nrepresentations by back-propagating errors. nature, 323(6088):533–536,\\n1986.\\n54. Alexander M Rush. The annotated transformer. In Proceedings of workshop\\nfor NLP open source software (NLP-OSS), pages 52–60, 2018.\\n55. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh,\\nSean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bern-\\nstein, et al. Imagenet large scale visual recognition challenge. International\\njournal of computer vision, 115:211–252, 2015.\\n56. Hinrich Schütze, Christopher D Manning, and Prabhakar Raghavan. In-\\ntroduction to information retrieval, volume 39. Cambridge University Press\\nCambridge, 2008.\\n57. David Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips,\\nDietmar Ebner, Vinay Chaudhary, and Michael Young. Machine learning:\\nThe high interest credit card of technical debt.(2014), 2014.\\n58. Nick Seaver. Computing Taste: Algorithms and the Makers of Music Recom-\\nmendation. University of Chicago Press, 2022.\\n59. Reza Shabani. How to train your own large language models, Apr 2023.\\nURL https://blog.replit.com/llm-training.\\n60. Christopher J Shallue, Jaehoon Lee, Joseph Antognini, Jascha Sohl-\\nDickstein, Roy Frostig, and George E Dahl. Measuring the effects of data\\nparallelism on neural network training. arXiv preprint arXiv:1811.03600,\\n2018.\\n61. Or Sharir, Barak Peleg, and Yoav Shoham. The cost of training nlp models:\\nA concise overview. arXiv preprint arXiv:2004.08900, 2020.\\n62. Dan Shiebler and Abhishek Tayal. Making machine learning easy with\\nembeddings. SysML http://www.sysml.cc/doc/115.pdf, 2010.\\n63. Adi Simhi and Shaul Markovitch. Interpreting embedding spaces by\\nconceptualization. arXiv preprint arXiv:2209.00445, 2022.\\n64. Harald Steck, Linas Baltrunas, Ehtsham Elahi, Dawen Liang, Yves Rai-\\nmond, and Justin Basilico. Deep learning for recommender systems: A\\nnetflix case study. AI Magazine, 42(3):7–18, 2021.\\n65. Krysta M Svore and Christopher JC Burges. A machine learning approach\\nfor improved bm25 retrieval. In Proceedings of the 18th ACM conference on\\nInformation and knowledge management, pages 1811–1814, 2009.\\n66. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\\nAidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you\\nneed. Advances in neural information processing systems, 30, 2017.\\n82'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 82, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='67. Bin Wang, Angela Wang, Fenxiao Chen, Yuncheng Wang, and C-C Jay\\nKuo. Evaluating word embedding models: Methods and experimental\\nresults. APSIPA transactions on signal and information processing, 8:e19, 2019.\\n68. Yuxuan Wang, Yutai Hou, Wanxiang Che, and Ting Liu. From static to\\ndynamic word representations: a survey. International Journal of Machine\\nLearning and Cybernetics, 11:1611–1630, 2020.\\n69. Christopher Wewer, Florian Lemmerich, and Michael Cochez.\\nUp-\\ndating embeddings for dynamic knowledge graphs.\\narXiv preprint\\narXiv:2109.10896, 2021.\\n70. Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Se-\\nbastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon\\nMann. Bloomberggpt: A large language model for finance. arXiv preprint\\narXiv:2303.17564, 2023.\\n71. Peng Xu, Xiatian Zhu, and David A Clifton. Multimodal learning with\\ntransformers: A survey. IEEE Transactions on Pattern Analysis and Machine\\nIntelligence, 2023.\\n72. Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L\\nHamilton, and Jure Leskovec. Graph convolutional neural networks for\\nweb-scale recommender systems. In Proceedings of the 24th ACM SIGKDD\\ninternational conference on knowledge discovery & data mining, pages 974–983,\\n2018.\\n73. Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. Deep learning based\\nrecommender system: A survey and new perspectives. ACM computing\\nsurveys (CSUR), 52(1):1–38, 2019.\\n74. Tianyi Zhang, Felix Wu, Arzoo Katiyar, Kilian Q Weinberger, and\\nYoav Artzi.\\nRevisiting few-sample bert fine-tuning.\\narXiv preprint\\narXiv:2006.05987, 2020.\\n75. Yong Zheng. Multi-stakeholder recommendation: Applications and chal-\\nlenges. arXiv preprint arXiv:1707.08913, 2017.\\n76. Martin Zinkevich. Rules of machine learning: Best practices for ml engi-\\nneering. URL: https://developers. google. com/machine-learning/guides/rules-of-\\nml, 2017.\\n83'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Object Detection\\nSihao Liang\\nJiajun Lu\\nKevin Perkins'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Overview\\nIntro\\nPart I: Two Stage Detection\\nPart II: Unified Detection\\nPart III: Others\\nSummary and comparison'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='What  is object detection\\nhttp://cs231n.stanford.edu/slides/winter1516_lecture8.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Terms\\nRecall\\nPrecision\\nmAP\\nIoU\\nhttps://en.wikipedia.org/wiki/Precision_and_recall'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 4, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Detection Competitions\\nPascal VOC\\nCOCO\\nImageNet ILSVRC\\nhttp://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html#introduction\\nCOCO: 200 classes \\nVOC: 20 classes'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 5, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Before Deep Learning\\nDeformable part models (DPM)\\n-\\nUses HOG features\\n-\\nVery fast\\nhttps://cs.brown.edu/~pff/papers/lsvm-pami.pdf\\nSliding windows.\\n-\\nScore every subwindow. \\nhttp://www.pyimagesearch.com/2014/11/10/histogram-oriented-gradients-object-detection/'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 6, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Selective Search\\nhttp://www.huppelen.nl/publications/selectiveSearchDraft.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 7, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Hard Negative Mining\\nImbalance between positive and negative examples.\\nUse negative examples with higher confidence score.\\nNon Maximum Suppression\\nIf output boxes overlap, only consider the most confident.'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 8, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Regression used to find bounding box parameters\\nApplied in one of two ways\\n-\\nBounding box refinement\\n-\\nComplete object detection\\nBounding Box Regression\\nI is the set of all matching bounding boxes (Highest IoU with ground truth)\\nExample Loss Function'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 9, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Two Stage Detection\\nPart I'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 10, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='RCNN : Region Proposal + CNN \\nUse selective search to come up with regional proposal\\nFirst object detection method using CNN\\n \\nRich feature hierarchies for accurate object detection and semantic segmentation\\nRoss Girshick Jeff Donahue Trevor Darrell Jitendra Malik\\nNov 2013\\nhttps://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 11, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='RCNN : \\nhttps://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 12, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Training RCNN\\nStep1: train your own CNN model for classification ( or use existing model), using \\nImageNet dataset.\\nConvolution \\nand Pooling\\nFully connected layer\\nSoftmax loss\\n4096 * 1000\\n1000 classes scores\\nImage source : http://www.shunvmall.com/bike-pic/47539009.html'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 13, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Training RCNN\\nStep2: focus on 20 classes + 1 background. Remove the last FC layer and replace it \\nwith a smaller layer and fine-tune the model using PASCAL VOC dataset\\nConvolution \\nand Pooling\\nFully connected layer\\nSoftmax loss\\n4096 * 21\\n21 classes scores'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 14, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Training RCNN\\nStep3: extract feature\\nImage\\nProposals\\nCrop & Warp\\nConvolution \\nand Pooling\\nStore all the features \\nafter pool 5 layer and \\nsave to disk\\nIt is about ~ 200G \\nfeatures'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 15, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Training RCNN\\nStep4: train SVM for each class\\nPositive \\nsamples for \\nMotorbike \\nNegative \\nsamples for \\nMotorbike \\nFeatures \\nfrom last \\nstep\\nCrop / \\nWarp \\nimage'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 16, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Training RCNN\\nStep4: train SVM for each class\\nNegative \\nsamples for \\nBicycle\\nPositive \\nsamples for \\nBicycle\\nFeatures \\nfrom last \\nstep\\nCrop / \\nWarp \\nimage'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 17, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Fast RCNN\\nShare convolution layers for proposals from the same image\\nFaster and More accurate than RCNN\\nROI Pooling\\nFast R-CNN\\nRoss Girshick\\nApr 2015\\nhttps://arxiv.org/pdf/1504.08083v2.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 18, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Fast RCNN\\nhttps://arxiv.org/pdf/1504.08083v2.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 19, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='RoI Pooling\\nimage\\nConv layer\\nDivided into \\nh * w region\\nMax pooling\\nDifferentiable'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 20, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='What is bbox-regressor?\\nBounding box regression\\nConvolution \\nand Pooling\\nFully connected layer\\nSoftmax loss\\nL2 loss\\nOR\\nL1 loss\\n4 value \\n(x,y,w,h)\\nOverfeat, VGG\\nDeepPose, R-CNN\\nTotal loss'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 21, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Convolution \\nand Pooling\\nFully connected layer\\nSoftmax loss\\nSmooth \\nL1 loss\\n4 value \\n(x,y,w,h)\\nTotal loss'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 22, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Result compare\\nTrained using VGG 16  on Pascal VOC 2007 dataset \\nNot including proposal time\\nSource: R. Girshick\\nFast R-CNN\\nR-CNN\\nTrain time (h)\\n9.5\\n84\\n-speedup\\n8.8x\\n1x\\nTest time/image\\n0.32s \\n47.00 s\\n-test speedup\\n146x\\n1x\\nmAP\\n66.9\\n66'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 23, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Result compare\\nSource: cs231 standford\\nFast R-CNN\\nR-CNN\\nTest time/image\\n0.32s \\n47.00 s\\n-test speedup\\n146x\\n1x\\nTest time/image with proposal\\n2s \\n50 s\\n-test speedup\\n25x\\n1x'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 24, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Don’t need to have external regional proposals\\nRPN - Regional Proposal Network \\nFaster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\\nShaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun\\nJun 2015\\nFaster RCNN\\nhttps://arxiv.org/pdf/1506.01497v3.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 25, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Faster RCNN\\nhttps://arxiv.org/pdf/1506.01497v3.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 26, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Faster RCNN\\nhttps://arxiv.org/pdf/1506.01497v3.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 27, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Result compare\\nTrained using Pascal VOC 2007 dataset \\nSource: cs231 standford\\nFaster R-CNN\\nFast R-CNN\\nR-CNN\\nTest time/image\\nWith proposal\\n0.2S\\n2s \\n50s\\n-test speedup\\n250x\\n25x\\n1x\\nmAP\\n66.9\\n66.9\\n66'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 28, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='R-FCN :Region-based Fully Convolutional \\nNetworks\\nhttps://arxiv.org/pdf/1605.06409v2.pdf\\nUse position sensitive score map\\nShare all conv and fc layers between all proposals for the same image\\nR-FCN: Object Detection via Region-based Fully Convolutional Networks\\nJifeng Dai, Yi Li, Kaiming He, Jian Sun\\nMay 2016'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 29, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='R-FCN\\nhttps://arxiv.org/pdf/1605.06409v2.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 30, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='R-FCN\\nhttps://arxiv.org/pdf/1605.06409v2.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 31, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='R-FCN\\nhttps://arxiv.org/pdf/1605.06409v2.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 32, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Methodologies Compare\\nTrained using ResNet 101\\nRCNN\\nFaster RCNN\\nRFCN\\nDepth of shared \\nconvolutional \\nsubnetwork\\n0\\n91\\n101\\nDepth of ROI-wise \\nsubnetwork\\n101\\n10\\n0'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 33, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Result compare\\nTrained using ResNet 101 on Pascal VOC 2007 dataset\\nFaster R-CNN\\nR-FCN\\nTest time/image\\nWith proposal\\n0.42S\\n0.2s \\nmAP\\n76.4\\n76.6'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 34, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Unified Detection\\nPart II'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 35, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Problems with 2 step detection.\\nComplex Pipeline\\nSlow (Cannot run in real time)\\nHard to optimize each component'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 36, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Yolo: You Only Look Once\\nConsider detection a regression problem\\nUse a single ConvNet\\nRuns once on entire image. Very Fast!\\nYou only look once: Unified, real-time object detection. \\nJoseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi\\nJune 2015'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 37, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='How it works\\nThe following predictions are made for each cell in an S x S grid.\\nC conditional class probabilities Pr(Classi | Obj)\\nB bounding boxes (4 parameters each)\\nB confidence scores Pr(Obj)*IoU\\nOutput is S x S  x (5B+C) tensor\\nhttps://arxiv.org/pdf/1506.02640v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 38, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Architecture\\nhttps://arxiv.org/pdf/1506.02640v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 39, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Performance (VOC 2007) \\nhttps://arxiv.org/pdf/1506.02640v5.pdf\\nYolo\\nFaster R-CNN (VGG-16)\\nmAP\\n63.4\\n73.2\\nFPS\\n45\\n7\\nTrained on Pascal VOC 2007 + 2012 dataset'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 40, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Limitations of Yolo\\nStruggles with small objects\\nStruggles with unusual aspect ratios\\nPoor localization'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 41, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='SSD Single Shot Detector\\nFaster than Yolo, as accurate as Faster R-CNN\\nPredicts categories and box offsets\\nUses small convolutional filters applied to feature maps\\nMakes predictions using feature maps of different scales\\nSSD: Single shot multibox detector\\nWei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander \\nC. Berg \\nDec 2015'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 42, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Comparison to Yolo\\nhttps://arxiv.org/pdf/1512.02325v5.pdf\\nSSD\\nYolo'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 43, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Default Boxes\\nMultiple aspect ratios per cell.\\nSimilar to Faster R-CNN Anchor Boxes.\\n-\\nApplied to many feature maps.\\nhttps://arxiv.org/pdf/1512.02325v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 44, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='SSD Detector\\nDetectors are convolutional filters.\\nEach detector outputs a single value.\\nPredict class probabilities.\\nPredict bounding box offsets.\\n(classes + 4) detectors are needed for a detection.\\n(classes + 4) x (#default boxes) x m x n outputs for a mxn feature map.'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 45, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Results (VOC 2007)\\nhttps://arxiv.org/pdf/1512.02325v5.pdf\\nSSD*\\nYolo*\\nFaster R-CNN*\\nmAP\\n74.3\\n66.4\\n73.2\\nFPS\\n46\\n21\\n7\\n*VGG16\\nTrained on Pascal VOC 2007 + 2012 dataset'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 46, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Others\\nPart III'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 47, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Feature Pyramid Networks\\nUses ConvNet as Feature Pyramid\\nIncludes low level feature maps to detect small objects\\nTop down pathway provides contextual information\\nFeature Pyramid Networks for Object Detection. \\nTsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie.\\nDec 2016'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 48, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Comparison to prior methods\\na.\\nAccurate but slow.\\nb.\\nMisses low level \\ninformation. (Yolo)\\nc.\\nMisses context in low \\nlevel predictions. \\n(SSD)\\nd.\\nAccurate and fast.\\nhttps://arxiv.org/pdf/1512.02325v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 49, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Top down pathway\\n-\\nHigh level (semantically strong) \\nfeature maps are upsampled. \\n-\\nLateral connections merge \\nfeature maps from bottom up \\npathway. \\nhttps://arxiv.org/pdf/1512.02325v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 50, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Feature Pyramid Networks for RPN\\n-\\nReplace single scale feature \\nmap with FPN.\\n-\\nSingle scale anchors at each \\nlevel.\\nhttps://arxiv.org/pdf/1512.02325v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 51, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Results\\n-\\nCOCO\\n-\\nState of the art single-model\\nhttps://arxiv.org/pdf/1512.02325v5.pdf\\nFaster R-CNN on FPN*\\nFaster R-CNN +++*\\nION**\\nmAP\\n36.2\\n34.9\\n31.2\\nmAP (small images)\\n18.2\\n15.6\\n12.8\\n* ResNet-101\\n** VGG-16'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 52, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='ION : Inside-Outside Network\\nUse multi-scale Conv features for inside region\\nUse four direction RNN features for outside region\\n \\nInside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks\\nSean Bell, C.Lawrence Zitnick, Kavita Bala, Ross Girshick\\nCornell University, Microsoft Research\\nCVPR 2016\\nhttps://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 53, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='ION: Inside-Outside Net\\n                                              https://www.robots.ox.ac.uk/~vgg/rg/slides/ion-coco.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 54, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content=''),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 55, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content=''),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 56, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Uses RNNs to capture context info from outside bounding box.'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 57, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Stack 2 RNNs together'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 58, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='ION: Inside-Outside Net\\nMain Changes:\\n-\\nInside: Skip connection with L2 normalization\\n-\\nOutside: Stacked 4-direction RNNs for context'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 59, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Results (VOC 2007)\\n                                              https://www.robots.ox.ac.uk/~vgg/rg/slides/ion-coco.pdf\\nTrained on Pascal VOC 2007 + 2012 dataset'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 60, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Summary and Comparison\\nPart IV'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 61, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Speed / Accuracy Trade-off\\nUnified tensorflow architecture\\nCompare speed, accuracy and memory usage\\n \\nSpeed/Accuracy trade-offs for modern convolutional object detectors\\nJonathan Huang, Kevin Murphy et al.\\nNov 2016\\nhttps://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 62, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Same Architectures\\n                                                                                       https://pan.baidu.com/s/1pKIKIIB\\nFeature \\nExtractor\\nFaster \\nRCNN\\nR-FCN\\nSSD\\nSpeed\\nAccuracy\\nMemory\\n...'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 63, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Recap: Faster RCNN\\n                                                                                       https://pan.baidu.com/s/1pKIKIIB'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 64, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Recap: R-FCN\\n                                                                                       https://pan.baidu.com/s/1pKIKIIB'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 65, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Recap: SSD\\n                                                                                       https://pan.baidu.com/s/1pKIKIIB'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 66, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Accuracy VS Speed'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 67, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='1. Different Feature Extractor'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 68, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='2. Detect Object Size'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 69, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='3. Image Resolution'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 70, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='4. Region Proposal Number'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 71, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='5. GPU Time'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 72, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='6. Memory'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 73, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Summary\\n●\\nSpeed First: SSD\\n●\\nBalance Speed and Accuracy:  R-FCN\\n●\\nAccuracy First: Faster RCNN (Reduce proposals, it can speed up a lot with \\nsome accuracy loss)'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 74, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Thanks!\\nQuestions?'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 75, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content=''),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 76, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='References\\nGirshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra, Rich feature hierarchies for accurate object detection and semantic segmentation, CVPR 2014\\nHe, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian, Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition, ECCV 2014\\nGirshick, Ross, Fast R-CNN, ICCV 2015\\nRen, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian, Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks, CVPR 2015\\nJifeng Dai, Yi Li, Kaiming He, Jian Sun R-FCN: Object Detection via Region-based Fully Convolutional Networks, NIPS 2016\\nErhan, Dumitru and Szegedy, Christian and Toshev, Alexander and Anguelov, Dragomir, Scalable Object Detection using Deep Neural Networks, CVPR 2014\\nBell, Sean and Lawrence Zitnick, C and Bala, Kavita and Girshick, Ross, Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks, CVPR 2016\\nRedmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali, You Only Look Once: Unified, Real-Time Object Detection, CVPR 2016\\nLiu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C, SSD: Single Shot MultiBox Detector, ECCV \\n2016\\nTsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie, Feature Pyramid Networks for Object Detection, arXiv 2016\\nHuang, Jonathan and Rathod, Vivek and Sun, Chen and Zhu, Menglong and Korattikara, Anoop and Fathi, Alireza and Fischer, Ian and Wojna, Zbigniew and Song, Yang and \\nGuadarrama, Sergio and others,Speed/accuracy trade-offs for modern convolutional object detectors, arXiv 2016'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 77, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Bonus Material\\nPart V'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 78, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Yolo v2 Faster, Better Stronger'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 79, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Performance on  MS COCO \\n         Method                    Data                      IoU                      Area                  #Dets                 Area\\nAvg. Precision\\nAvg. Recall'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 80, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Fast RCNN vs Faster RCNN'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 81, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='SPP-Net\\nhttps://arxiv.org/pdf/1406.4729v4.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 82, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='SPP-Net\\nConvolution \\nand Pooling\\nFully connected layer\\nSoftmax loss\\nSoftmax loss\\nSPP pooling to a fix length \\nlayer (max pooling)\\nCrop & Warp'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 83, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='SPP-Net\\nhttps://arxiv.org/pdf/1406.4729v4.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 84, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Multi-Box'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 85, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Multi-Box\\nGoal: Achieve a class-agnostic scalable object detection by predicting a set of \\nbounding boxes.\\nTrain a neural network to directly predict: \\n-\\nThe upper-left and lower-right coordinates of each bounding box\\n-\\nThe confidence score for the box containing an object'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 86, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Train Objective\\nProduce fixed number of bounding boxes with confidence, such as K=100 or 200.'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 87, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Number of Windows')]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_pdf_documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9e189aa8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text splitting into chunks\n",
        "\n",
        "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        length_function=len,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "    )\n",
        "    split_docs = text_splitter.split_documents(documents)\n",
        "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks.\")\n",
        "\n",
        "    if split_docs:\n",
        "        print(f\"\\nExample chunk:\")\n",
        "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
        "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
        "\n",
        "    return split_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "76a06c5a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split 182 documents into 371 chunks.\n",
            "\n",
            "Example chunk:\n",
            "Content: Attention Is All You Need\n",
            "Ashish Vaswani∗\n",
            "Google Brain\n",
            "avaswani@google.com\n",
            "Noam Shazeer∗\n",
            "Google Brain\n",
            "noam@google.com\n",
            "Niki Parmar∗\n",
            "Google Research\n",
            "nikip@google.com\n",
            "Jakob Uszkoreit∗\n",
            "Google Research\n",
            "usz...\n",
            "Metadata: {'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 0, 'source_file': 'attention.pdf', 'file_type': 'pdf'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 0, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 0, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='entirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1\\nIntroduction\\nRecurrent neural networks, long short-term memory [12] and gated recurrent [7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [29, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 0, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='transduction problems such as language modeling and machine translation [29, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 0, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='efﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 1, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Recurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsigniﬁcant improvements in computational efﬁciency through factorization tricks [18] and conditional\\ncomputation [26], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 1, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 16]. In all but a few cases [22], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2\\nBackground\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[20], ByteNet [15] and ConvS2S [8], all of which use convolutional neural networks as basic building'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 1, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[20], ByteNet [15] and ConvS2S [8], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difﬁcult to learn dependencies between distant positions [11]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 1, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='described in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 22, 23, 19].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [28].\\nTo the best of our knowledge, however, the Transformer is the ﬁrst transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 1, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [14, 15] and [8].\\n3\\nModel Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 29].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\\n[9], consuming the previously generated symbols as additional input when generating the next.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1\\nEncoder and Decoder Stacks\\nEncoder:'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 1, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1\\nEncoder and Decoder Stacks\\nEncoder:\\nThe encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position-\\n2'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 2, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Figure 1: The Transformer - model architecture.\\nwise fully connected feed-forward network. We employ a residual connection [10] around each of\\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder:\\nThe decoder is also composed of a stack of N = 6 identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 2, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='around each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3.2\\nAttention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1\\nScaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\n3'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 3, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Scaled Dot-Product Attention\\nMulti-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V ) = softmax(QKT\\n√dk\\n)V\\n(1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof\\n1\\n√dk . Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 3, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='1\\n√dk . Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efﬁcient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by\\n1\\n√dk .\\n3.2.2\\nMulti-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneﬁcial to linearly project the queries, keys and values h times with different, learned'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 3, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='we found it beneﬁcial to linearly project the queries, keys and values h times with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\noutput values. These are concatenated and once again projected, resulting in the ﬁnal values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = Pdk\\ni=1 qiki, has mean 0 and variance dk.\\n4'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 4, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='MultiHead(Q, K, V ) = Concat(head1, ..., headh)W O\\nwhere headi = Attention(QW Q\\ni , KW K\\ni , V W V\\ni )\\nWhere the projections are parameter matrices W Q\\ni\\n∈Rdmodel×dk, W K\\ni\\n∈Rdmodel×dk, W V\\ni\\n∈Rdmodel×dv\\nand W O ∈Rhdv×dmodel.\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3\\nApplications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[31, 2, 8].'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 4, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='position in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[31, 2, 8].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation ﬂow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3\\nPosition-wise Feed-Forward Networks'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 4, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='of the softmax which correspond to illegal connections. See Figure 2.\\n3.3\\nPosition-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0, xW1 + b1)W2 + b2\\n(2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4\\nEmbeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 4, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Similarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [24]. In the embedding layers, we multiply those weights by √dmodel.\\n3.5\\nPositional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\n5'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 5, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\\nLayer Type\\nComplexity per Layer\\nSequential\\nMaximum Path Length\\nOperations\\nSelf-Attention\\nO(n2 · d)\\nO(1)\\nO(1)\\nRecurrent\\nO(n · d2)\\nO(n)\\nO(n)\\nConvolutional\\nO(k · n · d2)\\nO(1)\\nO(logk(n))\\nSelf-Attention (restricted)\\nO(r · n · d)\\nO(1)\\nO(n/r)\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and ﬁxed [8].\\nIn this work, we use sine and cosine functions of different frequencies:\\nPE(pos,2i) = sin(pos/100002i/dmodel)\\nPE(pos,2i+1) = cos(pos/100002i/dmodel)\\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 5, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='PE(pos,2i) = sin(pos/100002i/dmodel)\\nPE(pos,2i+1) = cos(pos/100002i/dmodel)\\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any ﬁxed offset k, PEpos+k can be represented as a linear function of\\nPEpos.\\nWe also experimented with using learned positional embeddings [8] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4\\nWhy Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 5, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='during training.\\n4\\nWhy Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 5, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='dependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [11]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\nlength n is smaller than the representation dimensionality d, which is most often the case with'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 5, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='computational complexity, self-attention layers are faster than recurrent layers when the sequence\\nlength n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[31] and byte-pair [25] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\\n6'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 6, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='the input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k < n does not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [15], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [6], however, decrease the complexity\\nconsiderably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 6, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='convolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side beneﬁt, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5\\nTraining\\nThis section describes the training regime for our models.\\n5.1\\nTraining Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 6, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='target vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [31]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2\\nHardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3\\nOptimizer\\nWe used the Adam optimizer [17] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\\nrate over the course of training, according to the formula:'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 6, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='(3.5 days).\\n5.3\\nOptimizer\\nWe used the Adam optimizer [17] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate = d−0.5\\nmodel · min(step_num−0.5, step_num · warmup_steps−1.5)\\n(3)\\nThis corresponds to increasing the learning rate linearly for the ﬁrst warmup_steps training steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps = 4000.\\n5.4\\nRegularization\\nWe employ three types of regularization during training:\\nResidual Dropout\\nWe apply dropout [27] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\n7'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 7, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU\\nTraining Cost (FLOPs)\\nEN-DE\\nEN-FR\\nEN-DE\\nEN-FR\\nByteNet [15]\\n23.75\\nDeep-Att + PosUnk [32]\\n39.2\\n1.0 · 1020\\nGNMT + RL [31]\\n24.6\\n39.92\\n2.3 · 1019\\n1.4 · 1020\\nConvS2S [8]\\n25.16\\n40.46\\n9.6 · 1018\\n1.5 · 1020\\nMoE [26]\\n26.03\\n40.56\\n2.0 · 1019\\n1.2 · 1020\\nDeep-Att + PosUnk Ensemble [32]\\n40.4\\n8.0 · 1020\\nGNMT + RL Ensemble [31]\\n26.30\\n41.16\\n1.8 · 1020\\n1.1 · 1021\\nConvS2S Ensemble [8]\\n26.36\\n41.29\\n7.7 · 1019\\n1.2 · 1021\\nTransformer (base model)\\n27.3\\n38.1\\n3.3 · 1018\\nTransformer (big)\\n28.4\\n41.0\\n2.3 · 1019\\nLabel Smoothing\\nDuring training, we employed label smoothing of value ϵls = 0.1 [30]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6\\nResults\\n6.1\\nMachine Translation'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 7, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='hurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6\\nResults\\n6.1\\nMachine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The conﬁguration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 7, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='previous state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty α = 0.6 [31]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [31].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of ﬂoating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision ﬂoating-point capacity of each GPU 5.\\n6.2\\nModel Variations'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 7, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='model by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision ﬂoating-point capacity of each GPU 5.\\n6.2\\nModel Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 8, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN\\ndmodel\\ndff\\nh\\ndk\\ndv\\nPdrop\\nϵls\\ntrain\\nPPL\\nBLEU\\nparams\\nsteps\\n(dev)\\n(dev)\\n×106\\nbase\\n6\\n512\\n2048\\n8\\n64\\n64\\n0.1\\n0.1\\n100K\\n4.92\\n25.8\\n65\\n(A)\\n1\\n512\\n512\\n5.29\\n24.9\\n4\\n128\\n128\\n5.00\\n25.5\\n16\\n32\\n32\\n4.91\\n25.8\\n32\\n16\\n16\\n5.01\\n25.4\\n(B)\\n16\\n5.16\\n25.1\\n58\\n32\\n5.01\\n25.4\\n60\\n(C)\\n2\\n6.11\\n23.7\\n36\\n4\\n5.19\\n25.3\\n50\\n8\\n4.88\\n25.5\\n80\\n256\\n32\\n32\\n5.75\\n24.5\\n28\\n1024\\n128\\n128\\n4.66\\n26.0\\n168\\n1024\\n5.12\\n25.4\\n53\\n4096\\n4.75\\n26.2\\n90\\n(D)\\n0.0\\n5.77\\n24.6\\n0.2\\n4.95\\n25.5\\n0.0\\n4.67\\n25.3\\n0.2\\n5.47\\n25.7\\n(E)\\npositional embedding instead of sinusoids\\n4.92\\n25.7\\nbig\\n6\\n1024\\n4096\\n16\\n0.3\\n300K\\n4.33\\n26.4\\n213\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 8, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='(E)\\npositional embedding instead of sinusoids\\n4.92\\n25.7\\nbig\\n6\\n1024\\n4096\\n16\\n0.3\\n300K\\n4.33\\n26.4\\n213\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneﬁcial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-ﬁtting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [8], and observe nearly identical\\nresults to the base model.\\n7\\nConclusion\\nIn this work, we presented the Transformer, the ﬁrst sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 8, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='multi-headed self-attention.\\nFor translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efﬁciently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements\\nWe are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 8, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='tensorflow/tensor2tensor.\\nAcknowledgements\\nWe are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\n9'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 9, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='References\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 9, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='machine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[9] Alex Graves.\\nGenerating sequences with recurrent neural networks.\\narXiv preprint\\narXiv:1308.0850, 2013.\\n[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770–778, 2016.\\n[11] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient ﬂow in'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 9, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Recognition, pages 770–778, 2016.\\n[11] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient ﬂow in\\nrecurrent nets: the difﬁculty of learning long-term dependencies, 2001.\\n[12] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735–1780, 1997.\\n[13] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[14] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[15] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[16] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 9, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='2017.\\n[16] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[17] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[18] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[19] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[20] Samy Bengio Łukasz Kaiser. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n10'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 10, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='[21] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n[22] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing, 2016.\\n[23] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[24] Oﬁr Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[25] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[26] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 10, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.\\n[27] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overﬁtting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.\\n[28] Sainbayar Sukhbaatar, arthur szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\\nInc., 2015.\\n[29] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[30] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 10, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='networks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[30] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\\n[31] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.\\n[32] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n11'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 0, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='What are embeddings\\nVicki Boykis'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 1, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Abstract\\nOver the past decade, embeddings — numerical representations of\\nmachine learning features used as input to deep learning models — have\\nbecome a foundational data structure in industrial machine learning\\nsystems. TF-IDF, PCA, and one-hot encoding have always been key tools\\nin machine learning systems as ways to compress and make sense of\\nlarge amounts of textual data. However, traditional approaches were\\nlimited in the amount of context they could reason about with increasing\\namounts of data. As the volume, velocity, and variety of data captured\\nby modern applications has exploded, creating approaches specifically\\ntailored to scale has become increasingly important.\\nGoogle’s Word2Vec paper made an important step in moving from\\nsimple statistical representations to semantic meaning of words. The\\nsubsequent rise of the Transformer architecture and transfer learning, as\\nwell as the latest surge in generative methods has enabled the growth'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 1, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='subsequent rise of the Transformer architecture and transfer learning, as\\nwell as the latest surge in generative methods has enabled the growth\\nof embeddings as a foundational machine learning data structure. This\\nsurvey paper aims to provide a deep dive into what embeddings are,\\ntheir history, and usage patterns in industry.\\nColophon\\nThis paper is typeset with LATEX. The cover art is Kandinsky’s \"Circles in a\\nCircle\" , 1923. ChatGPT was used to generate some of the figures.\\nCode, LATEX, and Website\\nThe latest version of the paper and code examples are available here. The\\nwebsite for this project is here.\\nAbout the Author\\nVicki Boykis is a machine learning engineer. Her website is vickiboykis.com\\nand her semantic search side project is viberary.pizza.\\nAcknowledgements\\nI’m grateful to everyone who has graciously offered technical feedback but\\nespecially to Nicola Barbieri, Peter Baumgartner, Luca Belli, James Kirk, and'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 1, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Acknowledgements\\nI’m grateful to everyone who has graciously offered technical feedback but\\nespecially to Nicola Barbieri, Peter Baumgartner, Luca Belli, James Kirk, and\\nRavi Mody. All remaining errors, typos, and bad jokes are mine. Thank you to\\nDan for your patience, encouragement, for parenting while I was in the latent\\nspace, and for once casually asking, \"How do you generate these ’embeddings’,\\nanyway?\"\\nLicense\\nThis work is licensed under a Creative Commons\\n“Attribution-NonCommercial-ShareAlike 3.0 Un-\\nported” license.\\n2'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 2, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Contents\\n1\\nIntroduction\\n4\\n2\\nRecommendation as a business problem\\n9\\n2.1\\nBuilding a web app . . . . . . . . . . . . . . . . . . . . . . . . .\\n11\\n2.2\\nRules-based systems versus machine learning\\n. . . . . . . . .\\n13\\n2.3\\nBuilding a web app with machine learning\\n. . . . . . . . . . .\\n15\\n2.4\\nFormulating a machine learning problem . . . . . . . . . . . .\\n17\\n2.4.1\\nThe Task of Recommendations . . . . . . . . . . . . . .\\n20\\n2.4.2\\nMachine learning features . . . . . . . . . . . . . . . . .\\n22\\n2.5\\nNumerical Feature Vectors . . . . . . . . . . . . . . . . . . . . .\\n23\\n2.6\\nFrom Words to Vectors in Three Easy Pieces . . . . . . . . . . .\\n24\\n3\\nHistorical Encoding Approaches\\n25\\n3.1\\nEarly Approaches . . . . . . . . . . . . . . . . . . . . . . . . . .\\n26\\n3.2\\nEncoding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n26\\n3.2.1\\nIndicator and one-hot encoding . . . . . . . . . . . . . .\\n27\\n3.2.2\\nTF-IDF . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n31\\n3.2.3'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 2, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='26\\n3.2.1\\nIndicator and one-hot encoding . . . . . . . . . . . . . .\\n27\\n3.2.2\\nTF-IDF . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n31\\n3.2.3\\nSVD and PCA . . . . . . . . . . . . . . . . . . . . . . . .\\n37\\n3.3\\nLDA and LSA . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n38\\n3.4\\nLimitations of traditional approaches . . . . . . . . . . . . . . .\\n39\\n3.4.1\\nThe curse of dimensionality . . . . . . . . . . . . . . . .\\n39\\n3.4.2\\nComputational complexity\\n. . . . . . . . . . . . . . . .\\n40\\n3.5\\nSupport Vector Machines . . . . . . . . . . . . . . . . . . . . . .\\n41\\n3.6\\nWord2Vec . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n42\\n4\\nModern Embeddings Approaches\\n50\\n4.1\\nNeural Networks . . . . . . . . . . . . . . . . . . . . . . . . . .\\n51\\n4.1.1\\nNeural Network architectures . . . . . . . . . . . . . . .\\n51\\n4.2\\nTransformers . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n53\\n4.2.1\\nEncoders/Decoders and Attention . . . . . . . . . . . .\\n54\\n4.3'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 2, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='51\\n4.2\\nTransformers . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n53\\n4.2.1\\nEncoders/Decoders and Attention . . . . . . . . . . . .\\n54\\n4.3\\nBERT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n59\\n4.4\\nGPT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n60\\n5\\nEmbeddings in Production\\n60\\n5.1\\nEmbeddings in Practice\\n. . . . . . . . . . . . . . . . . . . . . .\\n62\\n5.1.1\\nPinterest . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n62\\n5.1.2\\nYouTube and Google Play Store . . . . . . . . . . . . . .\\n63\\n5.1.3\\nTwitter . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n66\\n5.2\\nEmbeddings as an Engineering Problem . . . . . . . . . . . . .\\n69\\n5.2.1\\nEmbeddings Generation . . . . . . . . . . . . . . . . . .\\n71\\n5.2.2\\nStorage and Retrieval\\n. . . . . . . . . . . . . . . . . . .\\n72\\n5.2.3\\nDrift Detection, Versioning, and Interpretability . . . .\\n74\\n5.2.4\\nInference and Latency . . . . . . . . . . . . . . . . . . .\\n75\\n5.2.5'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 2, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='. . . . . . . . . . . . . . . . . . .\\n72\\n5.2.3\\nDrift Detection, Versioning, and Interpretability . . . .\\n74\\n5.2.4\\nInference and Latency . . . . . . . . . . . . . . . . . . .\\n75\\n5.2.5\\nOnline and Offline Model Evaluation . . . . . . . . . .\\n76\\n5.2.6\\nWhat makes embeddings projects successful . . . . . .\\n76\\n6\\nConclusion\\n76\\n3'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 3, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nIntroduction\\nImplementing deep learning models has become an increasingly important\\nmachine learning strategy1 for companies looking to build data-driven prod-\\nucts. In order to build and power deep learning models, companies collect and\\nfeed hundreds of millions of terabytes of multimodal2 data into deep learning\\nmodels. As a result, embeddings — deep learning models’ internal represen-\\ntations of their input data — are quickly becoming a critical component of\\nbuilding machine learning systems.\\nFor example, they make up a significant part of Spotify’s item recom-\\nmender systems [27], YouTube video recommendations of what to watch [11],\\nand Pinterest’s visual search [31]. Even if they are not explicitly presented\\nto the user through recommendation system UIs, embeddings are also used\\ninternally at places like Netflix to make content decisions around which shows\\nto develop based on user preference popularity.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 3, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='to the user through recommendation system UIs, embeddings are also used\\ninternally at places like Netflix to make content decisions around which shows\\nto develop based on user preference popularity.\\nFigure 1: Left to right: Products that use embeddings used to generate recommended items:\\nSpotify Radio, YouTube Video recommendations, visual recommendations at Pinterest, BERT\\nEmbeddings in suggested Google search results\\nThe usage of embeddings to generate compressed, context-specific repre-\\nsentations of content exploded in popularity after the publication of Google’s\\nWord2Vec paper [47].\\n1Check out the machine learning industrial view Matt Turck puts together every year, which\\nhas exploded in size.\\n2Multimodal means a variety of data usually including text, video, audio, and more recently\\nas shown in Meta’s ImageBind, depth, thermal, and IMU.\\n4'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 4, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 2: Embeddings papers in arXiv by month. It’s interesting to note the decline in\\nfrequency of embeddings-specific papers, possibly in tandem with the rise of deep learning\\narchitectures like GPT source\\nBuilding and expanding on the concepts in Word2Vec, the Transformer\\n[66] architecture, with its self-attention mechanism, a much more specialized\\ncase of calculating context around a given word, has become the de-facto\\nway to learn representations of growing multimodal vocabularies, and its rise\\nin popularity both in academia and in industry has caused embeddings to\\nbecome a staple of deep learning workflows.\\nHowever, the concept of embeddings can be elusive because they’re neither\\ndata flow inputs or output results - they are intermediate elements that live\\nwithin machine learning services to refine models. So it’s helpful to define\\nthem explicitly from the beginning.\\nAs a general definition, embeddings are data that has been transformed'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 4, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='within machine learning services to refine models. So it’s helpful to define\\nthem explicitly from the beginning.\\nAs a general definition, embeddings are data that has been transformed\\ninto n-dimensional matrices for use in deep learning computations. The\\nprocess of embedding (as a verb):\\n• Transforms multimodal input into representations that are easier to\\nperform intensive computation on, in the form of vectors, tensors, or\\ngraphs [51]. For the purpose of machine learning, we can think of\\nvectors as a list (or array) of numbers.\\n• Compresses input information for use in a machine learning task — the\\ntype of methods available to us in machine learning to solve specific\\nproblems — such as summarizing a document or identifying tags or\\nlabels for social media posts or performing semantic search on a large\\ntext corpus. The process of compression changes variable feature\\ndimensions into fixed inputs, allowing them to be passed efficiently'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 4, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='text corpus. The process of compression changes variable feature\\ndimensions into fixed inputs, allowing them to be passed efficiently\\ninto downstream components of machine learning systems.\\n• Creates an embedding space that is specific to the data the embeddings\\nwere trained on but that, in the case of deep learning representations,\\ncan also generalize to other tasks and domains through transfer\\nlearning — the ability to switch contexts — which is one of the\\nreasons embeddings have exploded in popularity across machine\\nlearning applications\\n5'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 5, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='What do embeddings actually look like? Here is one single embedding,\\nalso called a vector, in three dimensions. We can think of this as a repre-\\nsentation of a single element in our dataset. For example, this hypothetical\\nembedding represents a single word \"fly\", in three dimensions. Generally, we\\nrepresent individual embeddings as row vectors.\\n\\x02\\n1\\n4\\n9\\n\\x03\\n(1)\\nAnd here is a tensor, also known as a matrix3, which is a multidimensional\\ncombination of vector representations of multiple elements. For example, this\\ncould be the representation of \"fly\", and \"bird.\"\\n\\x141\\n4\\n9\\n4\\n5\\n6\\n\\x15\\n(2)\\nThese embeddings are the output of the process of learning embeddings,\\nwhich we do by passing raw input data into a machine learning model. We\\ntransform that multidimensional input data by compressing it, through the\\nalgorithms we discuss in this paper, into a lower-dimensional space. The\\nresult is a set of vectors in an embedding space.\\nWord\\nSentence\\nImage\\nMultimodal data\\n[1, 4, 9]\\n[1, 4, 7]\\n[12, 0, 3]'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 5, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='algorithms we discuss in this paper, into a lower-dimensional space. The\\nresult is a set of vectors in an embedding space.\\nWord\\nSentence\\nImage\\nMultimodal data\\n[1, 4, 9]\\n[1, 4, 7]\\n[12, 0, 3]\\nEmbedding Space\\nAlgorithm\\nFigure 3: The process of embedding.\\nWe often talk about item embeddings being in X dimensions, ranging\\nanywhere from 100 to 1000, with diminishing returns in usefulness somewhere\\nbeyond 768 in the context of using them for machine learning problems4. This\\nmeans that each item (image, song, word, etc) is represented by a vector of\\nlength X, where each value is a coordinate in an X-dimensional space. For\\nmore on growing embedding context sizes, see this addendum post written in\\n2025.\\nWe just made up an embedding for \"bird\", but let’s take a look at what a\\nreal one for the word \"hold\" would look like in the quote, as generated by the\\nBERT deep learning model,\\n\"Hold fast to dreams, for if dreams die, life is a broken-winged bird that\\ncannot fly.\" — Langston Hughes'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 5, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='BERT deep learning model,\\n\"Hold fast to dreams, for if dreams die, life is a broken-winged bird that\\ncannot fly.\" — Langston Hughes\\nWe’ve highlighted this quote because we’ll be working with this sentence\\nas our input example throughout this text.\\n3The difference between a matrix and a tensor is that it’s a matrix if you’re doing linear\\nalgebra and a tensor if you’re an AI researcher.\\n4Embedding size is tunable as a hyperparameter but so far there have only been a few\\npapers on optimal embedding size, with most of the size of embeddings set through magic and\\nguesswork\\n6'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 6, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nimport torch\\n2\\nfrom transformers import BertTokenizer, BertModel\\n3\\n4\\n# Load pre-trained model tokenizer (vocabulary)\\n5\\ntokenizer = BertTokenizer.from_pretrained(\\'bert-base-uncased\\')\\n6\\n7\\ntext = \"\"\"Hold fast to dreams, for if dreams die, life is a broken-winged bird\\nthat cannot fly.\"\"\"\\n,→\\n8\\n9\\n# Tokenize the sentence with the BERT tokenizer.\\n10\\ntokenized_text = tokenizer.tokenize(text)\\n11\\n12\\n# Print out the tokens.\\n13\\nprint (tokenized_text)\\n14\\n15\\n[\\'[CLS]\\', \\'hold\\', \\'fast\\', \\'to\\', \\'dreams\\', \\',\\', \\'for\\', \\'if\\', \\'dreams\\', \\'die\\',\\n\\',\\', \\'life\\', \\'is\\', \\'a\\', \\'broken\\', \\'-\\', \\'winged\\', \\'bird\\', \\'that\\', \\'cannot\\',\\n\\'fly\\', \\'.\\', \\'[SEP]\\']\\n,→\\n,→\\n16\\n17\\n# BERT code truncated to show the final output, an embedding\\n18\\n19\\n[tensor([-3.0241e-01, -1.5066e+00, -9.6222e-01,\\n1.7986e-01, -2.7384e+00,\\n20\\n-1.6749e-01,\\n7.4106e-01,\\n1.9655e+00,\\n4.9202e-01,\\n-2.0871e+00,\\n,→\\n21\\n-5.8469e-01,\\n1.5016e+00,\\n8.2666e-01,\\n8.7033e-01,\\n8.5101e-01,\\n,→\\n22\\n5.5919e-01, -1.4336e+00,\\n2.4679e+00,\\n1.3920e+00,\\n-3.9291e-01,\\n,→\\n23\\n-1.2054e+00,'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 6, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1.9655e+00,\\n4.9202e-01,\\n-2.0871e+00,\\n,→\\n21\\n-5.8469e-01,\\n1.5016e+00,\\n8.2666e-01,\\n8.7033e-01,\\n8.5101e-01,\\n,→\\n22\\n5.5919e-01, -1.4336e+00,\\n2.4679e+00,\\n1.3920e+00,\\n-3.9291e-01,\\n,→\\n23\\n-1.2054e+00,\\n1.4637e+00,\\n1.9681e+00,\\n3.6572e-01,\\n3.1503e+00,\\n,→\\n24\\n-4.4693e-01, -1.1637e+00,\\n2.8804e-01, -8.3749e-01,\\n1.5026e+00,\\n,→\\n25\\n-2.1318e+00,\\n1.9633e+00, -4.5096e-01, -1.8215e+00,\\n3.2744e+00,\\n,→\\n26\\n5.2591e-01,\\n1.0686e+00,\\n3.7893e-01, -1.0792e-01,\\n5.1342e-01,\\n,→\\n27\\n-1.0443e+00,\\n1.7513e+00,\\n1.3895e-01, -6.6757e-01,\\n-4.8434e-01,\\n,→\\n28\\n-2.1621e+00, -1.5593e+01,\\n1.5249e+00,\\n1.6911e+00,\\n-1.2916e+00,\\n,→\\n29\\n1.2339e+00, -3.6064e-01, -9.6036e-01,\\n1.3226e+00,\\n1.6427e+00,\\n,→\\n30\\n1.4588e+00, -1.8806e+00,\\n6.3620e-01,\\n1.1713e+00,\\n1.1050e+00, ...\\n,→\\n31\\n2.1277e+00])\\n32\\nFigure 4: Analyzing Embeddings with BERT. See full notebook source\\nWe can see that this embedding is a PyTorch tensor object, a multidimen-\\n7'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 7, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='sional matrix containing multiple levels of embeddings, and that’s because\\nin BERT’s embedding representation, we have 13 different layers. One em-\\nbedding layer is computed for each layer of the neural network. Each level\\nrepresents a different view of our given token — or simply a sequence of\\ncharacters. We can get the final embedding by pooling several layers, details\\nwe’ll get into as we work our way up to understanding embeddings generated\\nusing BERT.\\nWhen we create an embedding for a word, sentence, or image that rep-\\nresents the artifact in the multidimensional space, we can do any number\\nof things with this embedding. For example, for tasks that focus on content\\nunderstanding in machine learning, we are often interested in comparing two\\ngiven items to see how similar they are. Projecting text as a vector allows us\\nto do so with mathematical rigor and compare words in a shared embedding\\nspace.\\nx\\ny\\nbird\\ndog\\nfly\\nFigure 5: Projecting words into a shared embedding space'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 7, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='to do so with mathematical rigor and compare words in a shared embedding\\nspace.\\nx\\ny\\nbird\\ndog\\nfly\\nFigure 5: Projecting words into a shared embedding space\\nFigure 6: Embeddings in the context of an application.\\nEngineering systems based on embeddings can be computationally ex-\\npensive to build and maintain [61]. The need to create, store, and manage\\nembeddings has also recently resulted in the explosion of an entire ecosystem\\nof related products. For example, the recent rise in the development of vector\\ndatabases to facilitate production-ready use of nearest neighbors semantic\\nqueries in machine learning systems5, and the rise of embeddings as a service6.\\nAs such, it’s important to understand their context both as end-consumers,\\nproduct management teams, and as developers who work with them. But in\\nmy deep-dive into the embeddings reference material, I found that there are\\ntwo types of resources: very deeply technical academic papers, for people who'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 7, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='my deep-dive into the embeddings reference material, I found that there are\\ntwo types of resources: very deeply technical academic papers, for people who\\n5For a survey of the vector database space today, refer to this article\\n6Embeddings now are a key differentiator in pricing between on-demand ML services\\n8'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 8, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='are already NLP experts, and surface-level marketing spam blurbs for people\\nlooking to buy embeddings-based tech, and that neither of these overlap in\\nwhat they cover.\\nIn Systems Thinking, Donella Meadows writes, “You think that because\\nyou understand ’one’ that you must therefore understand ’two’ because one\\nand one make two. But you forget that you must also understand ’and.’\"\\n[45] In order to understand the current state of embedding architectures and\\nbe able to decide how to build them, we must understand how they came\\nto be. In building my own understanding, I wanted a resource that was\\ntechnical enough to be useful enough to ML practitioners, but one that also\\nput embeddings in their correct business and engineering contexts as they\\nbecome more often used in ML architecture stacks. This is, hopefully, that text.\\nIn this text, we’ll examine embeddings from three perspectives, working\\nour way from the highest level view to the most technical. We’ll start with'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 8, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='In this text, we’ll examine embeddings from three perspectives, working\\nour way from the highest level view to the most technical. We’ll start with\\nthe business context, followed by the engineering implementation, and finally\\nlook at the machine learning theory, focusing on the nuts and bolts of how\\nthey work. On a parallel axis, we’ll also travel through time, surveying the\\nearliest approaches and moving towards modern embedding approaches.\\nIn writing this text, I strove to balance the need to have precise technical\\nand mathematical definitions for concepts and my desire to stay away from\\nexplanations that make people’s eyes glaze over. I’ve defined all technical\\njargon when it appears for the first time to build context. I include code as\\na frame of reference for practitioners, but don’t go as deep as a code tutorial\\nwould7. So, it would be helpful for the reader to have some familiarity with\\nprogramming and machine learning basics, particularly after the sections that'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 8, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='would7. So, it would be helpful for the reader to have some familiarity with\\nprogramming and machine learning basics, particularly after the sections that\\ndiscuss business context. But, ultimately the goal is to educate anyone who is\\nwilling to sit through this, regardless of level of technical understanding.\\nIt’s worth also mentioning what this text does not try to be: it does not try\\nto explain the latest advancements in GPT and generative models, it does not\\ntry to explain transformers in their entirety, and it does not try to cover all\\nof the exploding field of vector databases and semantic search. I’ve tried my\\nbest to keep it simple and focus on really understanding the core concept of\\nembeddings.\\n2\\nRecommendation as a business problem\\nLet’s step back and look at the larger context with a concrete example before\\ndiving into implementation details. Let’s build a social media network, Flutter,\\nthe premier social network for all things with wings. Flutter is a web and'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 8, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='diving into implementation details. Let’s build a social media network, Flutter,\\nthe premier social network for all things with wings. Flutter is a web and\\nmobile app where birds can post short snippets of text, videos, images, and\\nsounds, to let other birds, insects and bats in the area know what’s up. Its\\nbusiness model is based on targeted advertising, and its app architecture\\nincludes a \"home\" feed based on birds that you follow, made up of small\\npieces of multimedia content called “flits”, which can be either text, videos,\\nor photos. The home feed itself is by default in reverse chronological order\\n7In other words, I wanted to straddle the \"explanation\" and \"reference\" quadrants of the\\nDiátaxis framework\\n9'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 9, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='that is curated by the user. But we also would like to offer personalized,\\nrecommended flits so that the user finds interesting content on our platform\\nthat they might have not known about before.\\nFigure 7: Flutter’s content timeline in a social feed with a blend of organic followed content,\\nadvertising, and recommendations.\\nHow do we solve the problem of what to show in the timeline here so that\\nour users find the content relevant and interesting, and balance the needs of\\nour advertisers and business partners?\\nIn many cases, we can approach engineering solutions without involving\\nmachine learning. In fact, we should definitely start without it [76] because\\nmachine learning adds a tremendous amount of complexity to our working\\napplication [57]. In the case of the Flutter home feed, though, machine learning\\nforms a business-critical function part of the product offering. From the\\nbusiness product perspective, the objective is to offer Flutter’s users content'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 9, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='forms a business-critical function part of the product offering. From the\\nbusiness product perspective, the objective is to offer Flutter’s users content\\nthat is relevant8, interesting, and novel so they continue to use the platform.\\nIf we do not build discovery and personalization into our content-centric\\nproduct, Flutter users will not be able to discover more content to consume\\nand will disengage from the platform.\\nThis is the case for many content-based businesses, all of which have feed-\\nlike surface areas for recommendations, including Netflix, Pinterest, Spotify,\\nand Reddit. It also covers e-commerce platforms, which must surface relevant\\n8The specific definition of a relevant item in the recommendations space varies and is under\\nintense academic and industry debate, but generally it means an item that is of interest to the\\nuser\\n10'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 10, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='items to the user, and information retrieval platforms like search engines,\\nwhich must provide relevant answers to users upon keyword queries. There\\nis a new category of hybrid applications involving question-and-answering\\nin semantic search contexts that is arising as a result of work around the GPT\\nseries of models, but for the sake of simplicity, and because that landscape\\nchanges every week, we’ll stick to understanding the fundamental underlying\\nconcepts.\\nIn subscription-based platforms9, there is clear business objective that’s\\ntied directly to the bottom line, as outlined in this 2015 paper [64] about\\nNetflix’s recsys:\\nThe main task of our recommender system at Netflix is to help\\nour members discover content that they will watch and enjoy\\nto maximize their long-term satisfaction. This is a challenging\\nproblem for many reasons, including that every person is unique,\\nhas a multitude of interests that can vary in different contexts, and'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 10, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='to maximize their long-term satisfaction. This is a challenging\\nproblem for many reasons, including that every person is unique,\\nhas a multitude of interests that can vary in different contexts, and\\nneeds a recommender system most when they are not sure what\\nthey want to watch. Doing this well means that each member gets\\na unique experience that allows them to get the most out of Netflix.\\nAs a monthly subscription service, member satisfaction is tightly\\ncoupled to a person’s likelihood to retain with our service, which\\ndirectly impacts our revenue.\\nKnowing this business context, and given that personalized content is\\nmore relevant and generally gets higher rates of engagement [30] than non-\\npersonalized forms of recommendation on online platforms,10 how and why\\nmight we use embeddings in machine learning workflows in Flutter to show\\nusers flits that are interesting to them personally? We need to first understand\\nhow web apps work and where embeddings fit into them.\\n2.1'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 10, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='users flits that are interesting to them personally? We need to first understand\\nhow web apps work and where embeddings fit into them.\\n2.1\\nBuilding a web app\\nMost of the apps we use today — Spotify, Gmail, Reddit, Slack, and Flutter\\n— are all designed based on the same foundational software engineering\\npatterns. They are all apps available on web and mobile clients. They all have\\na front-end where the user interacts with the various product features of the\\napplications, an API that connects the front-end to back-end elements, and a\\ndatabase that processes data and remembers state.\\n9In ad-based services, the line between retention and revenue is a bit murkier, and we have\\noften what’s known as a multi-stakeholder problem, where the actual optimized function is a\\nbalance between meeting the needs of the user and meeting the needs of the advertiser [75]. In\\nreal life, this can often result in a process of enshittification [15] of the platform that leads to'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 10, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='balance between meeting the needs of the user and meeting the needs of the advertiser [75]. In\\nreal life, this can often result in a process of enshittification [15] of the platform that leads to\\nextremely suboptimal end-user experiences. So, when we create Flutter, we have to be very\\ncareful to balance these concerns, and we’ll also assume for the sake of simplification that\\nFlutter is a Good service that loves us as users and wants us to be happy.\\n10For more, see this case study on personalized recommendations as well as the intro section\\nof this paper which covers many personalization use-cases.\\n11'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 11, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='As an important note, features have many different definitions in machine\\nlearning and engineering. In this specific case, we mean collections of\\ncode that make up some front-end element, such as a button or a panel of\\nrecommendations. We’ll refer to these as product features, in contrast with\\nmachine learning features, which are input data into machine learning\\nmodels.\\nThis application architecture is commonly known as model-view-\\ncontroller pattern [20], or in common industry lingo, a CRUD app, named for\\nthe basic operations that its API allows to manage application state: create,\\nread, update, and delete.\\nFigure 8: Typical CRUD web app architecture\\nWhen we think of structural components in the architectures of these ap-\\nplications, we might think first in terms of product features. In an application\\nlike Slack, for example, we have the ability to post and read messages, man-\\nage notifications, and add custom emojis. Each of these can be seen as an'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 11, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='like Slack, for example, we have the ability to post and read messages, man-\\nage notifications, and add custom emojis. Each of these can be seen as an\\napplication feature. In order to create features, we have to combine common\\nelements like databases, caches, and web services. All of this happens as\\nthe client talks to the API, which talks to the database to process data. At a\\nmore granular, program-specific level, we might think of foundational data\\nstructures like arrays or hash maps, and lower still, we might think about\\nmemory management and network topologies. These are all foundational\\nelements of modern programming.\\nAt the feature level, though, we see that it not only includes the typical\\nCRUD operations, such as the ability to post and read Slack messages, but\\nalso elements that are more than operations that alter database state. Some\\nfeatures such as personalized channel suggestions, returning relevant results'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 11, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='also elements that are more than operations that alter database state. Some\\nfeatures such as personalized channel suggestions, returning relevant results\\nthrough search queries, and predicting Slack connection invites necessitates\\nthe use of machine learning.\\n12'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 12, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 9: CRUD App with Machine learning service\\n2.2\\nRules-based systems versus machine learning\\nTo understand where embeddings fit into these systems, it first makes sense to\\nunderstand where machine learning fits in at Flutter, or any given company,\\nas a whole. In a typical consumer company, the user-facing app is made up\\nof product features written in code, typically written as services or parts of\\nservices. To add a new web app feature, we write code based on a set of\\nbusiness logic requirements. This code acts on data in the app to develop our\\nnew feature.\\nIn a typical data-centric software development lifecycle, we start with the\\nbusiness logic. For example, let’s take the ability to post messages. We’d like\\nusers to be able to input text and emojis in their language of choice, have the\\nmessages sorted chronologically, and render correctly on web and mobile.\\nThese are the business requirements. We use the input data, in this case, user'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 12, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='messages sorted chronologically, and render correctly on web and mobile.\\nThese are the business requirements. We use the input data, in this case, user\\nmessages, and format them correctly and sort chronologically, at low latency,\\nin the UI.\\nFigure 10: A typical application development lifecycle\\nMachine learning-based systems are typically also services in the backend\\nof web applications. They are integrated into production workflows. But, they\\nprocess data much differently. In these systems, we don’t start with business\\nlogic. We start with input data that we use to build a model that will suggest\\nthe business logic for us. For more on the specifics of how to think about these\\ndata-centric engineering systems, see Kleppmann[35].\\nThis requires thinking about application development slightly differently,\\nand when we write an application that includes machine learning models as\\ninput, however, we’re inverting the traditional app lifecycle. What we have'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 12, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='and when we write an application that includes machine learning models as\\ninput, however, we’re inverting the traditional app lifecycle. What we have\\ninstead, is data plus our desired outcome. The data is combined into a model,\\nand it is this model which instead generates our business logic that builds\\nfeatures.\\nFigure 11: ML Development lifecycle\\n13'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 13, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='In short, the difference between programming and machine learning de-\\nvelopment is that we are not generating answers through business rules, but\\nbusiness rules through data. These rules are then re-incorporated into the\\napplication.\\nFigure 12: Generating answers via machine learning. The top chart shows a classical\\nprogramming approach with rules and data as inputs, while the bottom chart shows a machine\\nlearning approach with data and answers as inputs. [8]\\nAs an example, with Slack, for the channel recommendations product\\nfeature, we are not hard-coding a list of channels that need to be called from\\nthe organization’s API. We are feeding in data about the organization’s users\\n(what other channels they’ve joined, how long they’ve been users, what\\nchannels the people they’ve interacted the most with Slack in), and building a\\nmodel on that data that recommends a non-deterministic, personalized list of\\nchannels for each user that we then surface through the UI.\\n14'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 14, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 13: Traditional versus ML architecture and infra\\n2.3\\nBuilding a web app with machine learning\\nAll machine learning systems can be examined through how they accomplish\\nthese four steps. When we build models, our key questions should be, \"what\\nkind of input do we have and how is it formatted\", and \"what do we get as a\\nresult.\" We’ll be asking this for each of the approaches we look at. When we\\nbuild a machine learning system, we start by processing data and finish by\\nserving a learned model artifact.\\nThe four components of a machine learning system are11:\\n• Input data - processing data from a database or streaming from a\\nproduction application for use in modeling\\n• Feature Engineering and Selection - The process of examining the\\ndata and cleaning it to pick features. In this case, we mean features\\nas attributes of any given element that we use as inputs into machine\\nlearning. Examples of features are: user name, geographic location,'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 14, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='as attributes of any given element that we use as inputs into machine\\nlearning. Examples of features are: user name, geographic location,\\nhow many times they’ve clicked on a button for the past 5 days, and\\nrevenue. This piece always takes the longest in any given machine\\nlearning system, and is also known as finding representations [4] of\\nthe data that best fit the machine learning algorithm. This is where,\\nin the new model architectures, we use embeddings as input.\\n• Model Building - We select the features that are important and train\\nour model, iterating on different performance metrics over and over\\nagain until we have an acceptable model we can use. Embeddings\\nare also the output of this step that we can use in other, downstream\\nsteps.\\n11There are infinitely many layers of horror in ML systems [37]. These are still the founda-\\ntional components.\\n15'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 15, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• Model Serving - Now that we have a model we like, we serve it to\\nproduction, where it hits a web service, potentially cache, and our\\nAPI where it then propagates to the front-end for the user to consume\\nas part of our web app\\nFigure 14: CRUD app with ML\\nWithin machine learning, there are many approaches we can use to fit\\ndifferent tasks. Machine learning workflows that are most effective are formu-\\nlated as solutions to both a specific business need and a machine learning task.\\nTasks can best be thought of as approaches to modeling within the categorized\\nsolution space. For example, learning a regression model is a specific case\\nof a task. Others include clustering, machine translation, anomaly detection,\\nsimilarity matching, or semantic search. The three highest-level types of ML\\ntasks are supervised, where we have training data that can tell us whether the\\nresults the model predicted are correct according to some model of the world.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 15, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='tasks are supervised, where we have training data that can tell us whether the\\nresults the model predicted are correct according to some model of the world.\\nThe second is unsupervised, where there is not a single ground-truth answer.\\nAn example here is clustering of our customer base. A clustering model can\\ndetect patterns in your data but won’t explicitly label what those patterns are.\\nThe third is reinforcement learning which is separate from these two cate-\\ngories and formulated as a game theory problem: we have an agent moving\\nthrough an environment and we’d like to understand how to optimally move\\nthem through a given environment using explore-exploit techniques. We’ll\\nfocus on supervised learning, with a look at unsupervised learning with PCA\\nand Word2Vec.\\n16'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 16, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Machine Learning\\nSupervised Machine Learning\\nSVM\\nRegression\\nNeural\\nNetworks\\nUnsupervised\\nMachine\\nLearning\\nClustering\\nDimensionality\\nReduction\\nPCA\\nReinforcement\\nLearning\\nFigure 15: Machine learning task solution space and model families\\n2.4\\nFormulating a machine learning problem\\nAs we saw in the last section, machine learning is a process that takes data\\nas input to produce rules for how we should classify something or filter it\\nor recommend it, depending on the task at hand. In any of these cases, for\\nexample, to generate a set of potential candidates, we need to construct a\\nmodel.\\nA machine learning model is a set of instructions for generating a given\\noutput from data. The instructions are learned from the features of the input\\ndata itself. For Flutter, an example of a model we’d like to build is a candidate\\ngenerator that picks flits similar to flits our birds have already liked, because\\nwe think users will like those, too. For the sake of building up the intuition'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 16, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='generator that picks flits similar to flits our birds have already liked, because\\nwe think users will like those, too. For the sake of building up the intuition\\nfor a machine learning workflow, let’s pick a super-simple example that is not\\nrelated to our business problem, linear regression, which gives us a continuous\\nvariable as output in response.\\nFor example, let’s say, given the number of posts a user has made and how\\nmany posts they’ve liked, we’d like to predict how many days they’re likely to\\ncontinue to stay on Flutter. For traditional supervised modeling approaches\\nusing tabular data, we start with our input data, or a corpus as it’s generally\\nknown in machine learning problems that deal with text in the field known as\\nNLP (natural language processing).\\nWe’re not doing NLP yet, though, so our input data may look something\\nlike this, where we have a UID (userid) and some attributes of that user, such\\nas the number of times they’ve posted and number of posts they’ve liked.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 16, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='like this, where we have a UID (userid) and some attributes of that user, such\\nas the number of times they’ve posted and number of posts they’ve liked.\\nThese are our machine learning features.\\n17'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 17, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Table 1: Tabular Input Data for Flutter Users\\nbird_id\\nbird_posts\\nbird_likes\\n012\\n2\\n5\\n013\\n0\\n4\\n056\\n57\\n70\\n612\\n0\\n120\\nWe’ll need part of this data to train our model, part of it to test the accuracy\\nof the model we’ve trained, and part to tune meta-aspects of our model. These\\nare known as hyperparameters.\\nWe take two parts of this data as holdout data that we don’t feed into the\\nmodel. The first part, the test set, we use to validate the final model on data\\nit’s never seen before. We use the second split, called the validation set, to\\ncheck our hyperparameters during the model training phase. In the case of\\nlinear regression, there are no true hyperparameters, but we’ll need to keep in\\nmind that we will need to tune the model’s metadata for more complicated\\nmodels.\\nLet’s assume we have 100 of these values. A usual accepted split is to use\\n80% of data for training and 20% for testing. The reasoning is we want our\\nmodel to have access to as much data as possible so it learns a more accurate'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 17, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='80% of data for training and 20% for testing. The reasoning is we want our\\nmodel to have access to as much data as possible so it learns a more accurate\\nrepresentation.\\nIn general, our goal is to feed our input into the model, through a function\\nthat we pick, and get some predicted output, f (X) →y.\\nFigure 16: How inputs map to outputs in ML functions [34]\\nFor our simple dataset, we can use the linear regression equation:\\ny = x1β1 + x2β2 + ε\\n(3)\\nThis tells us that the output, y, can be predicted by two input variables, x1\\n(bird posts) and x2 (bird likes) with their given weights, β1 and β2, plus an\\nerror term ε, or the distance between each data point and the regression line\\ngenerated by the equation. Our task is to find the smallest sum of squared\\n18'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 18, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='differences between each point and the line, in other words to minimize the\\nerror, because it will mean that, at each point, our predicted y is as close to our\\nactual y as we can get it, given the other points.\\ny = x1β1 + x2β2 + ε\\n(4)\\nThe heart of machine learning is this training phase, which is the process of\\nfinding a combination of model instructions and data that accurately represent\\nour real data, which, in supervised learning, we can validate by checking the\\ncorrect \"answers\" from the test set.\\nFigure 17: The cycle of machine learning model development\\nAs the first round of training starts, we have our data. We train — or\\nbuild — our model by initializing it with a set of inputs, X. These are from the\\ntraining data. β1 and β2 are either initialized by setting to zero or initialized\\nrandomly (depending on the model, different approaches work best), and we\\ncalculate ˆy, our predicted value for the model. ϵ is derived from the data and'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 18, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='randomly (depending on the model, different approaches work best), and we\\ncalculate ˆy, our predicted value for the model. ϵ is derived from the data and\\nthe estimated coefficients once we get an output.\\ny = 2β1 + 5β2 + ε\\n(5)\\nHow do we know our model is good? We initialize it with some set of\\nvalues, weights, and we iterate on those weights, usually by minimizing a cost\\nfunction. The cost function is a function that models the difference between\\nour model’s predicted value and the actual output for the training data. The\\nfirst output may not be the most optimal, so we iterate over the model space\\nmany times, optimizing for the specific metric that will make the model as\\nrepresentative of reality as possible and minimize the difference between the\\nactual and predicted values. So in our case, we compare ˆy to y. The average\\nsquared difference between an observation’s actual and predicted values is\\nthe cost, otherwise known as MSE - mean squared error.\\nMSE = 1\\nN\\nn\\n∑\\ni=1\\n(yi −(mxi + b))2'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 18, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='squared difference between an observation’s actual and predicted values is\\nthe cost, otherwise known as MSE - mean squared error.\\nMSE = 1\\nN\\nn\\n∑\\ni=1\\n(yi −(mxi + b))2\\n(6)\\nWe’d like to minimize this cost, and we do so with gradient descent. When\\nwe say that the model learns, we mean that we can learn what the correct\\ninputs into a model are through an of iterative process where we feed the\\nmodel data, evaluate the output, and to see if the predictions it generates\\n19'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 19, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='improve through the process of gradient descent. We’ll know because our loss\\nshould incrementally decrease in every training iteration.\\nWe have finally trained our model. Now, we test the model’s predictions\\non the 20 values that we’ve used as a hold-out set; i.e. the model has not seen\\nthese before and we can confidently assume that they won’t influence the\\ntraining data. We compare how many elements of the hold-out set the model\\nwas able to predict correctly to see what the model’s accuracy was.\\n2.4.1\\nThe Task of Recommendations\\nWe just saw a simple example of machine learning as it relates to predicting\\ncontinuous response variables. When our business question is, \"What would\\nbe good content to show our users,\" we are facing the machine learning task for\\nrecommendation. Recommender systems are systems set up for information\\nretrieval, a field closely related to NLP that’s focused on finding relevant in-\\nformation in large collections of documents. The goal of information retrieval'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 19, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='retrieval, a field closely related to NLP that’s focused on finding relevant in-\\nformation in large collections of documents. The goal of information retrieval\\nis to synthesize large collections of unstructured text documents. Within infor-\\nmation retrieval, there are two complementary solutions in how we can offer\\nusers the correct content in our app: search, and recommendations.\\nSearch is the problem of directed [17] information seeking, i.e. the user\\noffers the system a specific query and would like a set of refined results.\\nSearch engines at this point are a well-established traditional solution in\\nthe space.\\nRecommendation is a problem where \"man is the query.\" [58] Here,\\nwe don’t know what the person is looking for exactly, but we would like\\nto infer what they like, and recommend items based on their learned tastes\\nand preferences.\\nThe first industrial recommender systems were created to filter messages\\nin email and newsgroups [22] at the Xerox Palo Alto Research Center based'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 19, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='and preferences.\\nThe first industrial recommender systems were created to filter messages\\nin email and newsgroups [22] at the Xerox Palo Alto Research Center based\\non a growing need to filter incoming information from the web. The most\\ncommon recommender systems today are those at Netflix, YouTube, and other\\nlarge-scale platforms that need a way to surface relevant content to users.\\nThe goal of recommender systems is surface items that are relevant to the\\nuser. Within the framework of machine learning approaches for recommenda-\\ntion, the main machine learning task is to determine which items to show to a\\nuser in a given situation. [5]. There are several common ways to approach the\\nrecommendation problem.\\n• Collaborative filtering - The most common approach for creating\\nrecommendations is to formulate our data as a problem of finding\\nmissing user-item interactions in a given set of user-item interaction\\nhistory. We start by collecting either explicit (ratings) data or implicit'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 19, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='missing user-item interactions in a given set of user-item interaction\\nhistory. We start by collecting either explicit (ratings) data or implicit\\nuser interaction data like clicks, pageviews, or time spent on items,\\nand compute. The simplest form of interactions are neighborhood\\nmodels, where ratings are predicted initially by finding users similar\\nto our given target user. We use similarity functions to compute the\\n20'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 20, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='closeness of users. Another common approach is using methods\\nsuch matrix factorization, the process of representing users and\\nitems in a feature matrix made up of low-dimensional factor vectors,\\nwhich in our case, are also known as embeddings, and learning those\\nfeature vectors through the process of minimizing a cost function.\\nThis process can be thought of as similar to Word2Vec [43], a deep\\nlearning model which we’ll discuss in depth in this document. There\\nare many different approaches to collaborative filtering, including\\nmatrix factorization and factorization machines.\\n• Content filtering - This approach uses metadata available about our\\nitems (for example in movies or music, the title, year released, genre,\\nand so on) as initial or additional features input into models and\\nwork well when we don’t have much information about user activ-\\nity, although they are often used in combination with collaborative\\nfiltering approaches. Many embeddings architectures fall into this'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 20, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='work well when we don’t have much information about user activ-\\nity, although they are often used in combination with collaborative\\nfiltering approaches. Many embeddings architectures fall into this\\ncategory since they help us model the textual features for our items.\\n• Learn to Rank - Learn to rank methods focus on ranking items in\\nrelation to each other based on a known set of preferred rankings\\nand the error is the number of cases when pairs or lists of items\\nare ranked incorrectly. Here, the problem is not presenting a single\\nitem, but a set of items and how they interplay. This step normally\\ntakes place after candidate generation, in a filtering step, because it’s\\ncomputationally expensive to rank extremely large lists.\\n• Neural Recommendations - The process of using neural networks to\\ncapture the same relationships that matrix factorization does without\\nexplicitly having to create a user/item matrix and based on the shape'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 20, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='capture the same relationships that matrix factorization does without\\nexplicitly having to create a user/item matrix and based on the shape\\nof the input data. This is where deep learning networks, and recently,\\nlarge language models, come into play. Examples of deep learning\\narchitectures used for recommendation include Word2Vec and BERT,\\nwhich we’ll cover in this document, and convolutional and recurrent\\nneural networks for sequential recommendation (such as is found\\nin music playlists, for example). Deep learning allows us to better\\nmodel content-based recommendations and give us representations\\nof our items in an embedding space. [73]\\nRecommender systems have evolved their own unique architectures12,\\nand they usually include constructing a four-stage recommender system that’s\\nmade up of several machine learning models, each of which perform a differ-\\nent machine learning task.\\nFigure 18: Recommender systems as a machine learning problem'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 20, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='made up of several machine learning models, each of which perform a differ-\\nent machine learning task.\\nFigure 18: Recommender systems as a machine learning problem\\n12For a good survey on the similarities and difference between search and recommendations,\\nread this great post on system design\\n21'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 21, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• Candidate Generation - First, we ingest data from the web app. This\\ndata goes into the initial piece, which hosts our first-pass model\\ngenerating candidate recommendations. This is where collaborative\\nfiltering takes place, and we whittle our list of potential candidates\\ndown from millions to thousands or hundreds.\\n• Ranking - Finally, we need a way to order the filtered list of recom-\\nmendations based on what we think the user will prefer the most, so\\nthe next stage is ranking, and then we serve them out in the timeline\\nor the ML product interface we’re working with.\\n• Filtering - Once we have a generated list of candidates, we want to\\ncontinue to filter them, using business logic (i.e. we don’t want to\\nsee NSFW content, or items that are not on sale, for example.). This\\nis generally a heavily heuristic-based step.\\n• Retrieval - This is the piece where the web application usually hits\\na model endpoint to get the final list of items served to the user\\nthrough the product UI.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 21, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• Retrieval - This is the piece where the web application usually hits\\na model endpoint to get the final list of items served to the user\\nthrough the product UI.\\nDatabases have become the fundamental tool in building backend in-\\nfrastructure that performs data lookups. Embeddings have become similar\\nbuilding blocks in the creation of many modern search and recommendation\\nproduct architectures. Embeddings are a type of machine learning feature —\\nor model input data — that we use first as input into the feature engineering\\nstage, and the first set of results that come from our candidate generation\\nstage, that are then incorporated into downstream processing steps of ranking\\nand retrieval to produce the final items the user sees.\\n2.4.2\\nMachine learning features\\nNow that we have a high-level conceptual view of how machine learning and\\nrecommender systems work, let’s build towards a candidate generation model\\nthat will offer relevant flits.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 21, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Now that we have a high-level conceptual view of how machine learning and\\nrecommender systems work, let’s build towards a candidate generation model\\nthat will offer relevant flits.\\nLet’s start by modeling a traditional machine learning problem and con-\\ntrast it with our NLP problem. For example, let’s say that one of our business\\nproblems is predicting whether a bird is likely to continue to stay on Flutter or\\nto churn13 — disengage and leave the platform.\\nWhen we predict churn, we have a given set of machine learning feature\\ninputs for each user and a final binary output of 1 or 0 from the model, 1 if the\\nbird is likely to churn, or 0 if the user is likely to stay on the platform.\\nWe might have the following inputs:\\n• How many posts the bird has clicked through in the past month (we’ll\\ncall this bird_posts in our input data)\\n• The geographical location of the bird from the browser headers\\n(bird_geo)\\n• How many posts the bird has liked over the past month (bird_likes)'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 21, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='call this bird_posts in our input data)\\n• The geographical location of the bird from the browser headers\\n(bird_geo)\\n• How many posts the bird has liked over the past month (bird_likes)\\n13An extremely common business problem to solve in almost every industry where either\\ncustomer population or subscription based on revenues is important\\n22'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 22, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Table 2: Tabular Input Data for Flutter Users\\nbird_id\\nbird_posts\\nbird_geo\\nbird_likes\\n012\\n2\\nUS\\n5\\n013\\n0\\nUK\\n4\\n056\\n57\\nNZ\\n70\\n612\\n0\\nUK\\n120\\nWe start by selecting our model features and arranging them in tabular\\nformat. We can formulate this data as a table (which, if we look closely, is also\\na matrix) based on rows of the bird id and our bird features.\\nTabular data is any structured data. For example, for a given Flutter user\\nwe have their user id, how many posts they’ve liked, how old the account\\nis, and so on. This approach works well for what we consider traditional\\nmachine learning approaches which deal with tabular data. As a general rule,\\nthe creation of the correct formulation of input data is perhaps the heart of\\nmachine learning. I.e. if we have bad input, we will get bad output. So in\\nall cases, we want to spend our time putting together our input dataset and\\nengineering features very carefully.\\nThese are all discrete features that we can feed into our model and learn'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 22, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='all cases, we want to spend our time putting together our input dataset and\\nengineering features very carefully.\\nThese are all discrete features that we can feed into our model and learn\\nweights from, and is fairly easy as long as we have numerical features. But,\\nsomething important to note here is that, in our bird interaction data, we have\\nboth numerical and textual features (bird geography). So what do we do with\\nthese textual features? How do we compare \"US\" to \"UK\"?\\nThe process of formatting data correctly to feed into a model is called fea-\\nture engineering. When we have a single continuous, numerical feature, like\\n“the age of the flit in days”, it’s easy to feed these features into a model. But,\\nwhen we have textual data, we need to turn it into numerical representations\\nso that we can compare these representations.\\n2.5\\nNumerical Feature Vectors\\nWithin the context of working with text in machine learning, we represent'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 22, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content=\"so that we can compare these representations.\\n2.5\\nNumerical Feature Vectors\\nWithin the context of working with text in machine learning, we represent\\nfeatures as numerical vectors. We can think of each row in our tabular feature\\ndata as a vector. And a collection of features, or our tabular representation,\\nis a matrix. For example, in the vector for our first user, [012, 2, 'US', 5],\\nwe can see that this particular value is represented by four features. When\\nwe create vectors, we can run mathematical computations over them and use\\nthem as inputs into ML models in the numerical form we require.\\nMathematically, vectors are collections of coordinates that tell us where\\na given point is in space among many dimensions. For example, in two\\ndimensions, we have a point [2, 5], representing bird_posts and bird_likes.\\nIn three dimensions, with three features including the bird id, we would\\nhave a vector\\n\\x02\\n12\\n2\\n5\\n\\x03\\n(7)\\nwhich tells us where that user falls on all three axes.\"),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 22, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='In three dimensions, with three features including the bird id, we would\\nhave a vector\\n\\x02\\n12\\n2\\n5\\n\\x03\\n(7)\\nwhich tells us where that user falls on all three axes.\\nBut how do we represent \"US\" or \"UK\" in this space? Because modern\\nmodels converge by performing operations on matrices [39], we need to\\n23'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 23, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='x\\ny\\nz\\n(.12, 0, 0)\\n(0, .2, 0)\\n(0, 0, .5)\\nFigure 19: Projecting a vector into the 3d space\\nencode geography as some sort of numerical value so that the model can\\ncalculate them as inputs14. So, once we have a combination of vectors, we can\\ncompare it to other points. So in our case, each row of data tells us where to\\nposition each bird in relation to any other given bird based on the combination\\nof features. And that’s really what our numerical features allow us to do.\\n2.6\\nFrom Words to Vectors in Three Easy Pieces\\nIn \"Operating Systems: Three Easy Pieces\", the authors write, \"Like any system\\nbuilt by humans, good ideas accumulated in operating systems over time,\\nas engineers learned what was important in their design.\" [3] Today’s large\\nlanguage models were likewise built on hundreds of foundational ideas over\\nthe course of decades. There are, similarly, several fundamental concepts that\\nmake up the work of transforming words to numerical representations.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 23, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='the course of decades. There are, similarly, several fundamental concepts that\\nmake up the work of transforming words to numerical representations.\\nThese show up over and over again, in every deep learning architecture\\nand every NLP-related task15:\\n• Encoding - We need to represent our non-numerical, multimodal\\ndata as numbers so we can create models out of them. There are\\nmany different ways of doing this.\\n• Vectors - we need a way to store the data we have encoded and\\nhave the ability to perform mathematical functions in an optimized\\nway on them. We store encodings as vectors, usually floating-point\\nrepresentations.\\n• Lookup matrices - Often times, the end-result we are looking for\\nfrom encoding and embedding approaches is to give some approxi-\\nmation about the shape and format of our text, and we need to be\\nable to quickly go from numerical to word representations across\\nlarge chunks of text. So we use lookup tables, also known as hash'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 23, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='mation about the shape and format of our text, and we need to be\\nable to quickly go from numerical to word representations across\\nlarge chunks of text. So we use lookup tables, also known as hash\\n14There are some models, specifically decision trees, where you don’t need to do text encoding\\nbecause the tree learns the categorical variables out of the box, however implementations differ,\\nfor example the two most popular implementations, scikit-learn and XGBoost [1], can’t.\\n15When we talk about tasks in NLP-based machine learning, we mean very specifically, what\\nthe machine learning problem is formulated to do. For example, we have the task of ranking,\\nrecommendation, translation, text summarization, and so on.\\n24'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 24, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='tables, also known as attention, to help us map between the words\\nand the numbers.\\nAs we go through the historical context of embeddings, we’ll build our\\nintuition from encoding to BERT and beyond16. What we’ll find as we go\\nfurther into the document is that the explanations for each concept get succes-\\nsively shorter, because we’ve already done the hard work of understanding\\nthe building blocks at the beginning.\\nFigure 20: Pyramid of fundamental concepts building to BERT\\n3\\nHistorical Encoding Approaches\\nCompressing content into lower dimensions for compact numerical repre-\\nsentations and calculations is not a new idea. For as long as humans have\\nbeen overwhelmed by information, we’ve been trying to synthesize it so that\\nwe can make decisions based on it. Early approaches have included one-hot\\nencoding, TF-IDF, bag-of-words, LSA, and LDA.\\nThe earlier approaches were count-based methods. They focused on count-\\ning how many times a word appeared relative to other words and generating'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 24, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='encoding, TF-IDF, bag-of-words, LSA, and LDA.\\nThe earlier approaches were count-based methods. They focused on count-\\ning how many times a word appeared relative to other words and generating\\nencodings based on that. LDA and LSA can be considered statistical ap-\\nproaches, but they are still concerned with inferring the properties of a dataset\\nthrough heuristics rather than modeling. Prediction-based approaches came\\nlater and instead learned the properties of a given text through models such\\nas support vector machines, Word2Vec, BERT, and the GPT series of models,\\nall of which use learned embeddings instead.\\n16Original diagram from this excellent guide on BERT\\n25'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 25, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Embedding Methods\\nCount-based Methods\\nTF-IDF\\nOne-Hot Encoding\\nBag-of-words\\nLSA\\nLDA\\nPrediction-based Methods\\nSVM\\nWord2Vec\\nBERT family\\nGPT family\\nFigure 21: Embedding Method Solution Space\\nA Note on the Code In looking at these approaches programmatically,\\nwe’ll start by using scikit-learn, the de-facto standard machine learning\\nlibrary for smaller datasets, with some implementations in native Python\\nfor clarity in understanding functionality that scikit-learn wraps. As we\\nmove into deep learning, we’ll move to PyTorch, a deep learning library\\nthat’s quickly becoming industry-standard for deep learning implemen-\\ntation. There are many different ways of implementing the concepts we\\ndiscuss here, these are just the easiest to illustrate using Python’s ML\\nlingua franca libraries.\\n3.1\\nEarly Approaches\\nThe first approaches to generating textual features were count-based, relying\\non simple counts or high-level understanding of statistical properties: they'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 25, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='3.1\\nEarly Approaches\\nThe first approaches to generating textual features were count-based, relying\\non simple counts or high-level understanding of statistical properties: they\\nwere descriptive instead of models, which are predictive and attempt to guess\\na value based on a set of input values. The first methods were encoding\\nmethods, a precursor to embedding. Encoding is often a process that still\\nhappens as the first stage of data preparation for input into more complex\\nmodeling approaches. There are several methods to create text features using\\na process known as encoding so that we can map the geography feature into\\nthe vector space:\\n• Ordinal encoding\\n• Indicator encoding\\n• One-Hot encoding\\nIn all these cases, what we are doing is creating a new feature that maps\\nto the text feature column but is a numerical representation of the variable so\\nthat we can project it into that space for modeling purposes. We’ll motivate'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 25, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='to the text feature column but is a numerical representation of the variable so\\nthat we can project it into that space for modeling purposes. We’ll motivate\\nthese examples with simple code snippets from scikit-learn, the most common\\nlibrary for demonstrating basic ML concepts. We’ll start with count-based\\napproaches.\\n3.2\\nEncoding\\nOrdinal encoding Let’s again come back to our dataset of flits. We encode our\\ndata using sequential numbers. For example, \"1\" is \"finch\", \"2\" is \"bluejay\" and\\nso on. We can use this method only if the variables have a natural ordered\\nrelationship to each other. For example, in this case \"bluejay\" is not \"more\"\\n26'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 26, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='than \"finch\" and so would be incorrectly represented in our model. The case is\\nthe same, if, in our flit data, we encode \"US\" as 1 and \"UK\" as 2.\\nTable 3: Bird Geographical Location Encoding\\nbird_id\\nbird_posts\\nbird_geo\\nbird_likes\\nenc_bird_geo\\n012\\n2\\nUS\\n5\\n2\\n013\\n0\\nUK\\n4\\n1\\n056\\n57\\nNZ\\n70\\n0\\n612\\n0\\nUK\\n120\\n1\\n1\\nfrom sklearn.preprocessing import OrdinalEncoder\\n2\\n3\\ndata = [[\\'US\\'], [\\'UK\\'], [\\'NZ\\']]\\n4\\n>>> print(data)\\n5\\n[[\\'US\\']\\n6\\n[\\'UK\\']\\n7\\n[\\'NZ\\']]\\n8\\n9\\n# our label features\\n10\\nencoder = OrdinalEncoder()\\n11\\nresult = encoder.fit_transform(data)\\n12\\n>>> print(result)\\n13\\n[[2.]\\n14\\n[1.]\\n15\\n[0.]]\\nFigure 22: Ordinal Encoding in Scikit-Learn source\\n3.2.1\\nIndicator and one-hot encoding\\nIndicator encoding, given n categories (i.e. \"US\", \"UK\", and \"NZ\"), encodes\\nthe variables into n −1 categories, creating a new feature for each category.\\nSo, if we have three variables, indicator encoding encodes into two indicator\\nvariables. Why would we do this? If the categories are mutually exclusive,'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 26, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='So, if we have three variables, indicator encoding encodes into two indicator\\nvariables. Why would we do this? If the categories are mutually exclusive,\\nas they usually are in point-in-time geolocation estimates, if someone is in\\nthe US, we know for sure they’re not in the UK and not in NZ, so it reduces\\ncomputational overhead.\\nIf we instead use all the variables and they are very closely correlated,\\nthere is a chance we’ll fall into something known as the indicator variable\\ntrap. We can predict one variable from the others, which means we no longer\\nhave feature independence. This generally isn’t a risk for geolocation since\\nthere are more than 2 or 3 and if you’re not in the US, it’s not guaranteed that\\nyou’re in the UK. So, if we have US = 1, UK = 2, and NZ = 3, and prefer more\\ncompact representations, we can use indicator encoding. However, many\\nmodern ML approaches don’t require linear feature independence and use L1'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 26, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='compact representations, we can use indicator encoding. However, many\\nmodern ML approaches don’t require linear feature independence and use L1\\nregularization17 to prune feature inputs that don’t minimize the error, and as\\n17Regularization is a way to prevent our model from overfitting. Overfitting means our\\n27'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 27, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content=\"such only use one-hot encoding.\\nOne-hot encoding is the most commonly-used of the count-based methods.\\nThis process creates a new variable for each feature that we have. Everywhere\\nthe element is present in the sentence, we place a “1” in the vector. We are\\ncreating a mapping of all the elements in the feature space, where 0 indicates a\\nnon-match and 1 indicates a match, and comparing how similar those vectors\\nare.\\n1\\nfrom sklearn.preprocessing import OneHotEncoder\\n2\\nimport numpy as np\\n3\\n4\\nenc = OneHotEncoder(handle_unknown='ignore')\\n5\\ndata = np.asarray([['US'], ['UK'], ['NZ']])\\n6\\nenc.fit(data)\\n7\\nenc.categories_\\n8\\n>>> [array(['NZ', 'UK', 'US'], dtype='<U2')]\\n9\\nonehotlabels = enc.transform(data).toarray()\\n10\\nonehotlabels\\n11\\n>>>\\n12\\narray([[0., 0., 1.],\\n13\\n[0., 1., 0.],\\n14\\n[1., 0., 0.]])\\nFigure 23: One-Hot Encoding in scikit-learnsource\\nTable 4: Our one-hot encoded data with labels\\nbird_id\\nUS\\nUK\\nNZ\\n012\\n1\\n0\\n0\\n013\\n0\\n1\\n0\\n056\\n0\\n0\\n1\"),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 27, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='array([[0., 0., 1.],\\n13\\n[0., 1., 0.],\\n14\\n[1., 0., 0.]])\\nFigure 23: One-Hot Encoding in scikit-learnsource\\nTable 4: Our one-hot encoded data with labels\\nbird_id\\nUS\\nUK\\nNZ\\n012\\n1\\n0\\n0\\n013\\n0\\n1\\n0\\n056\\n0\\n0\\n1\\nNow that we’ve encoded our textual features as vectors, we can feed them\\ninto the model we’re developing to predict churn. The function we’ve been\\nlearning will minimize the loss of the model, or the distance between the\\nmodel’s prediction and the actual value, by predicting correct parameters for\\neach of these features. The learned model will then return a value from 1\\nto 0 that is a probability that the event, either churn or no-churn, has taken\\nplace, given the input features of our particular bird. Since this is a supervised\\nmodel, we then evaluate this model for accuracy by feeding our test data\\ninto the model and comparing the model’s prediction against the actual data,\\nwhich tells us whether the bird has churned or not.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 27, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='into the model and comparing the model’s prediction against the actual data,\\nwhich tells us whether the bird has churned or not.\\nWhat we’ve built is a standard logistic regression model. Generally these\\ndays the machine learning community has converged on using gradient-\\nboosted decision tree methods for dealing with tabular data, but we’ll see\\nmodel can exactly predict outcomes based on the training data, but it can’t learn new inputs\\nthat we show it, which means it can’t generalize\\n28'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 28, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='that neural networks build on simple linear and logistic regression models to\\ngenerate their output, so it’s a good starting point.\\nEmbeddings as larger feature inputs\\nOnce we have encoded our feature data, we can use this input for any type\\nof model that accepts tabular features. In our machine learning task, we\\nwere looking for output that indicated whether a bird was likely to leave the\\nplatform based on their location and some usage data. Now, we’d like to focus\\nspecifically on surfacing flits that are similar to other flits the user has already\\ninteracted with so we’ll need feature representations of either/or our users or\\nour content.\\nLet’s go back to the original business question we posed at the beginning\\nof this document: how do we recommend interesting new content for Flutter\\nusers given that we know that past content they consumed (i.e. liked and\\nshared)?\\nIn the traditional collaborative filtering approach to recommendations,'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 28, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='users given that we know that past content they consumed (i.e. liked and\\nshared)?\\nIn the traditional collaborative filtering approach to recommendations,\\nwe start by constructing a user-item matrix based on our input data that, when\\nfactored, gives us the latent properties of each flit and allows us to recommend\\nsimilar ones.\\nIn our case, we have Flutter users who might have liked a given flit. What\\nother flits would we recommend given the textual properties of that one?\\nHere’s an example. We have a flit that our bird users liked.\\n\"Hold fast to dreams, for if dreams die, life is a broken-winged bird that\\ncannot fly.\"\\nWe also have other flits we may or may not want to surface in our bird’s\\nfeed.\\n\"No bird soars too high if he soars with his own wings.\"\\n“A bird does not sing because it has an answer, it sings because it has a\\nsong.”\\nHow would we turn this into a machine learning problem that takes\\nfeatures as input and a prediction as an output, knowing what we know about'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 28, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='song.”\\nHow would we turn this into a machine learning problem that takes\\nfeatures as input and a prediction as an output, knowing what we know about\\nhow to do this already? First, in order to build this matrix, we need to turn\\neach word into a feature that’s a column value and each user remains a row\\nvalue.\\nThe best way to think of the difference between tabular and free-form\\nrepresentations as model inputs is that a row of tabular data looks like\\nthis, [012,2,\"US\", 5], and a \"row\" or document of text data looks like this,\\n[\"No bird soars too high if he soars with his own wings.\"] In both\\ncases, each of these are vectors, or a list of values that represents a single bird.\\n29'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 29, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='In traditional machine learning, rows are our user data about a single bird\\nand columns are features about the bird. In recommendation systems, our\\nrows are the individual data about each user, and our column data represents\\nthe given data about each flit. If we can factor this matrix, that is decompose it\\ninto two matrices (Q and PT) that, when multiplied, the product is our original\\nmatrix (R), we can learn the \"latent factors\" or features that allow us to group\\nsimilar users and items together to recommend them.\\nAnother way to think about this is that in traditional ML, we have to\\nactively engineer features, but they are then available to us as matrices. In\\ntext and deep-learning approaches, we don’t need to do feature engineering,\\nbut need to perform the extra step of generating valuable numeric features\\nanyway.\\n1\\n3\\n5\\n5\\n4\\n5 4\\n4\\n2 1 3\\n2 4\\n1 2\\n3\\n4 3 5\\n2 4\\n5\\n4\\n2\\n4 3 4 2\\n2 5\\n1\\n3\\n3\\n2\\n4\\nR\\nusers\\nwords\\n≈\\nusers\\nlatent factors\\nQ\\n×\\nlatent factors\\nwords\\nPT'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 29, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='anyway.\\n1\\n3\\n5\\n5\\n4\\n5 4\\n4\\n2 1 3\\n2 4\\n1 2\\n3\\n4 3 5\\n2 4\\n5\\n4\\n2\\n4 3 4 2\\n2 5\\n1\\n3\\n3\\n2\\n4\\nR\\nusers\\nwords\\n≈\\nusers\\nlatent factors\\nQ\\n×\\nlatent factors\\nwords\\nPT\\nThe factorization of our feature matrix into these two matrices, where the\\nrows in Q are actually embeddings [43] for users and the rows in matrix P\\nare embeddings for flits, allows us to fill in values for flits that Flutter users\\nhave not explicitly liked, and then perform a search across the matrix to find\\nother words they might be interested in. The end-result is our generated\\nrecommendation candidates, which we then filter downstream and surface to\\nthe user because the core of the recommendation problem is to recommend\\nitems to the user.\\nIn this base-case scenario, each column could be a single word in the entire\\nvocabulary of every flit we have and the vector we create, shown in the matrix\\nfrequency table, would be an insanely large, sparse vector that has a 0 of\\noccurrence of words in our vocabulary. The way we can build toward this'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 29, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='frequency table, would be an insanely large, sparse vector that has a 0 of\\noccurrence of words in our vocabulary. The way we can build toward this\\nrepresentation is to start with a structure known as a bag of words, or simply\\nthe frequency of appearance of text in a given document (in our case, each flit\\nis a document.) This matrix is the input data structure for many of the early\\napproaches to embedding.\\nIn scikit-learn, we can create an initial matrix of our inputs across docu-\\nments using ‘CountVectorizer‘.\\n30'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 30, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nfrom sklearn.feature_extraction.text import CountVectorizer\\n2\\nimport pandas as pd\\n3\\n4\\nvect = CountVectorizer(binary=True)\\n5\\nvects = vect.fit_transform(flits)\\n6\\n7\\nresponses = [\"Hold fast to dreams, for if dreams die, life is a broken-winged\\nbird that cannot fly.\", \"No bird soars too high if he soars with his own\\nwings.\", \"A bird does not sing because it has an answer, it sings because\\nit has a song.\"]\\n,→\\n,→\\n,→\\n8\\n9\\ndoc = pd.DataFrame(list(zip(responses)))\\n10\\n11\\ntd = pd.DataFrame(vects.todense()).iloc[:5]\\n12\\ntd.columns = vect.get_feature_names_out()\\n13\\nterm_document_matrix = td.T\\n14\\nterm_document_matrix.columns = [\\'flit \\'+str(i) for i in range(1, 4)]\\n15\\nterm_document_matrix[\\'total_count\\'] = term_document_matrix.sum(axis=1)\\n16\\n17\\nprint(term_document_matrix.drop(columns=[\\'total_count\\']).head(10))\\n18\\n19\\nflit_1\\nflit_2\\nflit_3\\n20\\nan\\n0\\n0\\n1\\n21\\nanswer\\n0\\n0\\n1\\n22\\nbecause\\n0\\n0\\n1\\n23\\nbird\\n1\\n1\\n1\\n24\\nbroken\\n1\\n0\\n0\\n25\\ncannot\\n1\\n0\\n0\\n26\\ndie\\n1\\n0\\n0\\n27\\ndoes\\n0\\n0\\n1\\n28\\ndreams\\n1\\n0\\n0\\n29\\nfast\\n1\\n0\\n0\\n30\\n31'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 30, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='18\\n19\\nflit_1\\nflit_2\\nflit_3\\n20\\nan\\n0\\n0\\n1\\n21\\nanswer\\n0\\n0\\n1\\n22\\nbecause\\n0\\n0\\n1\\n23\\nbird\\n1\\n1\\n1\\n24\\nbroken\\n1\\n0\\n0\\n25\\ncannot\\n1\\n0\\n0\\n26\\ndie\\n1\\n0\\n0\\n27\\ndoes\\n0\\n0\\n1\\n28\\ndreams\\n1\\n0\\n0\\n29\\nfast\\n1\\n0\\n0\\n30\\n31\\nFigure 24: Creating a matrix frequency table to create a user-item matrix source\\n3.2.2\\nTF-IDF\\nOne-hot encoding just deals with presence and absence of a single term in\\na single document. However, when we have large amounts of data, we’d\\nlike to consider the weights of each term in relation to all the other terms in a\\ncollection of documents.\\nTo address the limitations of one-hot encoding, TF-IDF, or term frequency-\\ninverse document frequency was developed. TF-IDF was introduced in the\\n1970s18 as a way to create a vector representation of a document by averaging\\nall the document’s word weights. It worked really well for a long time and\\n18By Karen Spärck Jones, whose paper, \"Synonymy and semantic classification\" is fundamen-\\ntal to the field of NLP\\n31'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 31, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='still does in many cases. For example, one of the most-used search functions,\\nBM25, uses TF-IDF as a baseline [56] as a default search strategy in Elastic-\\nsearch/Opensearch 19. It extends TF-IDF to develop a probability associated\\nwith the probability of relevance for each pair of words in a document and it\\nis still being applied in neural search today [65].\\nTF-IDF will tell you how important a single word is in a corpus by assign-\\ning it a weight and, at the same time, down-weight common words like, \"a\",\\n\"and\", and \"the\". This calculated weight gives us a feature for a single word\\nTF-IDF, and also the relevance of the features across the vocabulary.\\nWe take all of our input data that’s structured in sentences and break it up\\ninto individual words, and perform counts on its values, generating the bag\\nof words. TF is term frequency, or the number of times a term appears in a\\ndocument relative to the other terms in the document.\\ntf(t, d) =\\nft,d\\n∑t′∈d ft′,d\\n(8)'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 31, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='of words. TF is term frequency, or the number of times a term appears in a\\ndocument relative to the other terms in the document.\\ntf(t, d) =\\nft,d\\n∑t′∈d ft′,d\\n(8)\\nAnd IDF is the inverse frequency of the term across all documents in our\\nvocabulary.\\nidf(t, D) = log\\nN\\n|{d ∈D : t ∈d}|\\n(9)\\nLet’s take a look at how to implement it from scratch:\\n19You can read about how Elasticsearch implements BM25 here\\n32'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 32, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\n2\\nimport math\\n3\\n4\\n# Process documents into individual words\\n5\\ndocumentA\\n= [\\'Hold\\',\\'fast\\',\\'to\\',\\'dreams\\',\\'for\\',\\'if\\',\\'dreams\\',\\'die,\\'\\n,\\'life\\',\\'is\\',\\'a\\',\\'broken-winged\\',\\'bird\\',\\'that\\',\\'cannot\\',\\'fly\\']\\n,→\\n6\\ndocumentB =\\n[\\'No\\',\\'bird\\',\\'soars\\',\\'too\\',\\'high\\',\\'if\\',\\n\\'he\\',\\'soars\\',\\'with\\',\\'his\\',\\'own\\',\\'wings\\']\\n,→\\n7\\n8\\ndef tf(doc_dict: dict, doc_elements: list[str]) -> dict:\\n9\\n\"\"\"Term frequency of a word in a document\\nover total words in\\ndocument\"\"\"\\n,→\\n10\\ntf_dict = {}\\n11\\ncorpus_count = len(doc_elements)\\n12\\nfor word, count in doc_dict.items():\\n13\\ntf_dict[word] = count / float(corpus_count)\\n14\\nreturn tf_dict\\n15\\n16\\ndef idf(doc_list: list[str]) -> dict:\\n17\\n\"\"\"The number of documents in which the term appears per term\"\"\"\\n18\\nidf_dict = {}\\n19\\nN = len(doc_list)\\n20\\nidf_dict = dict.fromkeys(doc_list[0].keys(), 0)\\n21\\nfor word, val in idf_dict.items():\\n22\\nidf_dict[word] = math.log10(N / (float(val) + 1))\\n23\\nreturn idf_dict\\n24\\n25\\n# inverse document frequencies for all words\\n26'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 32, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='21\\nfor word, val in idf_dict.items():\\n22\\nidf_dict[word] = math.log10(N / (float(val) + 1))\\n23\\nreturn idf_dict\\n24\\n25\\n# inverse document frequencies for all words\\n26\\n# dicts are frequency counts of words per doc e.g. dict.fromkeys(corpus, 0)\\n27\\nidfs = idf([dict_a, dict_b])\\n28\\n29\\ndef tfidf(doc_elements: list[str], idfs)-> dict:\\n30\\n\"\"\"TF * IDF per word given a word and number of docs the term appears\\nin\"\"\"\\n,→\\n31\\ntfidf_dict = {}\\n32\\nfor word, val in doc_elements.items():\\n33\\ntfidf_dict[word] = val * idfs[word]\\n34\\nreturn tfidf_dict\\n35\\n36\\n# Calculate the term frequency for each document individually\\n37\\ntf_a = tf(dict_a, document_a)\\n38\\ntf_b = tf(dict_b, document_b)\\n39\\n40\\n# Calculate the inverse document frequency given each term frequency\\n41\\ntfidf_a = tfidf(tf_a, idfs)\\n42\\ntfidf_b = tfidf(tf_b, idfs)\\n43\\n44\\n# Return weight of each word in each document wrt to the total corpus\\n45\\ndocument_tfidf = pd.DataFrame([tfidf_a, tfidf_b])\\n46\\ndocument_tfidf.T\\n47\\n#\\ndoc 0\\ndoc 1\\n48\\na\\n0.018814\\n0.000000\\n49\\ndreams'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 32, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='43\\n44\\n# Return weight of each word in each document wrt to the total corpus\\n45\\ndocument_tfidf = pd.DataFrame([tfidf_a, tfidf_b])\\n46\\ndocument_tfidf.T\\n47\\n#\\ndoc 0\\ndoc 1\\n48\\na\\n0.018814\\n0.000000\\n49\\ndreams\\n0.037629\\n0.000000\\n50\\nNo\\n0.000000\\n0.025086\\nFigure 25: Truncated implementation of TF-IDF, see full source\\n33'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 33, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Once we understand the underlying fundamental concept, we can use the\\nscikit-learn implementation which does the same thing, and also surfaces the\\nTF-IDF of each word in the vocabulary.\\n1\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n2\\nimport pandas as pd\\n3\\n4\\ncorpus = [\\n5\\n\"Hold fast to dreams, for if dreams die, life is a broken-winged bird\\nthat cannot fly.\",\\n,→\\n6\\n\"No bird soars too high if he soars with his own wings.\",\\n7\\n]\\n8\\n9\\n# langston hughes and william blake\\n10\\ntext_titles = [\"quote_lh\", \"quote_wb\"]\\n11\\n12\\nvectorizer = TfidfVectorizer()\\n13\\nvector = vectorizer.fit_transform(corpus)\\n14\\ndict(zip(vectorizer.get_feature_names_out(), vector.toarray()[0]))\\n15\\n16\\ntfidf_df = pd.DataFrame(vector.toarray(), index=text_titles,\\ncolumns=vectorizer.get_feature_names_out())\\n,→\\n17\\n18\\ntfidf_df.loc[\\'doc_freq\\'] = (tfidf_df > 0).sum()\\n19\\ntfidf_df.T\\n20\\n21\\n# How common or unique a word is in a given document wrt to the vocabulary\\n22\\nquote_lh\\nquote_wb\\ndoc_freq\\n23\\nbird\\n0.172503\\n0.197242\\n2.0'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 33, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='19\\ntfidf_df.T\\n20\\n21\\n# How common or unique a word is in a given document wrt to the vocabulary\\n22\\nquote_lh\\nquote_wb\\ndoc_freq\\n23\\nbird\\n0.172503\\n0.197242\\n2.0\\n24\\nbroken\\n0.242447\\n0.000000\\n1.0\\n25\\ncannot\\n0.242447\\n0.000000\\n1.0\\n26\\ndie\\n0.242447\\n0.000000\\n1.0\\nFigure 26: Implementation of TF-IDF in scikit-learn source\\nGiven that inverse document frequency is a measure of whether the word\\nis common or not across the documents, we can see that \"dreams\" is important\\nbecause they are rare across the documents and therefore interesting to us\\nmore so than \"bird.\" We see that the tf-idf for a given word, \"dreams\", is slightly\\ndifferent for each of these implementations, and that’s because Scikit-learn\\nnormalizes the denominator and uses a slightly different formula. You’ll also\\nnote that in the first implementation we separate the corpus words ourselves,\\ndon’t remove any stop words, and don’t lowercase everything. Many of these\\nsteps are done automatically in scikit-learn or can be set as parameters into'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 33, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='don’t remove any stop words, and don’t lowercase everything. Many of these\\nsteps are done automatically in scikit-learn or can be set as parameters into\\nthe processing pipeline. We’ll see later that these are critical NLP steps that\\nwe perform each time we work with text.\\nTF-IDF enforces several important ordering rules on our text corpus:\\n• Uprank term frequency when it occurs many times in a small number of\\ndocuments\\n34'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 34, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• Downrank term frequency when it occurs many times in many docu-\\nments, aka is not relevant\\n• Really downrank the term when it appears across your entire document\\nbase [56].\\nThere are numerous ways to calculate and create weights for individual\\nwords in TF-IDF. In each case, we calculate a score for each word that tells\\nus how important that word is in relation to each other word in our corpus,\\nwhich gives it a weight. Once we figure out how common each word is in\\nthe set of all possible flits and get a weighted score for the entire sentence in\\nrelation to other sentences.\\nGenerally, when we work with textual representations, we’re trying to\\nunderstand which words, phrases, or concepts are similar to each other. Within\\nour specific recommendations task, we are trying to understand which pieces\\nof content are similar to each other, so that we can recommend content that\\nusers will like based on either their item history or the user history of users\\nsimilar to them.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 34, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='of content are similar to each other, so that we can recommend content that\\nusers will like based on either their item history or the user history of users\\nsimilar to them.\\nSo, when we perform embedding in the context of recommender systems,\\nwe are looking to create neighborhoods from items and users, based on the\\nactivity of those users on our platform. This is the initial solution to the\\nproblem of “how do we recommend flits that are similar to flit that the user\\nhas liked.” This is the process of collaborative filtering.\\nThere are many approaches to collaborative filtering including a\\nneighborhood-based approach, which looks at weighted averages of user\\nratings and computes cosine similarity, between users. It then finds groups,\\nor neighborhoods of users which are similar to each other.\\nA key problem that makes up the fundamental problem in collaborative\\nfiltering and in recommendation systems in general is the ability to find similar'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 34, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='A key problem that makes up the fundamental problem in collaborative\\nfiltering and in recommendation systems in general is the ability to find similar\\nsets of items among very large collections [42].\\nMathematically, we can do this by looking at the distance metric between\\nany two given sets of items, and there are a number of different approaches,\\nincluding Euclidean distance, edit distance (more specifically, Levenshtein\\ndistance and Hamming distance), cosine distance, and more advanced com-\\npression approaches like minhashing.\\nThe most commonly used approach in most models where we’re trying\\nto ascertain the semantic closeness of two items is cosine similarity, which is\\nthe cosine of the angle between two objects represented as vectors, bounded\\nbetween -1 and 1. -1 means the two items are completely \"opposite\" of each\\nother and 1 means they are completely the same item, assuming unit length.\\nZero means that you should probably use a distance measure other than cosine'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 34, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='other and 1 means they are completely the same item, assuming unit length.\\nZero means that you should probably use a distance measure other than cosine\\nsimilarity because the vectors are completely orthogonal to each other. One\\npoint of clarification here is that cosine distance is the actual distance measure\\nand is calculated as 1 −similarity(⃗a,⃗b).\\nsimilarity(⃗a,⃗b) = ⃗a ·⃗b\\n|⃗a||⃗b|\\n=\\nn\\n∑\\ni=1\\naibi\\ns\\nn\\n∑\\ni=1\\na2\\ni\\ns\\nn\\n∑\\ni=1\\nb2\\ni\\n(10)\\n35'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 35, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='We use cosine similarity over other measures like Euclidean distance for\\nlarge text corpuses, for example, because in very large, sparse spaces, the\\ndirection of the vectors is just as, and even more important, than the actual\\nvalues.\\nThe higher the cosine similarity is for two words or documents, the better.\\nWe can use TF-IDF as a way to look at cosine similarity. Once we’ve given\\neach of our words a tf-idf score, we can also assign a vector to each word in\\nour sentence, and create a vector out of each quote to assess how similar they\\nare.\\nx\\ny\\nbird\\nwings\\nθ\\nθ\\nϕ\\nFigure 27: Illustration of cosine similarity between bird and wings vectors.\\nLet’s take a look at the actual equation for cosine similarity. We start with\\nthe dot product between two vectors, which is just the sum of each value\\nmultiplied by the corresponding value in our second vector, and then we\\ndivide by the normalized dot product.\\n1\\nv1 = [0,3,4,5,6]\\n2\\nv2 = [4,5,6,7,8]\\n3\\n4\\ndef dot(v1, v2):\\n5'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 35, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content=\"multiplied by the corresponding value in our second vector, and then we\\ndivide by the normalized dot product.\\n1\\nv1 = [0,3,4,5,6]\\n2\\nv2 = [4,5,6,7,8]\\n3\\n4\\ndef dot(v1, v2):\\n5\\ndot_product = sum((a * b) for a,b in zip(v1,v2))\\n6\\nreturn dot_product\\n7\\n8\\ndef cosine_similarity(v1, v2):\\n9\\n'''\\n10\\n(v1 dot v2)/||v1|| *||v2||)\\n11\\n'''\\n12\\nproducts = dot(v1,v2)\\n13\\ndenominator = ( (dot(v1,v1) **.5) * (dot(v2,v2) ** .5) )\\n14\\nsimilarity = products / denominator\\n15\\nreturn similarity\\n16\\n17\\nprint(cosine_similarity(v1, v2))\\n18\\n# 0.9544074144996451\\nFigure 28: Implementation of cosine similarity from scratch source\\nOr, once again, in scikit-learn, as a pairwise metric:\\n36\"),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 36, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nfrom sklearn.metrics import pairwise\\n2\\n3\\nv1 = [0,3,4,5,6]\\n4\\nv2 = [4,5,6,7,8]\\n5\\n6\\n# need to be in numpy data format\\n7\\npairwise.cosine_similarity([v1],[v2])\\n8\\n# array([[0.95440741]])\\n9\\nFigure 29: Implementation of cosine similarity in scikitsource\\nOther commonly-used distance measures in semantic similarity and rec-\\nommendations include:\\n• Euclidean distance - calculates the straight-line distance between two\\npoints\\n• Manhattan Distance - Measures the distance between two points by\\nsumming the absolute differences of their coordinates\\n• Jaccard Distance - Computes the dissimilarity between two sets by\\ndividing the size of their intersection by the size of their union.\\n• Hamming Distance - Measures the dissimilarity between two strings\\nby counting the positions in which they differ\\n3.2.3\\nSVD and PCA\\nThere is a problem with the vectors we created in one-hot encoding and TF-\\nIDF: they are sparse. A sparse vector is one that is mostly populated by zeroes.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 36, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='3.2.3\\nSVD and PCA\\nThere is a problem with the vectors we created in one-hot encoding and TF-\\nIDF: they are sparse. A sparse vector is one that is mostly populated by zeroes.\\nThey are sparse because most sentences don’t contain all the same words as\\nother sentences. For example, in our flit, we might encounter the word \"bird\"\\nin two sentences simultaneously, but the rest of the words will be completely\\ndifferent.\\n1\\nsparse_vector = [1,0,0,0,0,0,0,0,0,0]\\n2\\ndense_vector = [1,2,2,3,0,4,5,8,8,5]\\nFigure 30: Two types of vectors in text processing\\nSparse vectors result in a number of problems, among these cold start—the\\nidea that we don’t know to recommend items that haven’t been interacted with,\\nor for users who are new. What we’d like, instead, is to create dense vectors,\\nwhich will give us more information about the data, the most important of\\nwhich is accounting for the weight of a given word in proportion to other\\nwords. This is where we leave one-hot encodings and TD-IDF to move into'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 36, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='which is accounting for the weight of a given word in proportion to other\\nwords. This is where we leave one-hot encodings and TD-IDF to move into\\napproaches that are meant to solve for this sparsity. Dense vectors are just\\nvectors that have mostly non-zero values. We call these dense representations\\ndynamic representations [68].\\n37'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 37, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Several other related early approaches were used in lieu of TF-IDF for\\ncreating compact representations of items: principal components analysis\\n(PCA) and singular value decomposition (SVD).\\nSVD and PCA are both dimensionality reduction techniques that, applied\\nthrough matrix transformations to our original text input data, show us the\\nlatent relationship between two items by breaking items down into latent\\ncomponents through matrix transformations.\\nSVD is a type of matrix factorization that represents a given input feature\\nmatrix as the product of three matrices. It then uses the component matrices\\nto create linear combinations of features that are the largest differences from\\neach other and which are directionally different based on the variance of the\\nclusters of points from a given line. Those clusters represent the “feature\\nclusters” of the compressed features.\\nIn the process of performing SVD and decomposing these matrices, we'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 37, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='clusters of points from a given line. Those clusters represent the “feature\\nclusters” of the compressed features.\\nIn the process of performing SVD and decomposing these matrices, we\\ngenerate a matrix representation that includes the eigenvectors and eigenvalue\\npairs or the sample covariance pairs.\\nPCA uses the same initial input feature matrix, but whereas one-hot en-\\ncoding simply converts the text features into numerical features that we can\\nwork with, PCA also performs compression and projects our items into a\\ntwo-dimensional feature space. The first principal component is the scaled\\neigenvector of the data, the weights of the variables that describe your data\\nbest, and the second is the weights of the next set of variables that describe\\nyour data best.\\nThe resulting model is a projection of all the words, clustered into a single\\nspace based on these dimensions. While we can’t get individual meanings\\nof all these components, it’s clear that the clusters of words, aka features, are'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 37, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='space based on these dimensions. While we can’t get individual meanings\\nof all these components, it’s clear that the clusters of words, aka features, are\\nsemantically similar, that is they are close to each other in meaning20.\\nThe difference between the two is often confusing (people admitted as\\nmuch in the 80s [21] when these approaches were still being worked out),\\nand for the purposes of this survey paper we’ll say that PCA can often be\\nimplemented using SVD 21.\\n3.3\\nLDA and LSA\\nBecause PCA performs computation on each combination of features to gen-\\nerate the two dimensions, it becomes immensely computationally expensive\\nas the number of features grows. Many of these early methods, like PCA,\\nworked well for smaller datasets, like many of the ones used in traditional\\nNLP research, but as datasets continued to grow, they didn’t quite scale.\\nOther approaches grew out of TF-IDF and PCA to address their limitations,'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 37, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='NLP research, but as datasets continued to grow, they didn’t quite scale.\\nOther approaches grew out of TF-IDF and PCA to address their limitations,\\nincluding latent semantic analysis (LSA) and latent Dirichlet allocation\\n(LDA) [12]. Both of these approaches start with the input document matrix\\nthat we built in the last section. The underlying principle behind both of\\n20There are many definitions of semantic similarity - what does it mean for \"king\" and\\n\"queen\" to be close to each other? - but a high-level approach involves using original sources\\nlike thesauri and dictionaries to create a structured knowledge base and offer a structured\\nrepresentation of terms and concepts based on nodes and edges, aka how often they appear\\nnear each other. [6]\\n21This is how it’s implemented in the scikit-learn package\\n38'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 38, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='these models is that words that occur close together more frequently have\\nmore important relationships. LSA uses the same word weighting that we\\nused for TF-IDF and looks to combine that matrix into a lower rank matrix,\\na cosine similarity matrix. In the matrix, the values for the cells range from\\n[-1,1], where -1 represents documents that are complete opposites and 1 means\\nthe documents are identical. LSA then runs over the matrix and groups items\\ntogether.\\nLDA takes a slightly different approach. Although it uses the same matrix\\nfor input, it instead outputs a matrix where the rows are words and columns\\nare documents. The distance measure, instead of cosine similarity, is the\\nnumerical value for the topic that the intersection of the word and document\\nprovide. The assumption is that any sentence we input will contain a collection\\nof topics, based on proportions of representation in relation to the input\\ncorpus, and that there are a number of topics that we can use to classify'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 38, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='of topics, based on proportions of representation in relation to the input\\ncorpus, and that there are a number of topics that we can use to classify\\na given sentence. We initialize the algorithm by assuming that there is a\\nnon-zero probability that each word could appear in a topic. LDA initially\\nassigns words to topics at random, and then iterates until it converges to a\\npoint where it maximizes the probability for assigning a current word to a\\ncurrent topic. In order to do the word-to-topic mapping, LDA generates an\\nembedding that creates a space of clusters of words or sentences that work\\ntogether semantically.\\n3.4\\nLimitations of traditional approaches\\nAll of these traditional methods look to address the problem of generating\\nrelationships between items in our corpus in various ways in the latent space -\\nthe relationships between words that are not explicitly stated but that we can\\ntease out based on how we model the data.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 38, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='the relationships between words that are not explicitly stated but that we can\\ntease out based on how we model the data.\\nHowever, in all these cases, as our corpus starts to grow, we start to run\\ninto two problems: the curse of dimensionality and compute scale.\\n3.4.1\\nThe curse of dimensionality\\nAs we one-hot encode more features, our tabular data set grows. Going\\nback to our churn model, what happens once we have 181 instead of two\\nor three countries? We’ll have to encode each of them into their own vector\\nrepresentations. What happens if we have millions of vocabulary words, for\\nexample thousands of birds posting millions of messages every day? Our\\nsparse matrix for tf-idf becomes computationally intensive to factor.\\nWhereas our input vectors for tabular machine learning and naive text\\napproaches is only three entries because we only use three features, multi-\\nmodal data effectively has a dimensionality of the number of written words'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 38, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='approaches is only three entries because we only use three features, multi-\\nmodal data effectively has a dimensionality of the number of written words\\nin existence and image data has a dimensionality of height times width in\\npixels, for each given image. Video and audio data have similar exponential\\nproperties. We can profile the performance of any code we write using Big\\nO notation, which will classify an algorithm’s runtime. There are programs\\nthat perform worse and those that perform better based on the number of\\nelements the program processes. This means that one-hot encodings, in terms\\nof computing performance, are O(n) in the worst case complexity. So, if our\\n39'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 39, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='text is a corpus of a million unique words, we’ll get to a million columns, or\\nvectors, each of which will be sparse, since most sentences will not contain the\\nwords of other sentences.\\nLet’s take a more concrete case. Even in our simple case of our initial\\nbird quote, we have 28 features, one for each word in the sentence, assuming\\nwe don’t remove and process the most common stop words — extremely\\ncommon words like \"the\", \"who\", and \"is\" that appear in most texts but don’t\\nadd semantic meaning. How can we create a model that has 28 features?\\nThat’s fairly simple if tedious - we encode each word as a numerical value.\\nTable 5: One-hot encoding and the growing curse of dimensionality for our flit\\nflit_id\\nbird_id\\nhold\\nfast\\ndreams\\ndie\\nlife\\nbird\\n9823420\\n012\\n1\\n1\\n1\\n1\\n1\\n1\\n9823421\\n013\\n1\\n0\\n0\\n0\\n0\\n1\\nNot only will it be hard to run computations over a linearly increasing\\nset, once we start generating a large number of features (columns), we start'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 39, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='9823420\\n012\\n1\\n1\\n1\\n1\\n1\\n1\\n9823421\\n013\\n1\\n0\\n0\\n0\\n0\\n1\\nNot only will it be hard to run computations over a linearly increasing\\nset, once we start generating a large number of features (columns), we start\\nrunning into the curse of dimensionality, which means that, the more features\\nwe accumulate, the more data we need in order to accurately statistically\\nconfidently say anything about them, which results in models that may not\\naccurately represent our data [29] if we have extremely sparse features, which\\nis generally the case in user/item interactions in recommendations.\\n3.4.2\\nComputational complexity\\nIn production machine learning systems, the statistical properties of our al-\\ngorithm are important. But just as critical is how quickly our model returns\\ndata, or the system’s efficiency. System efficiency can be measured in many\\nways, and it is critical in any well-performing system to find the performance\\nbottleneck that leads to latency, or the time spent waiting before an operation'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 39, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='ways, and it is critical in any well-performing system to find the performance\\nbottleneck that leads to latency, or the time spent waiting before an operation\\nis performed [26]. If you have a recommendation system in production, you\\ncannot risk showing the user an empty feed or a feed that takes more than\\na few milliseconds to render. If you have a search system, you cannot risk\\nthe results taking more than a few milliseconds to return, particularly in e-\\ncommerce settings [2]. From the holistic systems perspective then, we can also\\nhave latency in how long it takes to generate data for a model, read in data,\\nand train the model.\\nThe two big drivers of latency are:\\n• I/O processing - We can only send as many items over the network as\\nour network speed allows\\n• CPU processing - We can only process as many items as we have memory\\navailable to us in any given system22\\nGenerally, TF-IDF performs well in terms of identifying key terms in the'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 39, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• CPU processing - We can only process as many items as we have memory\\navailable to us in any given system22\\nGenerally, TF-IDF performs well in terms of identifying key terms in the\\ndocument. However, since the algorithm processes all the elements in a\\n22there has been discussion over the past few years on whether IO or CPU are really the\\nbottleneck in any modern data-intensive application.\\n40'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 40, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='given corpus, the time complexity grows for both the numerator and the\\ndenominator in the equation and overall, the time-complexity of computing\\nthe TF-IDF weights for all the terms in all the documents is O(Nd), where N\\nis the total number of terms in the corpus and d is the number of documents\\nin the corpus. Additionally, because TF-IDF creates a matrix as output, what\\nwe end up doing is processing enormous state matrices. For example, if you\\nhave 100k documents and need to store frequency counts and features for the\\ntop five thousand words appearing in those documents, we get a matrix of\\nsize 100000 ∗5000. This complexity only grows.\\nThis linear time complexity growth becomes an issue when we’re trying\\nto process millions or hundreds of millions of tokens – usually a synonym\\nfor words but can also be sub-words such as syllables. This is a problem that\\nbecame especially prevalent as, over time in industry, storage became cheap.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 40, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='for words but can also be sub-words such as syllables. This is a problem that\\nbecame especially prevalent as, over time in industry, storage became cheap.\\nFrom newsgroups to emails, and finally, to public internet text, we began\\nto generate a lot of digital exhaust and companies collected it in the form of\\nappend-only logs [36], a sequence of records ordered by time, that’s configured\\nto continuously append records.23 .\\nCompanies started emitting, keeping, and using these endless log streams\\nfor data analysis and machine learning. All of a sudden, the algorithms that\\nhad worked well on a collection of less than a million documents struggled to\\nkeep up.\\nCapturing log data at scale began the rise of the Big Data era, which\\nresulted in a great deal of variety, velocity, and volume of data movement.\\nThe rise in data volumes coincided with data storage becoming much cheaper,\\nenabling companies to store everything they collected on racks of commodity\\nhardware.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 40, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='The rise in data volumes coincided with data storage becoming much cheaper,\\nenabling companies to store everything they collected on racks of commodity\\nhardware.\\nCompanies were already retaining analytical data needed to run critical\\nbusiness operations in relational databases, but access to that data was struc-\\ntured and processed in batch increments on a daily or weekly basis. This new\\nlogfile data moved quickly, and with a level of variety absent from traditional\\ndatabases.\\nThe resulting corpuses for NLP, search, and recommendation problems\\nalso exploded in size, leading people to look for more performant solutions.\\n3.5\\nSupport Vector Machines\\nThe first modeling approaches were shallow models — models that perform\\nmachine learning tasks using only one layer of weights and biases [9]. Support\\nvector machines (SVM), developed at Bell Laboratories in the mid-1990s,\\nwere used in high-dimensional spaces for NLP tasks like text categorization'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 40, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='vector machines (SVM), developed at Bell Laboratories in the mid-1990s,\\nwere used in high-dimensional spaces for NLP tasks like text categorization\\n[32]. SVMs separate data clusters into points that are linearly separable by a\\nhyperplane, a decision boundary that separates elements into separate classes.\\nIn a two-dimensional vector space, the hyperplane is a line, in a three or more\\ndimensional space, the separator also comes in many dimensions.\\nThe goal of the SVM is to find the optimal hyperplane such that the dis-\\ntance between new projections of objects (words in our case) into the space\\n23Jay Kreps’ canonical posts on how logging works are a must-read\\n41'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 41, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='maximizes the distance between the plane and the elements so there’s less\\nchance of mis-classifying them.\\nw · x + b > 1\\nw · x + b = 0\\nw · x + b < −1\\nMargin\\nFigure 31: Example of points in the vector space in an SVM separated by a hyperplane\\nExamples of supervised machine learning tasks performed with SVMs\\nincluded next word prediction, predicting the missing word in a given se-\\nquence, and predicting words that occur in a window. As an example, the\\nclassical word embedding inference task is autocorrect when we’re typing on\\nour phones. We type a word, and it’s the job of the autocorrect to predict the\\ncorrect word based on both the word itself and the surrounding context in the\\nsentence. It therefore needs to learn a vocabulary of embeddings that will give\\nit probabilities that it is selecting the correct word.\\nHowever, as in other cases, when we reach high dimensions, SVMs com-\\npletely fail to work with sparse data because they rely on computing distances'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 41, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='However, as in other cases, when we reach high dimensions, SVMs com-\\npletely fail to work with sparse data because they rely on computing distances\\nbetween points to determine the decision boundaries. Because in our sparse\\nvector representations of elements most of the distances are zero, the hyper-\\nplane will fail to cleanly separate the boundaries and classify words incorrectly.\\n3.6\\nWord2Vec\\nTo get around the limitations of earlier textual approaches and keep up with\\ngrowing size of text corpuses, in 2013, researchers at Google came up with an\\nelegant solution to this problem using neural networks, called Word2Vec [47].\\nSo far, we’ve moved from simple heuristics like one-hot encoding, to\\nmachine learning approaches like LSA and LDA that look to learn a dataset’s\\nmodeled features. Previously, like our original one-hot encodings, all the\\napproaches to embedding focused on generating sparse vectors that can give\\nan indication that two words are related, but not that there is a semantic'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 41, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='approaches to embedding focused on generating sparse vectors that can give\\nan indication that two words are related, but not that there is a semantic\\nrelationship between them. For example, “The dog chased the cat” and “the\\ncat chased the dog” would have the same distance in the vector space, even\\nthough they’re two completely different sentences.\\nWord2Vec is a family of models that has several implementations, each\\nof which focus on transforming the entire input dataset into vector represen-\\n42'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 42, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='tations and, more importantly, focusing not only on the inherent labels of\\nindividual words, but on the relationship between those representations.\\nThere are two modeling approaches to Word2Vec - continuous bag of\\nwords (CBOW) and skipgrams, both of which generate dense vectors of\\nembeddings but model the problem slightly differently. The end-goal of the\\nWord2Vec model in either case is to learn the parameters that maximize that\\nprobability of a given word or group of words being an accurate prediction\\n[23].\\nIn training skipgrams, we take a word from the initial input corpus and\\npredict the probability that a given set of words surround it. In the case of\\nour initial flit quote, \"Hold fast to dreams for if dreams die, life is a broken-\\nwinged bird that cannot fly\", the model’s intermediate steps generate a set of\\nembeddings that’s the distance between all the words in the dataset and fill\\nin the next several probabilities for the entire phrase, using the word \"fast\" as\\ninput.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 42, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='embeddings that’s the distance between all the words in the dataset and fill\\nin the next several probabilities for the entire phrase, using the word \"fast\" as\\ninput.\\nFigure 32: Word2Vec Architecture\\nIn training CBOW, we do the opposite: we remove a word from the middle\\nof a phrase known as the context window and train a model to predict the\\nprobability that a given word fills the blank, shown in the equation below\\nwhere we attempt to maximize.\\narg max\\nθ\\n∏\\nw∈Text\\n\"\\n∏\\nc∈C(w)\\np(c|w; θ)\\n#\\n(11)\\nIf we optimize these parameters - theta - and maximize the probability that\\n43'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 43, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='the word belongs in the sentences, we’ll learn good embeddings for our input\\ncorpus.\\nLet’s focus on a detailed implementation of CBOW to better understand\\nhow this works. This time, for the code portion, we’ll move on from scikit-\\nlearn, which works great for smaller data, to PyTorch for neural net operations.\\nAt a high level, we have a list of input words that are processed through a\\nsecond layer, the embedding layer, and then through the output layer, which\\nis just a linear model that returns probabilities.\\nWord #1\\nWord #2\\nWord #3\\nWord #4\\nOutput Probability\\nEmbeddings\\nInput\\nCorpus\\nLinear\\nRegression\\nFigure 33: Word2Vec CBOW Neural Network architecture\\nWe’ll run this implementation in PyTorch, the popular library for building\\nneural network models. The best way to implement Word2Vec, especially if\\nyou’re dealing with smaller datasets, is using Gensim, but Gensim abstracts\\naway the layers into inner classes, which makes for a fantastic user experi-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 43, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='you’re dealing with smaller datasets, is using Gensim, but Gensim abstracts\\naway the layers into inner classes, which makes for a fantastic user experi-\\nence. But, since we’re just learning about them, we’d like to see a bit more\\nexplicitly how they work, and PyTorch, although it does not have a native\\nimplementation of Word2Vec, lets us see the inner workings a bit more clearly.\\nTo model our problem in PyTorch, we’ll use the same approach as with\\nany problem in machine learning:\\n• Inspect and clean our input data.\\n• Build the layers of our model. (For traditional ML, we’ll have only\\none)\\n• Feed the input data into the model and track the loss curve\\n• Retrieve the trained model artifact and use it to make predictions on\\nnew items that we analyze\\n44'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 44, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 34: Steps for creating Word2Vec model\\nLet’s start from our input data. In this case, our corpus is all of the flits\\nwe’ve collected. We first need to process them as input into our model.\\n1\\nresponses = [\"Hold fast to dreams, for if dreams die, life is a broken-winged\\nbird that cannot fly.\", \"No bird soars too high if he soars with his own\\nwings.\", \"A bird does not sing because it has an answer, it sings because\\nit has a song.\"]\\n,→\\n,→\\n,→\\nFigure 35: Our Word2Vec input dataset\\nLet’s start with our input training data, which is our list of flits. To prepare\\ninput data for PyTorch, we can use the DataLoader or Vocab classes, which\\nsplits our text into tokens and tokenizes — or creates smaller, word-level\\nrepresentations of each sentence — for processing. For each line in the file, we\\ngenerate tokens by splitting each line into single words, removing whitespace\\nand punctuation, and lowercasing each individual word.\\nThis kind of processing pipeline is extremely common in NLP and spend-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 44, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='and punctuation, and lowercasing each individual word.\\nThis kind of processing pipeline is extremely common in NLP and spend-\\ning time to get this step right is extremely critical so that we get clean, correct\\ninput data. It typically includes [48]:\\n• Tokenization - transforming a sentence or a word into its component\\ncharacter by splitting it\\n• Removing noise - Including URLs, punctuation, and anything else in\\nthe text that is not relevant to the task at hand\\n• Word segmentation - Splitting our sentences into individual words\\n• Correcting spelling mistakes\\n45'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 45, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nclass TextPreProcessor:\\n2\\ndef __init__(self) -> None:\\n3\\nself.input_file = input_file\\n4\\n5\\ndef generate_tokens(self):\\n6\\nwith open(self.input_file, encoding=\"utf-8\") as f:\\n7\\nfor line in f:\\n8\\nline = line.replace(\"\\\\\\\\\", \"\")\\n9\\nyield line.strip().split()\\n10\\n11\\ndef build_vocab(self) -> Vocab:\\n12\\nvocab = build_vocab_from_iterator(\\n13\\nself.generate_tokens(), specials=[\"<unk>\"], min_freq=100\\n14\\n)\\n15\\nreturn vocab\\nFigure 36: Processing our input vocabulary and building a Vocabulary object from our\\ndataset in PyTorch\\nNow that we have an input vocabulary object we can work with, the next\\nstep is to create one-hot encodings of each word to a numerical position, and\\neach position back to a word, so that we can easily reference both our words\\nand vectors. The goal is to be able to map back and forth when we do lookups\\nand retrieval.\\nThis occurs in the Embedding layer. Within the Embedding layer of Py-\\nTorch, we initialize an Embedding matrix based on the size we specify and'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 45, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='and retrieval.\\nThis occurs in the Embedding layer. Within the Embedding layer of Py-\\nTorch, we initialize an Embedding matrix based on the size we specify and\\nsize of our vocabulary, and the layer indexes the vocabulary into a dictionary\\nfor retrieval. The embedding layer is a lookup table24 that matches a word to\\nthe corresponding word vector on an index by index basis. Initially, we create\\nour one-hot encoded word to term dictionary. Then, we create a mapping of\\neach word to a dictionary entry and a dictionary entry to each word. This\\nis known as bijection. In this way, the Embedding layer is like a one-hot\\nencoded matrix, and allows us to perform lookups. The lookup values in this\\nlayer are initialized to a set of random weights, which we next pass onto the\\nlinear layer.\\nEmbeddings resemble hash maps and also have their performance char-\\nacteristics (O(1) retrieval and insert time), which is why they can scale easily'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 45, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='linear layer.\\nEmbeddings resemble hash maps and also have their performance char-\\nacteristics (O(1) retrieval and insert time), which is why they can scale easily\\nwhen other approaches cannot. In the embedding layer, Word2Vec where each\\nvalue in the vector represents the word on a specific dimension, and more\\nimportantly, unlike many of the other methods, the value of each vector is in\\ndirect relationship to the other words in the input dataset.\\n24Embedding Layer PyTorch documents\\n46'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 46, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content=\"1\\nclass CBOW(torch.nn.Module):\\n2\\ndef __init__(self):\\n# we pass in vocab_size and embedding_dim as hyperparams\\n3\\nsuper(CBOW, self).__init__()\\n4\\nself.num_epochs = 3\\n5\\nself.context_size = 2\\n# 2 words to the left, 2 words to the right\\n6\\nself.embedding_dim = 100\\n# Size of your embedding vector\\n7\\nself.learning_rate = 0.001\\n8\\nself.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n9\\n10\\nself.vocab = TextPreProcessor().build_vocab()\\n11\\nself.word_to_ix = self.vocab.get_stoi()\\n12\\nself.ix_to_word = self.vocab.get_itos()\\n13\\nself.vocab_list = list(self.vocab.get_stoi().keys())\\n14\\nself.vocab_size = len(self.vocab)\\n15\\n16\\nself.model = None\\n17\\n18\\n# out: 1 x embedding_dim\\n19\\nself.embeddings = nn.Embedding(\\n20\\nself.vocab_size, self.embedding_dim\\n21\\n)\\n# initialize an Embedding matrix based on our inputs\\n22\\nself.linear1 = nn.Linear(self.embedding_dim, 128)\\n23\\nself.activation_function1 = nn.ReLU()\\n24\\n25\\n# out: 1 x vocab_size\\n26\\nself.linear2 = nn.Linear(128, self.vocab_size)\\n27\"),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 46, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='22\\nself.linear1 = nn.Linear(self.embedding_dim, 128)\\n23\\nself.activation_function1 = nn.ReLU()\\n24\\n25\\n# out: 1 x vocab_size\\n26\\nself.linear2 = nn.Linear(128, self.vocab_size)\\n27\\nself.activation_function2 = nn.LogSoftmax(dim=-1)\\nFigure 37: Word2Vec CBOW implementation in Pytorch. source\\nOnce we have our lookup values, we can process all our words. For CBOW,\\nwe take a single word and we pick a sliding window, in our case, two words\\nbefore, and two words after, and try to infer what the actual word is. This is\\ncalled the context vector, and in other cases, we’ll see that it’s called attention.\\nFor example, if we have the phrase \"No bird [blank] too high\", we’re trying to\\npredict that the answer is \"soars\" with a given softmax probability, aka ranked\\nagainst other words. Once we have the context vector, we look at the loss —\\nthe difference between the true word and the predicted word as ranked by\\nprobability — and then we continue.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 46, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='against other words. Once we have the context vector, we look at the loss —\\nthe difference between the true word and the predicted word as ranked by\\nprobability — and then we continue.\\nThe way we train this model is through context windows. For each given\\nword in the model, we create a sliding window that includes that word and 2\\nwords before it, and 2 words after it.\\nWe activate the linear layer with a ReLu activation function, which decides\\nwhether a given weight is important or not. In this case, ReLu squashes all the\\nnegative values we initialize our embeddings layer with down to zero since\\nwe can’t have inverse word relationships, and we perform linear regression\\nby learning the weights of the model of the relationship of the words. Then,\\nfor each batch we examine the loss, the difference between the real word and\\nthe word that we predicted should be there given the context window - and\\n47'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 47, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='we minimize it.\\nAt the end of each epoch, or pass through the model, we pass the weights,\\nor backpropagate them, back to the linear layer, and then again, update the\\nweights of each word, based on the probability. The probability is calculated\\nthrough a softmax function, which converts a vector of real numbers into a\\nprobability distribution - that is, each number in the vector, i.e. the value of the\\nprobability of each words, is in the interval between 0 and 1 and all of the word\\nnumbers add up to one. The distance, as backpropagated to the embeddings\\ntable, should converge or shrink depending on the model understanding how\\nclose specific words are.\\n48'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 48, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\n2\\ndef make_context_vector(self, context, word_to_ix) -> torch.LongTensor:\\n3\\n\"\"\"\\n4\\nFor each word in the vocab, find sliding windows of [-2,1,0,1,2] indexes\\n5\\nrelative to the position of the word\\n6\\n:param vocab: list of words in the vocab\\n7\\n:return: torch.LongTensor\\n8\\n\"\"\"\\n9\\nidxs = [word_to_ix[w] for w in context]\\n10\\ntensor = torch.LongTensor(idxs)\\n11\\n12\\n13\\ndef train_model(self):\\n14\\n15\\n# Loss and optimizer\\n16\\nself.model = CBOW().to(self.device)\\n17\\noptimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\\n18\\nloss_function = nn.NLLLoss()\\n19\\n20\\nlogging.warning(\\'Building training data\\')\\n21\\ndata = self.build_training_data()\\n22\\n23\\nlogging.warning(\\'Starting forward pass\\')\\n24\\nfor epoch in tqdm(range(self.num_epochs)):\\n25\\n# we start tracking how accurate our initial words are\\n26\\ntotal_loss = 0\\n27\\n28\\n# for the x, y in the training data:\\n29\\nfor context, target in data:\\n30\\ncontext_vector = self.make_context_vector(context, self.word_to_ix)\\n31\\n32\\n# we look at loss\\n33'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 48, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='26\\ntotal_loss = 0\\n27\\n28\\n# for the x, y in the training data:\\n29\\nfor context, target in data:\\n30\\ncontext_vector = self.make_context_vector(context, self.word_to_ix)\\n31\\n32\\n# we look at loss\\n33\\nlog_probs = self.model(context_vector)\\n34\\n35\\n# compare loss\\n36\\ntotal_loss += loss_function(\\n37\\nlog_probs, torch.tensor([self.word_to_ix[target]])\\n38\\n)\\n39\\n40\\n# optimize at the end of each epoch\\n41\\noptimizer.zero_grad()\\n42\\ntotal_loss.backward()\\n43\\noptimizer.step()\\n44\\n45\\n# Log out some metrics to see if loss decreases\\n46\\nlogging.warning(\"end of epoch {} | loss {:2.3f}\".format(epoch, total_loss))\\n47\\n48\\ntorch.save(self.model.state_dict(), self.model_path)\\n49\\nlogging.warning(f\\'Save model to {self.model_path}\\')\\nFigure 38: W\\nord2Vec CBOW implementation in PyTorch\\nsee full implementation here\\n49'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 49, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Once we’ve completed our iteration through our training set, we have\\nlearned a model that retrieves both the probability of a given word being the\\ncorrect word, and the entire embedding space for our vocabulary.\\n4\\nModern Embeddings Approaches\\nWord2Vec became one of the first neural network architectures to use the con-\\ncept of embedding to create a fixed feature vocabulary. But neural networks\\nas a whole were gaining popularity for natural language modeling because\\nof several key factors. First, in the 1980s, researchers made advancements in\\nusing the technique of backpropagation for training neural networks learning\\n[53]. Backpropagation is how a model learns to converge by calculating the\\ngradient of the loss function with respect to the weights of the neural network,\\nusing the chain rule, a concept from calculus which allows us to calculate\\nthe derivative of a function made up of multiple functions. This mechanism'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 49, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='using the chain rule, a concept from calculus which allows us to calculate\\nthe derivative of a function made up of multiple functions. This mechanism\\nallows the model to understand when it’s reached a global minimum for loss\\nand picks the correct weights for the model parameters, but training models\\nthrough gradient descent. Earlier approaches, such as the perceptron learning\\nrule, tried to do this, but had limitations, such as being able to work only\\non simple layer architectures, took a long time to converge, and experienced\\nvanishing gradients, which made it hard to effectively update the model’s\\nweights.\\nThese advances gave rise to the first kinds of multi-level neural networks,\\nfeed-forward neural networks. In 1998, a paper used backpropagation over\\nmultilayer perceptrons to correctly perform the task of recognizing handwrit-\\nten digit images [40], demonstrating a practical use-case practitioners and\\nresearchers could apply. This MNIST dataset is now one of the canonical'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 49, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='ten digit images [40], demonstrating a practical use-case practitioners and\\nresearchers could apply. This MNIST dataset is now one of the canonical\\n\"Hello World\" examples of deep learning.\\nSecond, in the 2000s, the rise of petabytes of aggregated log data resulted\\nin the creation of large databases of multimodal input data scraped from the\\ninternet. This made it possible to conduct wide-ranging experiments to prove\\nthat neural networks work on large amounts of data. For example, ImageNet\\nwas developed by researchers at Stanford who wanted to focus on improving\\nmodel performance by creating a gold set of neural network input data, the\\nfirst step in processing. FeiFei Li assembled a team of students and paid\\ngig workers from Amazon Turk to correctly label a set of 3.2 million images\\nscraped from the internet and organized based on categories according to\\nWordNet, a taxonomy put together by researchers in the 1970s [55].\\nResearchers saw the power of using standard datasets. In 2015, Alex'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 49, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='WordNet, a taxonomy put together by researchers in the 1970s [55].\\nResearchers saw the power of using standard datasets. In 2015, Alex\\nKrizhevsky, in collaboration with Ilya Sutskever, who now works at OpenAI\\nas one of the leading researchers behind the GPT series of models that form the\\nbasis of the current generative AI wave, submitted an entry to the ImageNet\\ncompetition called AlexNet. This model was a convolutional neural network\\nthat outperformed many other methods. There were two things that were\\nsignificant about AlexNet. The first was that it had eight stacked layers of\\nweights and biases, which was unusual at the time. Today, 12-layer neural.\\nnetworks like BERT and other transformers are completely normal, but at the\\ntime, more than two layers was revolutionary. The second was that it ran on\\n50'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 50, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='GPUs, a new architectural concept at the time, since GPUs were used mostly\\nfor gaming.\\nNeural networks started to become popular as ways to generate represen-\\ntations of vocabularies. In particular, neural network architectures, such as\\nand recurrent neural networks (RNNs) and later long short-term memory\\nnetworks (LSTMs) also emerged as ways to deal with textual data for all kinds\\nof machine learning tasks from NLP to computer vision.\\n4.1\\nNeural Networks\\nNeural networks are extensions on traditional machine learning models, but\\nthey have a few critical special properties. Let’s think back to our definition\\nof a model when we formalized a machine learning problem. A model is a\\nfunction with a set of learnable input parameters that takes some set of inputs\\nand one set of tabular input features, and gives us an output. In traditional\\nmachine learning approaches, there is one set, or layer, of learnable parameters\\nand one model. If our data doesn’t have complex interactions, our model can'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 50, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='machine learning approaches, there is one set, or layer, of learnable parameters\\nand one model. If our data doesn’t have complex interactions, our model can\\nlearn the feature space fairly easily and make accurate predictions.\\nHowever, when we start dealing with extremely large, implicit feature\\nspaces, such as are present in text, audio, or video, we will not be able to derive\\nspecific features that wouldn’t be obvious if we were manually creating them.\\nA neural network, by stacking neurons, each of which represent some aspect\\nof the model, can tease out these latent representations. Neural networks\\nare extremely good at learning representations of data, with each level of the\\nnetwork transforming a learned representation of the level to a higher level\\nuntil we get a clear picture of our data [41].\\n4.1.1\\nNeural Network architectures\\nWe’ve already encountered our first neural network, Word2Vec, which seeks to\\nunderstand relationships between words in our text that the words themselves'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 50, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='4.1.1\\nNeural Network architectures\\nWe’ve already encountered our first neural network, Word2Vec, which seeks to\\nunderstand relationships between words in our text that the words themselves\\nwould not tell us. Within the neural network space, there are several popular\\narchitectures:\\n• Feed-forward networks that extract meaning from fixed-length in-\\nputs. Results of these model are not fed back into the model for\\niteration\\n• Convolutional neural nets (CNNs) - used mainly for image process-\\ning, which involves a convolutional layer made up of a filter that\\nmoves across an image to check for feature representations which\\nare then multiplied via dot product with the filter to pull out specific\\nfeatures\\n• recurrent neural networks, which take a sequence of items and\\nproduce a vector that summarizes the sentence\\nRNNs and CNNs are used mainly in feature extraction - they generally\\ndo not represent the entire modeling flow, but are fed later into feed-forward'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 50, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='produce a vector that summarizes the sentence\\nRNNs and CNNs are used mainly in feature extraction - they generally\\ndo not represent the entire modeling flow, but are fed later into feed-forward\\nmodels that do the final work of classification, summarization, and more.\\n51'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 51, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Neural Networks\\nFeedforward\\nSingle-layer\\nMulti-layer\\nRecurrent\\nElman\\nJordan\\nLSTM\\nGRU\\nConvolutional\\nAutoencoder\\nVanilla\\nVariational\\nGenerative Adversarial\\nRadial Basis Function\\nFigure 39: Types of Neural Networks\\nNeural networks are complex to build and manage for a number of reasons.\\nFirst, they require extremely large corpuses of clean, well-labeled data to\\nbe optimized. They also require special GPU architectures for processing,\\nand, as we’ll see in the production section, they have their own metadata\\nmanagement and latency considerations. Finally, within the network itself,\\nwe need to complete a large amount of passes we need to do over the model\\nobject using batches of our training data to get it to converge. The number of\\nfeature matrices that we need to run calculations over25, and, consequently,\\nthe amount of data we have to keep in-memory through the lifecycle of the\\nmodel ends up accumulating and requires a great deal of performance tuning.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 51, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='the amount of data we have to keep in-memory through the lifecycle of the\\nmodel ends up accumulating and requires a great deal of performance tuning.\\nThese features made developing and running neural networks pro-\\nhibitively expensive until the last fifteen years or so. First, the exponential\\nincrease in storage space provided by the growing size of commodity hard-\\nware both on-prem and in the cloud meant that we could now store that data\\nfor computation, and the explosion of log data gave companies such as Google\\na lot of training data to work with. Second, the rise of the GPU as a tool that\\ntakes advantage of the neural network’s ability to perform embarrassingly\\nparallel computation — a characteristic of computation when it’s easy to sepa-\\nrate steps out into ones that can be performed in parallel, such as word count\\nfor example. In a neural network, we can generally parallelize computation in\\nany given number of ways, including at the level of a single neuron.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 51, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='for example. In a neural network, we can generally parallelize computation in\\nany given number of ways, including at the level of a single neuron.\\n25There is no good single resource for calculating the computational complexity of a neural\\nnetwork given that there are many wide-ranging architectures but this post does a good job\\nlaying out the case that it’s essentially O(n5)\\n52'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 52, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='While GPUs were initially used for working with computer graphics, in the\\nearly 2000s [49], researchers discovered the potential to use them for general\\ncomputation, and Nvidia made an enormous bet on this kind of computing by\\nintroducing CUDA, an API layer on top of GPUs. This in turn allowed for the\\ncreation and development of high-level popular deep learning frameworks\\nlike PyTorch and Tensorflow.\\nNeural networks could now be trained and experimented with at scale. To\\ncome back to a comparison to our previous approaches, when we calculate TF-\\nIDF, we need to loop over each individual word and perform our computations\\nover the entire dataset in sequence to arrive at a score in proportion to all other\\nwords, which means that our computational complexity will be O(ND) [10].\\nHowever, with a neural network, we can either distribute the model train-\\ning across different GPUs in a process known as model parallelism, or com-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 52, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='However, with a neural network, we can either distribute the model train-\\ning across different GPUs in a process known as model parallelism, or com-\\npute batches — the size of the training data fed into the model and used in a\\ntraining loop before its hyperparameters are updated in parallel and update\\nat the end of each minibatch, which is known as data parallelism. [60].\\n4.2\\nTransformers\\nWord2Vec is a feed-forward network. The model weights and information only\\nflows from the encoding state, to the hidden embedding layer, to the output\\nprobability layer. There is no feedback between the second and third layers,\\nwhich means that each given layer doesn’t know anything about the state of\\nthe layers that follow it. It can’t make inference suggestions longer than the\\ncontext window. This works really well for machine learning problems where\\nwe’re fine with a single, static vocabulary.\\nHowever, it doesn’t work well on long ranges of text that require under-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 52, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='context window. This works really well for machine learning problems where\\nwe’re fine with a single, static vocabulary.\\nHowever, it doesn’t work well on long ranges of text that require under-\\nstanding words in context of each other. For example, over the course of a\\nconversation, we might say, \"I read that quote by Langston Hughes. I liked\\nit, but didn’t really read his later work,\" we understand that \"it\" refers to\\nthe quote, context from the previous sentence, and \"his\" refers to \"Langston\\nHughes\", mentioned two sentences ago.\\nOne of the other limitations was that Word2Vec can’t handle out-of-\\nvocabulary words — words that the model has not been trained on and\\nneeds to generalize to. This means that if our users search for a new trending\\nterm or we want to recommend a flit that was written after our model was\\ntrained, they won’t see any relevant results from our model. [14], unless the\\nmodel is retrained frequently.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 52, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='term or we want to recommend a flit that was written after our model was\\ntrained, they won’t see any relevant results from our model. [14], unless the\\nmodel is retrained frequently.\\nAnother problem is that Word2Vec encounters context collapse around\\npolysemy — the coexistence of many possible meanings for the same phrase:\\nfor example, if you have \"jail cell\" and \"cell phone\" in the same sentence, it\\nwon’t understand that the context of both words is different. Much of the\\nwork of NLP based in deep learning has been in understanding and retaining\\nthat context to propagate through the model and pull out semantic meaning.\\nDifferent approaches were proposed to overcome these limitations. Re-\\nsearchers experimented with recurrent neural networks, RNNs. An RNN\\nbuilds on traditional feed-forward networks, with the difference being that\\nlayers of the model give feedback to previous layers. This allows the model to\\n53'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 53, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='keep memory of the context around words in a sentence.\\nNeuron\\nxt\\nht\\n(a) Feedforward Neural Network\\nNeuron\\nxt\\nht\\n(b) Recurrent Neural Network\\nA problem with traditional RNNs was that because during backpropaga-\\ntion the weights had to be carried through to the previous layers of neurons,\\nthey experienced the problem of vanishing gradients. This occurs when we\\ncontinuously take the derivative such that the partial derivative used in the\\nchain rule during backpropagation approaches zero. Once we approach zero,\\nthe neural network assumes it has reached a local optimum and stops training,\\nbefore convergence.\\nA very popular variation of an RNN that worked around this problem\\nwas the long-short term memory network (LSTM), developed initially by\\nSchmidhuber26 and brought to popularity for use in text applications speech\\nrecognition and image captioning [33]. Whereas our previous model takes only\\na vector at a time as input, RNNs operate on sequences of vectors using GRUs,'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 53, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='recognition and image captioning [33]. Whereas our previous model takes only\\na vector at a time as input, RNNs operate on sequences of vectors using GRUs,\\nwhich allows the network to control how much information is passed in for\\nanalysis. While LSTMs worked fairly well, they had their own limitations.\\nBecause they were architecturally complicated, they took much longer to\\ntrain, and at a higher computational cost, because they couldn’t be trained in\\nparallel.\\n4.2.1\\nEncoders/Decoders and Attention\\nTwo concepts allowed researchers to overcome computationally expensive\\nissues with remembering long vectors for a larger context window than\\nwhat was available in RNNs and Word2Vec before it: the encoder/decoder\\narchitecture, and the attention mechanism.\\nThe encoder/decoder architecture is a neural network architecture com-\\nprised of two neural networks, an encoder that takes the input vectors from\\nour data and creates an embedding of a fixed length, and a decoder, also a'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 53, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='prised of two neural networks, an encoder that takes the input vectors from\\nour data and creates an embedding of a fixed length, and a decoder, also a\\nneural network, which takes the embeddings encoded as input and generates\\n26If you read Schmidhuber, you will come to the understanding that everything in deep\\nlearning was developed initially by Schmidhuber\\n54'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 54, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='a static set of outputs such as translated text or a text summary. In between\\nthe two types of layers is the attention mechanism, a way to hold the state\\nof the entire input by continuously performing weighted matrix multiplica-\\ntions that highlight the relevance of specific terms in relation to each other\\nin the vocabulary. We can think of attention as a very large, complex hash\\ntable that keeps track of the words in the text and how they map to different\\nrepresentations both in the input and the output.\\n-0.2\\n-0.1\\n0.1\\n0.4\\n-0.3\\n1.1\\nDecoder\\nEncoder\\nDecoder\\nTranslated\\ntext\\nInput\\ntext\\nFigure 41: The encoder/decoder architecture\\n55'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 55, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nclass EncoderDecoder(nn.Module):\\n2\\n\"\"\"\\n3\\nDefining the encoder/decoder steps\\n4\\n\"\"\"\\n5\\ndef __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\\n6\\nsuper(EncoderDecoder, self).__init__()\\n7\\nself.encoder = encoder\\n8\\nself.decoder = decoder\\n9\\nself.src_embed = src_embed\\n10\\nself.tgt_embed = tgt_embed\\n11\\nself.generator = generator\\n12\\n13\\ndef forward(self, src, tgt, src_mask, tgt_mask):\\n14\\n\"Take in and process masked src and target sequences.\"\\n15\\nreturn self.decode(self.encode(src, src_mask), src_mask,\\n16\\ntgt, tgt_mask)\\n17\\n18\\ndef encode(self, src, src_mask):\\n19\\nreturn self.encoder(self.src_embed(src), src_mask)\\n20\\n21\\ndef decode(self, memory, src_mask, tgt, tgt_mask):\\n22\\nreturn self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\\n23\\n24\\nclass Generator(nn.Module):\\n25\\n\"Define standard linear + softmax generation step.\"\\n26\\ndef __init__(self, d_model, vocab):\\n27\\nsuper(Generator, self).__init__()\\n28\\nself.proj = nn.Linear(d_model, vocab)\\n29\\n30\\ndef forward(self, x):\\n31'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 55, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='\"Define standard linear + softmax generation step.\"\\n26\\ndef __init__(self, d_model, vocab):\\n27\\nsuper(Generator, self).__init__()\\n28\\nself.proj = nn.Linear(d_model, vocab)\\n29\\n30\\ndef forward(self, x):\\n31\\nreturn F.log_softmax(self.proj(x), dim=-1)\\n32\\nFigure 42: A typical encoder/decoder architecture From the Annotated Transformer\\n\"Attention is All You Need\" [66], released in 2017, combined both of these\\nconcepts into a single architecture. The paper immediately saw a great deal\\nof success, and today Transformers are one of the de-facto models used for\\nnatural language tasks.\\nBased on the success of the original model, a great deal of variations on\\nTransformer architectures have been released, followed by GPT and BERT in\\n2018, Distilbert, a smaller and more compact version of BERT in 2019, and\\nGPT-3 in 202027.\\n27For a complete visual transformer timeline, check out this link\\n56'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 56, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Transformer\\nGPT\\nGPT-2\\nGPT-3\\nDALL-E\\nGPT-4\\nBERT\\nDistilBERT\\nRoBERTa\\nPaLM\\nFigure 43: Timeline of Transformer Models\\nTransformer architectures themselves are not new, but they contain all\\nthe concepts we’ve discussed so far: vectors, encodings, and hash maps.\\nThe goal of a transformer model is to take a piece of multimodal content,\\nand learn the latent relationships by creating multiple views of groups of\\nwords in the input corpus (multiple context windows). The self-attention\\nmechanism, implemented as scaled dot-product attention in the Transformer\\npaper, creates different context windows of the data a number of times through\\nthe six encoder and six decoder layers. The output is the result of the specific\\nmachine learning task — a translated sentence, a summarized paragraph –\\nand the next-to-last layer is the model’s embeddings, which we can use for\\ndownstream work.\\nFigure 44: View into transformer layers, inspired by multiple sources including this diagram'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 56, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='and the next-to-last layer is the model’s embeddings, which we can use for\\ndownstream work.\\nFigure 44: View into transformer layers, inspired by multiple sources including this diagram\\nThe transformer model described in the paper takes a corpus of text as\\ninput28. We first transform our text to token embeddings by tokenizing and\\nmapping every word or subword to an index. This is the same process as in\\nWord2Vec: we simply assign each word to an element in a matrix. However,\\nthese alone will not help us with context, so, on top of this, we also learn\\na positional embeddings with the help of a sine or cosine function that is\\nmapped and compressed into a matrix considering the position of all the other\\nword in the vocabulary. The final output of this process is the positional vector\\n28In theory you can use any modality for transformers without modifying the input other\\nthan to label the data with the given modality [71], but the early work, such as machine'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 56, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='28In theory you can use any modality for transformers without modifying the input other\\nthan to label the data with the given modality [71], but the early work, such as machine\\ntranslation, focuses on text, so we will as well\\n57'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 57, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='or the word encoding.\\nNext, these positional vectors are passed in parallel to the model. Within\\nthe Transformer paper, the model consists of six layers that perform encod-\\ning and six that perform decoding. We start with the encoder layer, which\\nconsists of two sub-layers: the self-attention layer, and a feed-forward neural\\nnetwork. The self-attention layer is the key piece, which performs the process\\nof learning the relationship of each term in relation to the other through scaled\\ndot-product attention. We can think of self-attention in several ways: as a\\ndifferentiable lookup table, or as a large lookup dictionary that contains both\\nthe terms and their positions, with the weights of each term in relationship to\\nthe other obtained from previous layers.\\nThe scaled dot-product attention is the product of three matrices: key,\\nquery, and value. These are initially all the same values that are outputs of\\nprevious layers - in the first pass through the model, they are initially all the'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 57, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='query, and value. These are initially all the same values that are outputs of\\nprevious layers - in the first pass through the model, they are initially all the\\nsame, initialized at random and adjusted at each step by gradient descent.\\nFor each embedding, we generate a weighted average value based on these\\nlearned attention weights. We calculate the dot product between query and\\nkey, and finally normalize the weights via softmax. Multi-head attention\\nmeans that we perform the process of calculating the scaled dot product\\nattention multiple times in parallel and concatenate the outcome into one\\nvector.\\nAttention(Q, K, V) = so f tmax(QKT\\n√dk\\n)V\\n(12)\\nWhat’s great about scaled dot-product attention (and about all of the layers\\nof the encoder) is that the work can be done in parallel across all the tokens in\\nour codebase: we don’t need to wait for one word to finish processing as we\\ndo in Word2Vec in order to process the next one, so the number of input steps'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 57, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='our codebase: we don’t need to wait for one word to finish processing as we\\ndo in Word2Vec in order to process the next one, so the number of input steps\\nremains the same, regardless of how big our vocabulary is.\\nThe decoder piece differs slightly from the encoder. It starts with a different\\ninput dataset: in the transformer paper, it’s the target language dataset we’d\\nlike to translate the text into. So for example if we were translating our Flit\\nfrom English to Italian, we’d expect to train on the Italian corpus. Otherwise,\\nwe perform all the same actions: we create indexed embeddings that we then\\nconvert into positional embeddings. We then feed the positional embeddings\\nfor the target text into a layer that has three parts: masked multi-headed\\nattention, multiheaded attention, and a feed-forward neural network. The\\nmasked multi-headed attention component is just like self-attention, with one\\nextra piece: the mask matrix introduced in this step acts as a filter to prevent'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 57, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='masked multi-headed attention component is just like self-attention, with one\\nextra piece: the mask matrix introduced in this step acts as a filter to prevent\\nthe attention head from looking at future tokens, since the input vocabulary\\nfor the decoder are our \"answers\", I.e. what the translated text should be.\\nThe output from the masked multi-head self attention layer is passed to the\\nencoder-decoder attention portion, which accepts the final input from the\\ninitial six encoder layers for the key and value, and uses the input from the\\nprevious decoder layer as the query, and then performs scaled dot-product\\nover this. Each output is then fed into the feed forward layer, to a finalized set\\nof embeddings.\\nOnce we have the hidden state for each token, we can then attach the task\\n58'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 58, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='head. In our case, this is prediction of what a word should be. At each step of\\nthe process, the decoder looks at the previous steps and generates based on\\nthose steps so we form a complete sentence [54]. We then get the predicted\\nword, just like in Word2Vec.\\nTransformers were revolutionary for a number of reasons, because they\\nsolved several problems people had been working on:\\n• Parallelization - Each step in the model is parallelizable, meaning we\\ndon’t need to wait to know the positional embedding of one word in\\norder to work on another, since each embedding lookup matrix focuses\\nattention on a specific word, with a lookup table of all other words in\\nrelationship to that word - each matrix for each word carries the context\\nwindow of the entire input text.\\n• Vanishing gradients - Previous models like RNNs can suffer from van-\\nishing or exploding gradients, which means that the model reaches a\\nlocal minimum before it’s fully-trained, making it challenging to cap-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 58, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='ishing or exploding gradients, which means that the model reaches a\\nlocal minimum before it’s fully-trained, making it challenging to cap-\\nture long-term dependencies. Transformers mitigate this problem by\\nallowing direct connections between any two positions in the sequence,\\nenabling information to flow more effectively during both forward and\\nbackward propagation.\\n• Self-attention - The attention mechanism allows us to learn the context\\nof an entire text that’s longer than a 2 or 3-word sliding context window,\\nallowing us to learn different words in different contexts and predict\\nanswers with more accuracy\\n4.3\\nBERT\\nFigure 45: Encoder-only architecture\\nAfter the explosive success of \"Attention is All you Need\", a variety of trans-\\nformer architectures arose, research and implementation in this architecture\\nexploded in deep learning. The next transformer architecture to be considered\\na significant step forward was BERT. BERT stands for Bi-Directional Encoder'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 58, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='exploded in deep learning. The next transformer architecture to be considered\\na significant step forward was BERT. BERT stands for Bi-Directional Encoder\\nand was released 2018 [13], based on a paper written by Google as a way\\nto solve common natural language tasks like sentiment analysis, question-\\nanswering, and text summarization. BERT is a transformer model, also based\\non the attention mechanism, but its architecture is such that it only includes\\nthe encoder piece. Its most prominent usage is in Google Search, where it’s\\nthe algorithm powering surfacing relevant search results. In the blog post\\nthey released on including BERT in search ranking in 2019, Google specifi-\\ncally discussed adding context to queries as a replacement for keyword-based\\n59'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 59, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='methods as a reason they did this.29\\nBERT works as a masked language model. Masking is simply what we\\ndid when we implemented Word2Vec by removing words and building our\\ncontext window. When we created our representations with Word2Vec, we\\nonly looked at sliding windows moving forward. The B in Bert is for bi-\\ndirectional, which means it pays attention to words in both ways through\\nscaled dot-product attention. BERT has 12 transformer layers. It starts by\\nusing WordPiece, an algorithm that segments words into subwords, into\\ntokens. To train BERT, the goal is to predict a token given its context.\\nThe output of BERT is latent representations of words and their context —\\na set of embeddings. BERT is, essentially, an enormous parallelized Word2Vec\\nthat remembers longer context windows. Given how flexible BERT is, it\\ncan be used for a number of tasks, from translation, to summarization, to\\nautocomplete. Because it doesn’t have a decoder component, it can’t generate'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 59, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='can be used for a number of tasks, from translation, to summarization, to\\nautocomplete. Because it doesn’t have a decoder component, it can’t generate\\ntext, which paved the way for GPT models to pick up where BERT left off.\\n4.4\\nGPT\\nAround the same time that BERT was being developed, another transformer\\narchitecture, the GPT series, was being developed at OpenAI. GPT differs\\nfrom BERT in that it encodes as well as decodes text from embeddings and\\ntherefore can be used for probabilistic inference.\\nThe original, first GPT model was trained as a 12-layer, 12-headed trans-\\nformer with only a decoder piece, based on data from Book Corpus. Sub-\\nsequent versions built on this foundation to try and improve context under-\\nstanding. The largest breakthrough was in GPT-4, which was trained with\\nreinforcement learning from Human Feedback, a property which allows it\\nto make inferences from text that feels much closer to what a human would\\nwrite.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 59, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='reinforcement learning from Human Feedback, a property which allows it\\nto make inferences from text that feels much closer to what a human would\\nwrite.\\nWe’ve now reached the forefront of what’s possible with embeddings\\nin this paper. With the rise of generative methods and methods based on\\nReinforcement Learning with Human Feedback like OpenAI’s ChatGPT, as\\nwell as the nascent open-source Llama, Alpaca, and other models, anything\\nwritten in this paper would already be impossibly out of date by the time it\\nwas published30.\\n5\\nEmbeddings in Production\\nWith the advent of Transformer models, and more importantly, BERT, gen-\\nerating representations of large, multimodal objects for use in all sorts of\\nmachine learning tasks suddenly became much easier, the representations\\nbecame more accurate, and if the company had GPUs available, computations\\ncould now be computed with speed-up in parallel. Now that we understand\\nwhat embeddings are, what should we do with them? After all, we’re not'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 59, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='could now be computed with speed-up in parallel. Now that we understand\\nwhat embeddings are, what should we do with them? After all, we’re not\\n29BERT search announcement\\n30There are already some studies about possible uses of LLMs for recommendations, includ-\\ning conversational recommender systems, but it’s still very early days. For more information\\ncheck out this post\\n60'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 60, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='doing this just as a math exercise. If there is one thing to take away from this\\nentire text, it is this:\\nThe final goal of all industrial machine learning (ML) projects is to develop\\nML products and rapidly bring them into production. [37]\\nThe model that is deployed is always better and more accurate than the\\nmodel that is only ever a prototype. We’ve gone through the process of\\ntraining embeddings end to end here, but there are several modalities for\\nworking with embeddings. We can:\\n• Train our own embeddings model - We can train BERT or some variation\\nof BERT from scratch. BERT uses an enormous amount of training\\ndata, so this is not really advantageous to us, unless we want to better\\nunderstand the internals and have access to a lot of GPUs.\\n• Use pretrained embeddings and fine-tune - There are many variations\\non BERT models and they all Variations of BERT have been used to\\ngenerate embeddings to use as downstream input into many recom-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 60, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• Use pretrained embeddings and fine-tune - There are many variations\\non BERT models and they all Variations of BERT have been used to\\ngenerate embeddings to use as downstream input into many recom-\\nmender and information retrieval systems. One of the largest gifts that\\nthe transformer architecture gives us is the ability to perform transfer\\nlearning.\\nBefore, when we learned embeddings in pre-transformer architectures,\\nour representation of whatever dataset we had at hand was fixed — we\\ncouldn’t change the weights of the words in TF-IDF without regenerating\\nan entire dataset.\\nNow, we have the ability to treat the output of the layers of BERT as input\\ninto the next neural network layer of our own, custom model. In addition to\\ntransfer learning, there are also numerous more compact models for BERT,\\nsuch as Distilbert and RoBERTA and for many of the larger models in places\\nlike the HuggingFace Model Hub31.\\nArmed with this knowledge, we can think of several use cases of embed-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 60, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='such as Distilbert and RoBERTA and for many of the larger models in places\\nlike the HuggingFace Model Hub31.\\nArmed with this knowledge, we can think of several use cases of embed-\\ndings, given their flexibility as a data structure.\\n• Feeding them into another model - For example, we can now per-\\nform collaborative filtering using both user and item embeddings\\nthat were learned from our data instead of coding the users and items\\nthemselves.\\n• Using them directly - We can use item embeddings directly for\\ncontent filtering - finding items that are closest to other items, a task\\nrecommendation shares with search. There are a host of algorithms\\nused to perform vector similarity lookups by projecting items into our\\nembedding space and performing similarity search using algorithms\\nlike faiss and HNSW.\\n31For a great writeup on the development of open-source machine learning deep learning,\\nsee \"A Call to Build Models Like We Build Open-Source Software\"\\n61'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 61, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='5.1\\nEmbeddings in Practice\\nMany companies are working with embeddings in all of these contexts today,\\nacross areas that span all aspects of information retrieval. Embeddings gen-\\nerated with deep learning models are being generated for use in wide and\\ndeep models for App Store recommendations at Google Play [73], dual em-\\nbeddings for product complementary content recommendations at Overstock\\n[38], personalization of search results at Airbnb via real-time ranking [25], us-\\ning embeddings for content understanding at Netflix [16], for understanding\\nvisual styles at Shutterstock [24], and many other examples.\\n5.1.1\\nPinterest\\nOne notable example is Pinterest. Pinterest as an application has a wide variety\\nof content that needs to be personalized and classified for recommendation to\\nusers across multiple surfaces, particularly the Homefeed and shopping tab.\\nThe scale of generated content - 350 million monthly users and 2 billion items'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 61, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='users across multiple surfaces, particularly the Homefeed and shopping tab.\\nThe scale of generated content - 350 million monthly users and 2 billion items\\n- Pins — or cards with an image described by text — necessitates a strong\\nfiltering and ranking policy.\\nTo represent a user’s interest and surface interesting content, Pinterest\\ndeveloped PinnerSage [50], which represents user interests through multiple\\n256-dimension embeddings that are clustered based on similarity and repre-\\nsented by medioids — an item that is a representative of a center of a given\\ninterest cluster.\\nThe foundation of this system is a set of embeddings developed through an\\nalgorithm called PinSage [72]. Pinsage generates embeddings using a Graph\\nConvolutional neural network, which is a neural net that takes into account the\\ngraph structure of relationships between nodes in the network. The algorithm\\nlooks at the nearest neighbors of a pin and samples from nearby pins based'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 61, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='graph structure of relationships between nodes in the network. The algorithm\\nlooks at the nearest neighbors of a pin and samples from nearby pins based\\non related neighborhood visits. The input is embeddings of a Pin: the image\\nembeddings, and the text embeddings, and finds the nearest neighbors.\\nPinsage embeddings are then passed to Pinnersage, which takes the pins\\nthe user has acted on for the past 90 days and clusters them. It computes the\\nmedioid and takes the top 3 medioids based on importance, and, given a user\\nquery that is a medioid, performs an approximate nearest neighbors search\\nusing HNSW to find the pins closest to the query in the embedding space.\\n62'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 62, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 46: Pinnersage and Pinsage embeddings-based similarity retrieval\\n5.1.2\\nYouTube and Google Play Store\\nYouTube\\nYouTube was one of the first large companies to publicly share their work on\\nembeddings used in the context of a production recommender system with\\n\"Deep Neural Networks for YouTube Recommendations.\"\\nYouTube has over 800 million pieces of content (videos) and 2.6 billion\\nactive users that they’d like to recommend those videos to. The application\\nneeds to recommend existing content to users, while also generalizing to new\\ncontent, which is uploaded frequently. They need to be able to serve these\\nrecommendations at inference time — when the user loads a new page —\\nwith low latency.\\nIn this paper [11], YouTube shares how they created a two-stage recom-\\nmender system for videos based on two deep learning models. The machine\\nlearning task is to predict the correct next video to show the user at a given\\ntime in YouTube recommendations so that they click. The final output is'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 62, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='learning task is to predict the correct next video to show the user at a given\\ntime in YouTube recommendations so that they click. The final output is\\nformulated as a classification problem: given a user’s input features and the\\ninput features of a video, can we predict a class for the user that includes the\\npredicted watch time for the user for a specific video with a specific probability.\\nFigure 47: YouTube’s end-to-end video recommender system, including a candidate generator\\nand ranker [11]\\n63'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 63, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='We set this task given a user, U and context C32\\nGiven the size of the input corpus, we need to formulate the problem as\\na two-stage recommender: the first is the candidate generator that reduces\\nthe candidate video set to hundreds of items and a second model, similar in\\nsize and shape, called a ranker that ranks these hundreds of videos by the\\nprobability that the user will click on them and watch.\\nThe candidate generator is a softmax deep learning model with several\\nlayers, all activated with ReLU activation functions – rectified linear unit\\nactivation that outputs the input directly if positive; otherwise, it’s zero. The\\nuses both embedded and tabular learning features, all of which are combined\\nand\\nTo build the model, we use two sets of embeddings as input data: one\\nthat’s the user plus context as features, and a set of video items. The model\\nhas several hundreds of features, both tabular and embeddings-based. For the\\nembeddings-based features, we include elements like:'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 63, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='has several hundreds of features, both tabular and embeddings-based. For the\\nembeddings-based features, we include elements like:\\n• User watch history - represented by a vector of sparse video ID elements\\nmapped into a dense vector representation\\n• User’s search history - Maps search term to video clicked from the search\\nterm, also in a sparse vector mapped into the same space as the user\\nwatch history\\n• User’s geography, age, and gender - mapped as tabular features\\n• The number of previous impressions a video had, normalized per user\\nover time\\nThese are all combined into a single item embedding, and in the case of\\nthe user, a single embedding that’s a blended map of all the user embedding\\nfeatures, and fed into the models’ softmax layers, which compare the distance\\nbetween the output of the softmax layer, i.e. the probability that the user will\\nclick on an item, and a set of ground truth items, i.e. a set of items that the user'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 63, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='between the output of the softmax layer, i.e. the probability that the user will\\nclick on an item, and a set of ground truth items, i.e. a set of items that the user\\nhas already interacted with. The log probability of an item is the dot product\\nof two n-dimensional vectors, i.e. the query and item embeddings.\\nWe consider this an example of Implicit feedback - feedback the user did\\nnot explicitly give, such as a rating, but that we can capture in our log data.\\nEach class response, of which there are approximately a million, is given a\\nprobability as output.\\nThe DNN is a generalization of the matrix factorization model we dis-\\ncussed earlier.\\n32In recommender systems, we often think of four relevant items to formulate our recom-\\nmender problem - user, item, context, and query. The context is usually the environment, for\\nexample the time of day or the geography of the user at inference time\\n64'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 64, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 48: YouTube’s multi-step neural network model for video recommendations using\\ninput embeddings [11]\\nGoogle Play App Store\\nSimilar work, although with a different architecture, was done in the App\\nStore in Google Play in \"Wide and Deep Learning for Recommender Systems\"\\n[7]. This one crosses the search and recommendation space because it returns\\ncorrect ranked and personalized app recommendations as the result of a search\\nquery. The input is clickstream data collected when a user visits the app store.\\nFigure 49: Wide and deep [7]\\nThe recommendations problem is formulated here as two jointly-trained\\nmodels. The weights are shared and cross-propagated between the two models\\nbetween epochs.\\nThere are two problems when we try to build models that recommend\\nitems: memorization - the model needs to learn patterns by learning how\\nitems occur together given the historical data, and generalization - the model\\nneeds to be able to give new recommendations the user has not seen before that'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 64, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='items occur together given the historical data, and generalization - the model\\nneeds to be able to give new recommendations the user has not seen before that\\nare still relevant to the user, improving recommendation diversity. Generally,\\none model alone cannot encompass both of these tradeoffs.\\nWide and deep is made up of two models that look to complement each\\nother:\\n65'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 65, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• A wide model which uses traditional tabular features to improve the\\nmodel’s memorization.\\nThis is a general linear model trained on\\nsparse, one-hot encoded features like user_installed_app=netflix\\nacross thousands of apps.\\nMemorization works here by creat-\\ning binary features that are combinations of features, such as\\nAND(user_installed_app=netflix, impression_app_pandora, allow-\\ning us to see different combinations of co-occurrence in relationship\\nto the target, i.e. likelihood to install app Y. However, this model cannot\\ngeneralize if it gets a new value outside of the training data.\\n• A deep model that supports generalization across items that the model\\nhas not seen before, using a feed-forward neural network made up\\nof categorical features that are translated to embeddings, such as user\\nlanguage, device class, and whether a given app has an impression.\\nEach of these embeddings range from 0-100 in dimensionality. They'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 65, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='language, device class, and whether a given app has an impression.\\nEach of these embeddings range from 0-100 in dimensionality. They\\nare combined jointly into a concatenated embedding space with dense\\nvectors in 1200 dimensions. and initialized randomly. The embedding\\nvalues are trained to minimize loss of the final function, which is a\\nlogistic loss function common to the deep and wide model.\\nFigure 50: The deep part of the wide and deep model [7]\\nThe model is trained on 500 billion examples, and evaluated offline using\\nAUC and online using app acquisition rate, the rate at which people download\\nthe app. Based on the paper, using this approach improved the app acquisition\\nrate on the main landing page of the app store by 3.9 % relative to the control\\ngroup.\\n5.1.3\\nTwitter\\nAt Twitter, pre-computed embeddings were a critical part recommendations\\nfor many app surface areas including user onboarding topic interest predic-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 65, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='group.\\n5.1.3\\nTwitter\\nAt Twitter, pre-computed embeddings were a critical part recommendations\\nfor many app surface areas including user onboarding topic interest predic-\\ntion, recommended Tweets, home timeline construction, users to follow, and\\n66'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 66, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='recommended ads.\\nTwitter had a number of embeddings-based models but we’ll cover two\\nprojects here: Twice [44], content embeddings for Tweets, which looks to find\\nrich representations of Tweets that include both text and visual data for use in\\nsurfacing Tweets in the home timeline, Notifications and Topics. Twitter also\\ndeveloped TwHIN [18], Twitter Heterogeneous Information Network, a set\\nof graph-based embeddings [18], developed for tasks like personalized ads\\nrankings, account follow-recommendation, offensive content detection, and\\nsearch ranking, based on nodes (such as users and advertisers) and edges that\\nrepresent entity interactions.\\nFigure 51: Twitter’s Twice Embeddings, a trained BERT model [44]\\nTwice is a BERT model trained from scratch on an input corpus of 200\\nmillion Tweets that users engaged with sampled over 90 days and also includes\\nassociations to the users themselves. The objective of the model is to optimize'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 66, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='million Tweets that users engaged with sampled over 90 days and also includes\\nassociations to the users themselves. The objective of the model is to optimize\\non several tasks: topic prediction (aka the topic associated with a Tweet, of\\nwhich there could be multiple), engagement prediction (the likelihood a user\\nis to engage with a Tweet), and language prediction to cluster Tweets of the\\nsame language to be clustered closer together.\\nTwHIN, rather than just focusing on Tweet content, considers all entities in\\nTwitter’s environment (Tweets, users, advertiser entities) as belong together\\nin a joint embedding space graph.\\nJoint embedding is performed by using data from user-Tweet engagement,\\nadvertising, and following data, to create multi-model embeddings. TWHin\\nis used for candidate generation. The candidate generator finds users to\\nfollow or Tweets to engage with an HNSW or Faiss to retrieve candidate items.\\nTWHin embeddings are then used to query candidate items and increase'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 66, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='follow or Tweets to engage with an HNSW or Faiss to retrieve candidate items.\\nTWHin embeddings are then used to query candidate items and increase\\ndiversity in the candidate pool.\\n67'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 67, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 52: Twitter’s model of the app’s heterogeneous information network [18]\\nEmbeddings at Flutter\\nOnce we synthesize enough of these architectures, we see some patterns\\nstart to emerge that we can think about adapting for developing our relevant\\nrecommendation system at Flutter.\\nFirst, we need a great deal of input data to make accurate predictions\\nfrom, and that data should have information about either explicit, or, more\\nlikely, implicit data like user clicks and purchases so that we can construct our\\nmodel of user preferences. The reason we need a lot of data is two-fold. First,\\nneural networks are data-hungry and require a large amount of training data\\nto correctly infer relationships in comparison to traditional models. Second,\\nlarge data requires a large pipeline.\\nIf we don’t have a lot of data, a simpler model will work well-enough,\\nso we need to make sure we are actually at the scale where embeddings\\nand neural networks help our business problem. It’s likely the case that we'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 67, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='so we need to make sure we are actually at the scale where embeddings\\nand neural networks help our business problem. It’s likely the case that we\\ncan start much simpler. And in fact, a recent paper by one of the original\\nresearchers who developed factorization machines, an important approach\\nin recommendations, argues that simple dot products found as the result of\\nmatrix factorization outperform neural networks [52]. Second, in order to get\\ngood embeddings, we will need to spend a great deal of time cleaning and\\nprocessing data and creating features, as we did in the YouTube paper, so the\\noutcome has to be worth the time spent.\\nSecond, we need to be able to understand the latent relationship between\\nusers and items they’ve interacted with. In traditional recommenders, we\\ncould use TF-IDF to find the weighted word features as part of a particular flit\\nand compare across documents, as long as our corpus doesn’t grow too large.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 67, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='could use TF-IDF to find the weighted word features as part of a particular flit\\nand compare across documents, as long as our corpus doesn’t grow too large.\\nIn more advanced recommendation systems, we could perform this same task\\nby looking at either naive association rules, or framing recommendation as\\nan interaction-based collaborative filtering problem not unlike Word2Vec to\\ngenerate latent features, aka embeddings, of our users and items. In fact, this\\n68'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 68, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='is exactly what Levy and Goldberg argued in \"Neural Word Embedding as Im-\\nplicit Matrix Factorization\" [43]. They looked at the skipgram implementation\\nof Word2Vec and found that implicitly it factors a word-context matrix.\\nWe could alternatively still use tabular features as input into our collabo-\\nrative filtering problem but use a neural network [28] instead of simple dot\\nproduct to converge on the correct relationships and the downstream ranking\\nfor the model.\\nGiven our new knowledge about how embeddings and recommender sys-\\ntems work, we can now incorporate embeddings into the recommendations\\nwe serve for flits at Flutter. If we want to recommend relevant content, we\\nmight do it in a number of different ways, depending on our business require-\\nments. In our corpus, we have hundreds of millions of messages that we need\\nto filter down to hundreds to show the user. So we can start with a baseline of\\nWord2Vec or similar and move on to any of the BERT or other neural network'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 68, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='to filter down to hundreds to show the user. So we can start with a baseline of\\nWord2Vec or similar and move on to any of the BERT or other neural network\\napproaches to developing model input features, vector similarity search, and\\nranking, through the power of embeddings.\\nEmbeddings are endlessly flexible and endlessly useful, and can empower\\nand improve the performance of our multimodal machine learning workflows.\\nHowever, as we just saw, there are some things to keep in mind if we do\\ndecide to use them.\\n5.2\\nEmbeddings as an Engineering Problem\\nIn general, machine learning workflows add an enormous amount of com-\\nplexity and overhead to our engineering systems, for a number of reasons\\n[57]. First, they blend data that then needs to be monitored for drift down-\\nstream. Second, they are non-deterministic in their outputs, which means they\\nneed to be tracked extremely carefully as artifacts, since we generally don’t'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 68, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='stream. Second, they are non-deterministic in their outputs, which means they\\nneed to be tracked extremely carefully as artifacts, since we generally don’t\\nversion-control data. Third, they result in processing pipeline jungles.\\nAs a special case of glue code, pipeline jungles often appear in\\ndata preparation. These can evolve organically, as new signals are\\nidentified and new information sources added. Without care, the\\nresulting system for preparing data in an ML-friendly format may\\nbecome a jungle of scrapes, joins, and sampling steps, often with\\nintermediate files output.\\nAs we can see from several system diagrams, including PinnerSage and\\nthe Wide and Deep Model, recommender systems in production utilizing\\nembeddings have many moving components.\\n69'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 69, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 53: PinnerSage model archi-\\ntecture [50]\\nFigure 54: Wide and Deep model\\narchitecture [7]\\nYou may recall that we discussed the simple stages of a recommender\\nsystem in this diagram.\\nFigure 55: Generic system processing embeddings in context\\nGiven all of our production-level requirements for a successful recom-\\nmendation system, our actual production system generally looks more like\\nthis:\\n• Generating embeddings\\n• Storing embeddings\\n• Embedding feature engineering and iteration\\n• Artifact retrieval\\n• updating embeddings\\n• versioning embeddings and data drift\\n• Inference and latency\\n• Online (A/B test) and offline (metric sweep) model evaluation\\nGiven all of our concern space, the diagram of any given production\\nsystem would look more like this\\n70'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 70, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 56: Recommender systems as a machine learning problem\\n5.2.1\\nEmbeddings Generation\\nWe’ve already seen that embeddings are usually generated as a byproduct of\\ntraining neural network models, most often the penultimate layer that’s used\\nbefore a layer to classify or regress is added as the final output. We have two\\nways to build them. We can train our own models, as YouTube, Pinterest, and\\nTwitter have done. In the LLM space, there is also growing interest in being\\nable to train large language models in-house.\\nHowever, one of the large benefits of deep learning models is that we\\ncan also use pre-trained model. A pretrained model is any model that’s like\\nthe one we’re considering for our task that has already been trained on an\\nenormous corpus of training data, and can be used for downstream tasks.\\nBERT is an example of a model that has already been pre-trained and can\\nbe used for any number of machine learning tasks through the process of'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 70, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='BERT is an example of a model that has already been pre-trained and can\\nbe used for any number of machine learning tasks through the process of\\nfine-tuning. In fine-tuning, we take a model that’s already been pre-trained\\non a generic dataset. For example, BERT was trained on BookCorpus, a set of\\n11k books with 800 million words and English Wikipedia, 2.5 billion words.\\nAn aside on training data\\nTraining data is the most important part of any given model. Where does it\\ncome from for pre-trained large language models? Usually scraping large\\nparts of the internet. In the interest of competitive advantage, how these\\ntraining datasets are put together is usually not revealed, and there is a\\nfair amount of reverse-engineering and speculation. For example, \"What’s\\nin my AI\" goes into the training data behind the GPT series of models\\nand finds that GPT-3 was trained on Books1 and Books2. Books1 is likely\\nbookcorpus and books2 is likely libgen. GPT also includes the Common'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 70, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='and finds that GPT-3 was trained on Books1 and Books2. Books1 is likely\\nbookcorpus and books2 is likely libgen. GPT also includes the Common\\nCrawl, a large open-source dataset of indexed websites, WebText2, and\\nWikipedia. This information is important because when we pick a model\\n71'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 71, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='we need to at least understand at a high level what it was trained on to\\nbe a general-purpose model so we can explain what changes when we\\nfine-tune it.\\nIn fine-tuning a model, we perform all the same steps as we do for training\\nfrom scratch. We have training data, we have a model, and we minimize a\\nloss function. However, there are several differences. When we create our\\nnew model, we copy the existing, pre-trained model with the exception of\\nthe final output layer, which we initialize from scratch based on our new task.\\nWhen we train the model, we initialize these parameters at random and only\\ncontinue to adjust the parameters of the previous layers so that they focus on\\nthis task rather than starting to train from scratch. In this way, if we have a\\nmodel like BERT that’s trained to generalize across the whole internet, but our\\ncorpus for Flutter is very sensitive to trending topics and needs to be updated\\non a daily basis, we can refocus the model without having to train a new one'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 71, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='corpus for Flutter is very sensitive to trending topics and needs to be updated\\non a daily basis, we can refocus the model without having to train a new one\\nwith as few as 10k samples instead of our original hundreds of millions [74].\\nThere are, likewise, BERT embeddings available that we can fine-tune.\\nThere are other generalized corpuses available, such as GloVE, Word2Vec, and\\nFastText (also trained with CBOW). We need to make a decision whether to\\nuse these, train a model from scratch, or a third option, to query embeddings\\navailable from an API as is the case for OpenAI embeddings, although doing\\nso can potentially come at a higher cost, relative to training or fine-tuning our\\nown. Of course, all of this is subject to our particular use-case and is important\\nto evaluate when we start a project.\\n5.2.2\\nStorage and Retrieval\\nOnce we’ve trained our model, we’ll need to extract the embeddings from\\nthe trained object. Generally, when a model is trained, the resulting output is'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 71, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='5.2.2\\nStorage and Retrieval\\nOnce we’ve trained our model, we’ll need to extract the embeddings from\\nthe trained object. Generally, when a model is trained, the resulting output is\\na data structure that contains all the parameters of the model, including the\\nmodel’s weights, biases, layers and learning rate. The embeddings are part of\\nthis model object as a layer, and they initially live in-memory. When we write\\nthe model to disk, we propagate them as a model object, which is serialized\\nonto memory and loaded at re-training or inference time.\\nThe simplest form of embedding store can be an in-memory numpy ar-\\nray33.\\nBut if we are iterating on building a model with embeddings, we want to\\nbe able to do a number of things with them:\\n• Access them in batch and one-by-one at inference time\\n• Perform offline analysis on the quality of the embeddings\\n• Embedding feature engineering\\n• Update embeddings with new models\\n• Version embeddings\\n• Encode new embeddings for new documents'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 71, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• Perform offline analysis on the quality of the embeddings\\n• Embedding feature engineering\\n• Update embeddings with new models\\n• Version embeddings\\n• Encode new embeddings for new documents\\n33From a Tweet by Andrej Karpathy in response to how he stores vector embeddings for a\\nsmall movie recommendations side project in 2023,\"np.array people keep reaching for much\\nfancier things way too fast these days. Tweet\\n72'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 72, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='The most complex and customizable software that handles many of these\\nuse-cases is a vector database, and somewhere in-between vector databases\\nand in-memory storage are vector search plugins for existing stores like Post-\\ngres and SQLite, and caches like Redis.\\nThe most important operation we’d like to perform with embeddings is\\nvector search, which allows us to find embeddings that are similar to a given\\nembedding so we can return item similarity. If we want to search embeddings,\\nwe need a mechanism that is optimized to search through our matrix data\\nstructures and perform nearest-neighbor comparisons in the same way that\\na traditional relational database is optimized to search row-based relations.\\nRelational databases use a b-tree structure to optimize reads by sorting items\\nin ascending order within a hierarchy of nodes, built on top of an indexed\\ncolumn in the database. We can’t perform columnar lookups on our vectors'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 72, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='in ascending order within a hierarchy of nodes, built on top of an indexed\\ncolumn in the database. We can’t perform columnar lookups on our vectors\\nefficiently, so we need to create different structures for them. For example,\\nmany vector stores are based on inverted indices.\\nA general-form embeddings store contains the embeddings themselves, an\\nindex to map them back from the latent space into words, pictures, or text, and\\na way to do similarity comparisons between different types of embeddings\\nusing various nearest neighbors algorithms. We talked before about cosine\\nsimilarity as a staple of comparing latent space representations. This can be-\\ncome computationally expensive over millions of sets of vectors, because we’d\\nneed to do a pairwise comparison over every pair. To solve this, approximate\\nnearest neighbors (ANN) algorithms were developed to, as in recommender\\nsystems, create neighborhoods out of elements of vectors and find a vector’s'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 72, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='nearest neighbors (ANN) algorithms were developed to, as in recommender\\nsystems, create neighborhoods out of elements of vectors and find a vector’s\\nk-nearest neighbors. The most frequently-used algorithms include HNSW\\n(hierarchical navigable small worlds) and Faiss, both of which are standalone\\nlibraries and also implemented as part of many existing vector stores.\\nThe trade-off between full and nearest neighbor search is that the latter is\\nless precise, but it’s much faster. When we switch between precision and recall\\nin evaluation, we need to be aware of the tradeoffs and think about what our\\nrequirements are with respect to how accurate our embeddings are and their\\ninference latency.\\nHere’s an example of the embeddings storage system that Twitter built for\\nexactly this use case, long before vector databases came into the picture. [62].\\nFigure 57: Twitter’s embeddings pipeline [62]\\n73'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 73, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Given that Twitter uses embeddings in multiple sources as described in\\nthe previous section, Twitter made embeddings \"first class citizens\" by creat-\\ning a centralized platform that reprocesses data and generates embeddings\\ndownstream into the feature registry.\\n5.2.3\\nDrift Detection, Versioning, and Interpretability\\nOnce we’ve trained embeddings, we might think we’re done. But embeddings,\\nlike any machine learning pipeline, need to be refreshed because we might\\nrun into concept drift. Concept drift occurs when the data underlying our\\nmodel changes. For example, let’s say that our model includes, as a binary\\nfeature, people who have landlines or not. In 2023, this would no longer be as\\nrelevant of a feature in most of the world as most people have switched to cell\\nphones as their primary telephones, so the model would lose accuracy.\\nThis phenomenon is even more prevalent with embeddings that are used\\nfor classification. For example, let’s say we use embeddings for trending topic'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 73, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='This phenomenon is even more prevalent with embeddings that are used\\nfor classification. For example, let’s say we use embeddings for trending topic\\ndetection. The model has to generalize, as in the wide and deep model, to\\ndetect new classes, but if our classes change quickly, it may not be able to, so\\nwe need to retrain your embeddings frequently. Or, for example, if we model\\nembeddings in a graph, as Pinterest does, and the relationships between nodes\\nin the graph change, we may have to update them [69]. We could also have an\\ninflux of spam or corrupted content which changes the relationship in your\\nembeddings, in which case we’ll need to retrain.\\nEmbeddings can be hard to understand (so hard that some people have\\neven written entire papers about them) and harder to interpret. What does it\\nmean for a king to be close to queen but far away from the knight? What does\\nit mean for two flits to be close to each other in a projected embedding space?'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 73, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='mean for a king to be close to queen but far away from the knight? What does\\nit mean for two flits to be close to each other in a projected embedding space?\\nWe have two ways we can think about this, intrinsic and extrinsic evalua-\\ntion. For the embeddings themselves (extrinsic evaluation), we can visualize\\nthem through either UMAP—Uniform Manifold Approximation and Projec-\\ntion for Dimension Reduction or t-sne — t-distributed stochastic neighbor\\nembedding, algorithms that allow us to visualize highly-dimensional data in\\ntwo or three dimensions, much like PCA. Or we can fit embeddings into our\\ndownstream task (for example, summarization, or classification), and analyze\\nthe same way we would with offline metrics. There are many different ap-\\nproaches [67] but the summary is that embeddings can be objectively hard to\\nevaluate and we’ll need to factor the time to perform this evaluation into our\\nmodeling time.\\nOnce we retrain our initial baseline model, we now have a secondary issue:'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 73, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='evaluate and we’ll need to factor the time to perform this evaluation into our\\nmodeling time.\\nOnce we retrain our initial baseline model, we now have a secondary issue:\\nhow do we compare the first set of embeddings to the second; that is, how do\\nwe evaluate whether they are good representations of our data, given the case\\nthat embeddings are often unsupervised; i.e. — how do we know whether\\n\"king\" should be close to \"queen\"? On their own, as a first-pass, embeddings\\ncan be hard to interpret, because in a multidimensional space it’s hard to\\nunderstand which dimension of a vector corresponds to a decision to place\\nitems next to each other [63]. When compared to other sets of embeddings,\\nwe might use the offline metrics of the final model task, precision and recall,\\nor we could measure the distance of the distribution of the embeddings in the\\n74'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 74, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='latent space by comparing the statistical distance between the two probability\\ndistributions using a metric known as Kullback–Leibler divergence.\\nFinally, now let’s say that we have two sets of embeddings, you need to\\nversion them and keep both sets so that, in case your new model doesn’t work\\nas well, you can fall back to the old one. This goes hand-in-hand with the\\nproblem of model versioning in ML operations, except in this case we need to\\nboth version the model and the output data.\\nThere are numerous different approaches to model and data versioning\\nthat involve building a system that tracks both the metadata and the location\\nof the assets that are kept in a secondary data store. Another thing to keep in\\nmind is that embedding layers, particularly for large vocabularies, can balloon\\nin size, so now we have to consider storage costs, as well.\\n5.2.4\\nInference and Latency\\nWhen working with embeddings, we are operating not only in a theoretical,'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 74, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='in size, so now we have to consider storage costs, as well.\\n5.2.4\\nInference and Latency\\nWhen working with embeddings, we are operating not only in a theoretical,\\nbut practical engineering environment. The most critical engineering part of\\nany machine learning system that works in production is inference time —\\nhow quickly does it take to query the model asset and return a result to an\\nend-user.\\nFor this, we care about latency, which we can roughly define as any time\\nspent waiting and is a critical performance metric in any production system\\n[26]. Generally speaking, it’s the time of any operation to complete – appli-\\ncation request, database query, and so on. Latency at the level of the web\\nservice is generally measured in milliseconds, and every effort is made to\\nreduce this as close to zero as realistically possible. For use-cases like search\\nand loading a feed of content, the experience needs to be instantaneous or the'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 74, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='reduce this as close to zero as realistically possible. For use-cases like search\\nand loading a feed of content, the experience needs to be instantaneous or the\\nuser experience will degrade and we could even lose revenue. In a study from\\na while back, Amazon found that every 100ms increase in latency cuts profits\\nby 1% [19].\\nGiven this, we need to think about how to reduce the footprint of our\\nmodel and all the layers in serving it so that the response to the user is\\ninstantaneous. We do this by creating observability throughout our machine\\nlearning system, starting with the hardware the system is running on, to\\nCPU and GPU utilization, the performance of our model architecture, and\\nhow that model interacts with other components. For example, when we are\\nperforming nearest neighbor lookup, the way we perform that lookup and the\\nalgorithm we use, the programming language we use to write that algorithm,\\nall compound latency concerns.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 74, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='performing nearest neighbor lookup, the way we perform that lookup and the\\nalgorithm we use, the programming language we use to write that algorithm,\\nall compound latency concerns.\\nAs an example, in the wide and deep paper, the recommender ranking\\nmodel scores over 10 million apps per second. The application was initially\\nsingle-threaded, with all candidates taking 31 milliseconds. By implementing\\nmultithreading, they were able to reduce client-side latency to 14 milliseconds\\n[7].\\nOperations of machine learning systems is an entirely other art and craft\\nof study and one that’s best left for another paper [37].\\n75'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 75, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='5.2.5\\nOnline and Offline Model Evaluation\\nWe’ve barely scratched the surface of one of the most critical parts of a model:\\nhow it performs in offline and online testing. When we talk about offline tests,\\nwe mean analyzing the statistical properties of a model to learn whether the\\nmodel is a valid model - i.e. does our loss function converge? Does the model\\noverfit or underfit? What is the precision and recall? Do we experience any\\ndrift? If it’s a recommendation ranker model, are we using metrics like NDCG\\n—normalized discounted cumulative gain— to understand whether our new\\nmodel ranks items better than the previous iteration?\\nThen, there is online evaluation, aka how successful the model actually\\nis in the production context. Usually, this is evaluated through A/B testing\\nwhere one set of users gets the old model or system and a holdout set of users\\ngets the new system, and looking at the statistical significance of metrics like'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 75, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='where one set of users gets the old model or system and a holdout set of users\\ngets the new system, and looking at the statistical significance of metrics like\\nclick-through rate, items served, and time spent on a given area of the site.\\n5.2.6\\nWhat makes embeddings projects successful\\nFinally, once we have all our algorithmic and engineering concerns lined up,\\nthere is the final matter to consider of what will make our project successful\\nfrom a business perspective. We should acknowledge that we might not\\nalways need embeddings for our machine learning problem, or that we might\\nnot need machine learning at all, initially, if our project is based entirely on a\\nhandful of heuristic rules that can be determined and analyzed by humans\\n[76].\\nIf we conclude that we are operating in a data-rich space where automati-\\ncally inferring semantic relationships between entities is correct, we need to\\nask ourselves if we’re willing to put in a great deal of effort into producing'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 75, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='cally inferring semantic relationships between entities is correct, we need to\\nask ourselves if we’re willing to put in a great deal of effort into producing\\nclean datasets, the baseline of any good machine learning model, even in cases\\nof large language models. In fact, clean, domain data is so important that\\nmany of the companies discussed here ended up training their own embed-\\ndings models, and, recently companies like Bloomberg [70] and Replit [59] are\\neven training their own large language models to improve accuracy for their\\nspecific business domain.\\nCritically, to get to a stage where we have a machine learning system\\ndealing with embeddings, we need a team that has multilevel alignment\\naround the work that needs to be done. In larger companies, the size of this\\nteam will be larger, but most specifically work with embeddings requires\\nsomeone who can speak to the use case specifically, someone who advocates'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 75, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='team will be larger, but most specifically work with embeddings requires\\nsomeone who can speak to the use case specifically, someone who advocates\\nfor the use case and gets it prioritized, and a technical person who can do the\\nwork [46].\\nIf all of these components come together, we now have an embeddings-\\nbased recommender system in production.\\n6\\nConclusion\\nWe have now walked through an end-to-end example of what embeddings\\nare. We started with a high-level overview of how embeddings fit into the\\n76'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 76, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='context of a machine learning application. We then did a deep dive on early\\napproaches to encoding, built up intuition of embeddings in Word2Vec and\\nthen moving on to transformers and BERT. Although reducing dimensionality\\nas a concept has always been important in machine learning systems to de-\\ncrease computational and storage complexity, compression has become even\\nmore important in the modern explosion of multimodal representations of\\ndata that comes from application log files, images, video, and audio, and the\\nexplosion of Transformer, generative, and diffusion models, combined with\\nthe cheap storage and explosion of data, has amended itself to architectures\\nwhere embeddings are used more and more.\\nWe’ve understood the engineering context of why we might include ma-\\nchine learning models in our application, how they work, how to incorporate\\nthem, and where embeddings —dense representations of deep learning model'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 76, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='chine learning models in our application, how they work, how to incorporate\\nthem, and where embeddings —dense representations of deep learning model\\ninput and output data – can be best leveraged. Embeddings are a powerful\\ntool in any machine learning system, but one that comes at a cost of mainte-\\nnance and interpretability. Generating embeddings using the correct method,\\nwith the correct metrics and hardware and software, is a project that takes con-\\nsiderable thought. We now hopefully have a solid grasp of the fundamentals\\nof embedding and can either leverage them – or explain why not to –in our\\nnext project. Good luck navigating embeddings, see you in the latent space!\\n77'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 77, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='References\\n1. Gabriel\\nAltay.\\nCategorical\\nvariables\\nin\\ndecision\\ntrees,\\nMar\\n2020. URL https://www.kaggle.com/code/gabrielaltay/categorical-\\nvariables-in-decision-trees.\\n2. Ioannis Arapakis, Xiao Bai, and B Barla Cambazoglu. Impact of response\\nlatency on user behavior in web search. In Proceedings of the 37th inter-\\nnational ACM SIGIR conference on Research & development in information\\nretrieval, pages 103–112, 2014.\\n3. Remzi H Arpaci-Dusseau and Andrea C Arpaci-Dusseau. Operating sys-\\ntems: Three easy pieces. Arpaci-Dusseau Books, LLC, 2018.\\n4. Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation\\nlearning: A review and new perspectives. IEEE transactions on pattern\\nanalysis and machine intelligence, 35(8):1798–1828, 2013.\\n5. Pablo Castells and Dietmar Jannach. Recommender systems: A primer.\\narXiv preprint arXiv:2302.02579, 2023.\\n6. Dhivya Chandrasekaran and Vijay Mago. Evolution of semantic similar-\\nity—a survey. ACM Computing Surveys (CSUR), 54(2):1–37, 2021.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 77, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='arXiv preprint arXiv:2302.02579, 2023.\\n6. Dhivya Chandrasekaran and Vijay Mago. Evolution of semantic similar-\\nity—a survey. ACM Computing Surveys (CSUR), 54(2):1–37, 2021.\\n7. Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar\\nChandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai,\\nMustafa Ispir, et al. Wide & deep learning for recommender systems.\\nIn Proceedings of the 1st workshop on deep learning for recommender systems,\\npages 7–10, 2016.\\n8. Francois Chollet. Deep learning with Python. Simon and Schuster, 2021.\\n9. Ronan Collobert and Jason Weston. A unified architecture for natural\\nlanguage processing: Deep neural networks with multitask learning. In\\nProceedings of the 25th international conference on Machine learning, pages\\n160–167, 2008.\\n10. Yingnan Cong, Yao-ban Chan, and Mark A Ragan. A novel alignment-free\\nmethod for detection of lateral genetic transfer based on tf-idf. Scientific\\nreports, 6(1):1–13, 2016.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 77, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='160–167, 2008.\\n10. Yingnan Cong, Yao-ban Chan, and Mark A Ragan. A novel alignment-free\\nmethod for detection of lateral genetic transfer based on tf-idf. Scientific\\nreports, 6(1):1–13, 2016.\\n11. Paul Covington, Jay Adams, and Emre Sargin. Deep neural networks for\\nyoutube recommendations. In Proceedings of the 10th ACM conference on\\nrecommender systems, pages 191–198, 2016.\\n12. Toni Cvitanic, Bumsoo Lee, Hyeon Ik Song, Katherine Fu, and David\\nRosen. Lda v. lsa: A comparison of two computational text analysis tools\\nfor the functional categorization of patents. In International Conference on\\nCase-Based Reasoning, 2016.\\n13. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert:\\nPre-training of deep bidirectional transformers for language understand-\\ning. arXiv preprint arXiv:1810.04805, 2018.\\n78'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 78, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='14. Giovanni Di Gennaro, Amedeo Buonanno, and Francesco AN Palmieri.\\nConsiderations about learning word2vec. The Journal of Supercomputing,\\npages 1–16, 2021.\\n15. Author Cory Doctorow.\\nPluralistic: Tiktok’s enshittification (21 jan\\n2023), Feb 2023. URL https://pluralistic.net/2023/01/21/potemkin-\\nai/#hey-guys.\\n16. Melody Dye, Chaitanya Ekandham, Avneesh Saluja, and Ashish Ras-\\ntogi.\\nSupporting content decision makers with machine learning,\\nDec 2020.\\nURL https://netflixtechblog.com/supporting-content-\\ndecision-makers-with-machine-learning-995b7b76006f.\\n17. Michael D Ekstrand and Joseph A Konstan. Recommender systems nota-\\ntion: proposed common notation for teaching and research. arXiv preprint\\narXiv:1902.01348, 2019.\\n18. Ahmed El-Kishky, Thomas Markovich, Serim Park, Chetan Verma, Baekjin\\nKim, Ramy Eskander, Yury Malkov, Frank Portman, Sofía Samaniego,\\nYing Xiao, et al. Twhin: Embedding the twitter heterogeneous information'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 78, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Kim, Ramy Eskander, Yury Malkov, Frank Portman, Sofía Samaniego,\\nYing Xiao, et al. Twhin: Embedding the twitter heterogeneous information\\nnetwork for personalized recommendation. In Proceedings of the 28th\\nACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages\\n2842–2850, 2022.\\n19. Tobias Flach, Nandita Dukkipati, Andreas Terzis, Barath Raghavan, Neal\\nCardwell, Yuchung Cheng, Ankur Jain, Shuai Hao, Ethan Katz-Bassett,\\nand Ramesh Govindan. Reducing web latency: the virtue of gentle aggres-\\nsion. In Proceedings of the ACM SIGCOMM 2013 conference on SIGCOMM,\\npages 159–170, 2013.\\n20. Martin Fowler. Patterns of Enterprise Application Architecture: Pattern Enterpr\\nApplica Arch. Addison-Wesley, 2012.\\n21. Jan J Gerbrands. On the relationships between svd, klt and pca. Pattern\\nrecognition, 14(1-6):375–381, 1981.\\n22. David Goldberg, David Nichols, Brian M Oki, and Douglas Terry. Using\\ncollaborative filtering to weave an information tapestry. Communications'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 78, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='recognition, 14(1-6):375–381, 1981.\\n22. David Goldberg, David Nichols, Brian M Oki, and Douglas Terry. Using\\ncollaborative filtering to weave an information tapestry. Communications\\nof the ACM, 35(12):61–70, 1992.\\n23. Yoav Goldberg and Omer Levy. word2vec explained: deriving mikolov\\net al.’s negative-sampling word-embedding method.\\narXiv preprint\\narXiv:1402.3722, 2014.\\n24. Raul Gomez Bruballa, Lauren Burnham-King, and Alessandra Sala. Learn-\\ning users’ preferred visual styles in an image marketplace. In Proceedings\\nof the 16th ACM Conference on Recommender Systems, pages 466–468, 2022.\\n25. Mihajlo Grbovic and Haibin Cheng. Real-time personalization using\\nembeddings for search ranking at airbnb. In Proceedings of the 24th ACM\\nSIGKDD international conference on knowledge discovery & data mining, pages\\n311–320, 2018.\\n79'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 79, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='26. Brendan Gregg. Systems performance: enterprise and the cloud. Pearson\\nEducation, 2014.\\n27. Casper Hansen, Christian Hansen, Lucas Maystre, Rishabh Mehrotra,\\nBrian Brost, Federico Tomasi, and Mounia Lalmas. Contextual and sequen-\\ntial user embeddings for large-scale music recommendation. In Proceedings\\nof the 14th ACM Conference on Recommender Systems, pages 53–62, 2020.\\n28. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and\\nTat-Seng Chua. Neural collaborative filtering. In Proceedings of the 26th\\ninternational conference on world wide web, pages 173–182, 2017.\\n29. Michael E Houle, Hans-Peter Kriegel, Peer Kröger, Erich Schubert, and\\nArthur Zimek. Can shared-neighbor distances defeat the curse of dimen-\\nsionality? In Scientific and Statistical Database Management: 22nd Interna-\\ntional Conference, SSDBM 2010, Heidelberg, Germany, June 30–July 2, 2010.\\nProceedings 22, pages 482–500. Springer, 2010.\\n30. Dietmar Jannach, Markus Zanker, Alexander Felfernig, and Gerhard'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 79, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='tional Conference, SSDBM 2010, Heidelberg, Germany, June 30–July 2, 2010.\\nProceedings 22, pages 482–500. Springer, 2010.\\n30. Dietmar Jannach, Markus Zanker, Alexander Felfernig, and Gerhard\\nFriedrich. Recommender systems: an introduction. Cambridge University\\nPress, 2010.\\n31. Yushi Jing, David Liu, Dmitry Kislyuk, Andrew Zhai, Jiajing Xu, Jeff\\nDonahue, and Sarah Tavel. Visual search at pinterest. In Proceedings of\\nthe 21th ACM SIGKDD International Conference on Knowledge Discovery and\\nData Mining, pages 1889–1898, 2015.\\n32. Thorsten Joachims. Text categorization with support vector machines:\\nLearning with many relevant features. In Machine Learning: ECML-98: 10th\\nEuropean Conference on Machine Learning Chemnitz, Germany, April 21–23,\\n1998 Proceedings, pages 137–142. Springer, 2005.\\n33. Andrej Karpathy. The unreasonable effectiveness of recurrent neural\\nnetworks, May 2015. URL https://karpathy.github.io/2015/05/21/\\nrnn-effectiveness/.\\n34. P.N. Klein.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 79, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='33. Andrej Karpathy. The unreasonable effectiveness of recurrent neural\\nnetworks, May 2015. URL https://karpathy.github.io/2015/05/21/\\nrnn-effectiveness/.\\n34. P.N. Klein.\\nCoding the Matrix: Linear Algebra Through Applications to\\nComputer Science. Newtonian Press, 2013. ISBN 9780615880990. URL\\nhttps://books.google.com/books?id=3AA4nwEACAAJ.\\n35. Martin Kleppmann. Designing data-intensive applications: The big ideas\\nbehind reliable, scalable, and maintainable systems. \" O’Reilly Media, Inc.\",\\n2017.\\n36. Jay Kreps. I heart logs: Event data, stream processing, and data integration. \"\\nO’Reilly Media, Inc.\", 2014.\\n37. Dominik Kreuzberger, Niklas Kühl, and Sebastian Hirschl.\\nMachine\\nlearning operations (mlops): Overview, definition, and architecture. arXiv\\npreprint arXiv:2205.02302, 2022.\\n38. Giorgi Kvernadze, Putu Ayu G Sudyanti, Nishan Subedi, and Mohammad\\nHajiaghayi. Two is better than one: Dual embeddings for complementary\\nproduct recommendations. arXiv preprint arXiv:2211.14982, 2022.\\n80'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 80, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='39. Valliappa Lakshmanan, Sara Robinson, and Michael Munn.\\nMachine\\nlearning design patterns. O’Reilly Media, 2020.\\n40. Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-\\nbased learning applied to document recognition. Proceedings of the IEEE,\\n86(11):2278–2324, 1998.\\n41. Yann LeCun, Yoshua Bengio, Geoffrey Hinton, et al. Deep learning. nature,\\n521 (7553), 436-444. Google Scholar Google Scholar Cross Ref Cross Ref, page 25,\\n2015.\\n42. Jure Leskovec, Anand Rajaraman, and Jeffrey David Ullman. Mining of\\nmassive data sets. Cambridge university press, 2020.\\n43. Omer Levy and Yoav Goldberg. Neural word embedding as implicit\\nmatrix factorization. Advances in neural information processing systems, 27,\\n2014.\\n44. Xianjing Liu, Behzad Golshan, Kenny Leung, Aman Saini, Vivek Kulkarni,\\nAli Mollahosseini, and Jeff Mo. Twice-twitter content embeddings. In\\nCIKM 2022, 2022.\\n45. Donella H Meadows. Thinking in systems: A primer. chelsea green publish-\\ning, 2008.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 80, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Ali Mollahosseini, and Jeff Mo. Twice-twitter content embeddings. In\\nCIKM 2022, 2022.\\n45. Donella H Meadows. Thinking in systems: A primer. chelsea green publish-\\ning, 2008.\\n46. Doug Meil. Ai in the enterprise. Communications of the ACM, 66(6):6–7,\\n2023.\\n47. Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient\\nestimation of word representations in vector space.\\narXiv preprint\\narXiv:1301.3781, 2013.\\n48. Usman Naseem, Imran Razzak, Shah Khalid Khan, and Mukesh Prasad.\\nA comprehensive survey on word representation models: From classical\\nto state-of-the-art word representation language models. Transactions on\\nAsian and Low-Resource Language Information Processing, 20(5):1–35, 2021.\\n49. Bogdan Oancea, Tudorel Andrei, and Raluca Mariana Dragoescu. Gpgpu\\ncomputing. arXiv preprint arXiv:1408.6923, 2014.\\n50. Aditya Pal, Chantat Eksombatchai, Yitong Zhou, Bo Zhao, Charles Rosen-\\nberg, and Jure Leskovec. Pinnersage: Multi-modal user embedding frame-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 80, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='computing. arXiv preprint arXiv:1408.6923, 2014.\\n50. Aditya Pal, Chantat Eksombatchai, Yitong Zhou, Bo Zhao, Charles Rosen-\\nberg, and Jure Leskovec. Pinnersage: Multi-modal user embedding frame-\\nwork for recommendations at pinterest. In Proceedings of the 26th ACM\\nSIGKDD International Conference on Knowledge Discovery & Data Mining,\\npages 2311–2320, 2020.\\n51. Delip Rao and Brian McMahan. Natural language processing with PyTorch:\\nbuild intelligent language applications using deep learning. \" O’Reilly Media,\\nInc.\", 2019.\\n52. Steffen Rendle, Walid Krichene, Li Zhang, and John Anderson. Neural\\ncollaborative filtering vs. matrix factorization revisited. In Proceedings of\\nthe 14th ACM Conference on Recommender Systems, pages 240–248, 2020.\\n81'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 81, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='53. David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning\\nrepresentations by back-propagating errors. nature, 323(6088):533–536,\\n1986.\\n54. Alexander M Rush. The annotated transformer. In Proceedings of workshop\\nfor NLP open source software (NLP-OSS), pages 52–60, 2018.\\n55. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh,\\nSean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bern-\\nstein, et al. Imagenet large scale visual recognition challenge. International\\njournal of computer vision, 115:211–252, 2015.\\n56. Hinrich Schütze, Christopher D Manning, and Prabhakar Raghavan. In-\\ntroduction to information retrieval, volume 39. Cambridge University Press\\nCambridge, 2008.\\n57. David Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips,\\nDietmar Ebner, Vinay Chaudhary, and Michael Young. Machine learning:\\nThe high interest credit card of technical debt.(2014), 2014.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 81, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Dietmar Ebner, Vinay Chaudhary, and Michael Young. Machine learning:\\nThe high interest credit card of technical debt.(2014), 2014.\\n58. Nick Seaver. Computing Taste: Algorithms and the Makers of Music Recom-\\nmendation. University of Chicago Press, 2022.\\n59. Reza Shabani. How to train your own large language models, Apr 2023.\\nURL https://blog.replit.com/llm-training.\\n60. Christopher J Shallue, Jaehoon Lee, Joseph Antognini, Jascha Sohl-\\nDickstein, Roy Frostig, and George E Dahl. Measuring the effects of data\\nparallelism on neural network training. arXiv preprint arXiv:1811.03600,\\n2018.\\n61. Or Sharir, Barak Peleg, and Yoav Shoham. The cost of training nlp models:\\nA concise overview. arXiv preprint arXiv:2004.08900, 2020.\\n62. Dan Shiebler and Abhishek Tayal. Making machine learning easy with\\nembeddings. SysML http://www.sysml.cc/doc/115.pdf, 2010.\\n63. Adi Simhi and Shaul Markovitch. Interpreting embedding spaces by\\nconceptualization. arXiv preprint arXiv:2209.00445, 2022.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 81, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='embeddings. SysML http://www.sysml.cc/doc/115.pdf, 2010.\\n63. Adi Simhi and Shaul Markovitch. Interpreting embedding spaces by\\nconceptualization. arXiv preprint arXiv:2209.00445, 2022.\\n64. Harald Steck, Linas Baltrunas, Ehtsham Elahi, Dawen Liang, Yves Rai-\\nmond, and Justin Basilico. Deep learning for recommender systems: A\\nnetflix case study. AI Magazine, 42(3):7–18, 2021.\\n65. Krysta M Svore and Christopher JC Burges. A machine learning approach\\nfor improved bm25 retrieval. In Proceedings of the 18th ACM conference on\\nInformation and knowledge management, pages 1811–1814, 2009.\\n66. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\\nAidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you\\nneed. Advances in neural information processing systems, 30, 2017.\\n82'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 82, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='67. Bin Wang, Angela Wang, Fenxiao Chen, Yuncheng Wang, and C-C Jay\\nKuo. Evaluating word embedding models: Methods and experimental\\nresults. APSIPA transactions on signal and information processing, 8:e19, 2019.\\n68. Yuxuan Wang, Yutai Hou, Wanxiang Che, and Ting Liu. From static to\\ndynamic word representations: a survey. International Journal of Machine\\nLearning and Cybernetics, 11:1611–1630, 2020.\\n69. Christopher Wewer, Florian Lemmerich, and Michael Cochez.\\nUp-\\ndating embeddings for dynamic knowledge graphs.\\narXiv preprint\\narXiv:2109.10896, 2021.\\n70. Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Se-\\nbastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon\\nMann. Bloomberggpt: A large language model for finance. arXiv preprint\\narXiv:2303.17564, 2023.\\n71. Peng Xu, Xiatian Zhu, and David A Clifton. Multimodal learning with\\ntransformers: A survey. IEEE Transactions on Pattern Analysis and Machine\\nIntelligence, 2023.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 82, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='arXiv:2303.17564, 2023.\\n71. Peng Xu, Xiatian Zhu, and David A Clifton. Multimodal learning with\\ntransformers: A survey. IEEE Transactions on Pattern Analysis and Machine\\nIntelligence, 2023.\\n72. Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L\\nHamilton, and Jure Leskovec. Graph convolutional neural networks for\\nweb-scale recommender systems. In Proceedings of the 24th ACM SIGKDD\\ninternational conference on knowledge discovery & data mining, pages 974–983,\\n2018.\\n73. Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. Deep learning based\\nrecommender system: A survey and new perspectives. ACM computing\\nsurveys (CSUR), 52(1):1–38, 2019.\\n74. Tianyi Zhang, Felix Wu, Arzoo Katiyar, Kilian Q Weinberger, and\\nYoav Artzi.\\nRevisiting few-sample bert fine-tuning.\\narXiv preprint\\narXiv:2006.05987, 2020.\\n75. Yong Zheng. Multi-stakeholder recommendation: Applications and chal-\\nlenges. arXiv preprint arXiv:1707.08913, 2017.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 82, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Revisiting few-sample bert fine-tuning.\\narXiv preprint\\narXiv:2006.05987, 2020.\\n75. Yong Zheng. Multi-stakeholder recommendation: Applications and chal-\\nlenges. arXiv preprint arXiv:1707.08913, 2017.\\n76. Martin Zinkevich. Rules of machine learning: Best practices for ml engi-\\nneering. URL: https://developers. google. com/machine-learning/guides/rules-of-\\nml, 2017.\\n83'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Object Detection\\nSihao Liang\\nJiajun Lu\\nKevin Perkins'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Overview\\nIntro\\nPart I: Two Stage Detection\\nPart II: Unified Detection\\nPart III: Others\\nSummary and comparison'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='What  is object detection\\nhttp://cs231n.stanford.edu/slides/winter1516_lecture8.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Terms\\nRecall\\nPrecision\\nmAP\\nIoU\\nhttps://en.wikipedia.org/wiki/Precision_and_recall'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 4, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Detection Competitions\\nPascal VOC\\nCOCO\\nImageNet ILSVRC\\nhttp://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html#introduction\\nCOCO: 200 classes \\nVOC: 20 classes'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 5, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Before Deep Learning\\nDeformable part models (DPM)\\n-\\nUses HOG features\\n-\\nVery fast\\nhttps://cs.brown.edu/~pff/papers/lsvm-pami.pdf\\nSliding windows.\\n-\\nScore every subwindow. \\nhttp://www.pyimagesearch.com/2014/11/10/histogram-oriented-gradients-object-detection/'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 6, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Selective Search\\nhttp://www.huppelen.nl/publications/selectiveSearchDraft.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 7, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Hard Negative Mining\\nImbalance between positive and negative examples.\\nUse negative examples with higher confidence score.\\nNon Maximum Suppression\\nIf output boxes overlap, only consider the most confident.'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 8, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Regression used to find bounding box parameters\\nApplied in one of two ways\\n-\\nBounding box refinement\\n-\\nComplete object detection\\nBounding Box Regression\\nI is the set of all matching bounding boxes (Highest IoU with ground truth)\\nExample Loss Function'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 9, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Two Stage Detection\\nPart I'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 10, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='RCNN : Region Proposal + CNN \\nUse selective search to come up with regional proposal\\nFirst object detection method using CNN\\n \\nRich feature hierarchies for accurate object detection and semantic segmentation\\nRoss Girshick Jeff Donahue Trevor Darrell Jitendra Malik\\nNov 2013\\nhttps://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 11, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='RCNN : \\nhttps://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 12, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Training RCNN\\nStep1: train your own CNN model for classification ( or use existing model), using \\nImageNet dataset.\\nConvolution \\nand Pooling\\nFully connected layer\\nSoftmax loss\\n4096 * 1000\\n1000 classes scores\\nImage source : http://www.shunvmall.com/bike-pic/47539009.html'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 13, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Training RCNN\\nStep2: focus on 20 classes + 1 background. Remove the last FC layer and replace it \\nwith a smaller layer and fine-tune the model using PASCAL VOC dataset\\nConvolution \\nand Pooling\\nFully connected layer\\nSoftmax loss\\n4096 * 21\\n21 classes scores'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 14, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Training RCNN\\nStep3: extract feature\\nImage\\nProposals\\nCrop & Warp\\nConvolution \\nand Pooling\\nStore all the features \\nafter pool 5 layer and \\nsave to disk\\nIt is about ~ 200G \\nfeatures'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 15, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Training RCNN\\nStep4: train SVM for each class\\nPositive \\nsamples for \\nMotorbike \\nNegative \\nsamples for \\nMotorbike \\nFeatures \\nfrom last \\nstep\\nCrop / \\nWarp \\nimage'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 16, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Training RCNN\\nStep4: train SVM for each class\\nNegative \\nsamples for \\nBicycle\\nPositive \\nsamples for \\nBicycle\\nFeatures \\nfrom last \\nstep\\nCrop / \\nWarp \\nimage'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 17, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Fast RCNN\\nShare convolution layers for proposals from the same image\\nFaster and More accurate than RCNN\\nROI Pooling\\nFast R-CNN\\nRoss Girshick\\nApr 2015\\nhttps://arxiv.org/pdf/1504.08083v2.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 18, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Fast RCNN\\nhttps://arxiv.org/pdf/1504.08083v2.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 19, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='RoI Pooling\\nimage\\nConv layer\\nDivided into \\nh * w region\\nMax pooling\\nDifferentiable'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 20, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='What is bbox-regressor?\\nBounding box regression\\nConvolution \\nand Pooling\\nFully connected layer\\nSoftmax loss\\nL2 loss\\nOR\\nL1 loss\\n4 value \\n(x,y,w,h)\\nOverfeat, VGG\\nDeepPose, R-CNN\\nTotal loss'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 21, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Convolution \\nand Pooling\\nFully connected layer\\nSoftmax loss\\nSmooth \\nL1 loss\\n4 value \\n(x,y,w,h)\\nTotal loss'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 22, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Result compare\\nTrained using VGG 16  on Pascal VOC 2007 dataset \\nNot including proposal time\\nSource: R. Girshick\\nFast R-CNN\\nR-CNN\\nTrain time (h)\\n9.5\\n84\\n-speedup\\n8.8x\\n1x\\nTest time/image\\n0.32s \\n47.00 s\\n-test speedup\\n146x\\n1x\\nmAP\\n66.9\\n66'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 23, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Result compare\\nSource: cs231 standford\\nFast R-CNN\\nR-CNN\\nTest time/image\\n0.32s \\n47.00 s\\n-test speedup\\n146x\\n1x\\nTest time/image with proposal\\n2s \\n50 s\\n-test speedup\\n25x\\n1x'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 24, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Don’t need to have external regional proposals\\nRPN - Regional Proposal Network \\nFaster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\\nShaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun\\nJun 2015\\nFaster RCNN\\nhttps://arxiv.org/pdf/1506.01497v3.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 25, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Faster RCNN\\nhttps://arxiv.org/pdf/1506.01497v3.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 26, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Faster RCNN\\nhttps://arxiv.org/pdf/1506.01497v3.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 27, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Result compare\\nTrained using Pascal VOC 2007 dataset \\nSource: cs231 standford\\nFaster R-CNN\\nFast R-CNN\\nR-CNN\\nTest time/image\\nWith proposal\\n0.2S\\n2s \\n50s\\n-test speedup\\n250x\\n25x\\n1x\\nmAP\\n66.9\\n66.9\\n66'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 28, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='R-FCN :Region-based Fully Convolutional \\nNetworks\\nhttps://arxiv.org/pdf/1605.06409v2.pdf\\nUse position sensitive score map\\nShare all conv and fc layers between all proposals for the same image\\nR-FCN: Object Detection via Region-based Fully Convolutional Networks\\nJifeng Dai, Yi Li, Kaiming He, Jian Sun\\nMay 2016'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 29, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='R-FCN\\nhttps://arxiv.org/pdf/1605.06409v2.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 30, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='R-FCN\\nhttps://arxiv.org/pdf/1605.06409v2.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 31, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='R-FCN\\nhttps://arxiv.org/pdf/1605.06409v2.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 32, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Methodologies Compare\\nTrained using ResNet 101\\nRCNN\\nFaster RCNN\\nRFCN\\nDepth of shared \\nconvolutional \\nsubnetwork\\n0\\n91\\n101\\nDepth of ROI-wise \\nsubnetwork\\n101\\n10\\n0'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 33, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Result compare\\nTrained using ResNet 101 on Pascal VOC 2007 dataset\\nFaster R-CNN\\nR-FCN\\nTest time/image\\nWith proposal\\n0.42S\\n0.2s \\nmAP\\n76.4\\n76.6'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 34, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Unified Detection\\nPart II'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 35, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Problems with 2 step detection.\\nComplex Pipeline\\nSlow (Cannot run in real time)\\nHard to optimize each component'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 36, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Yolo: You Only Look Once\\nConsider detection a regression problem\\nUse a single ConvNet\\nRuns once on entire image. Very Fast!\\nYou only look once: Unified, real-time object detection. \\nJoseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi\\nJune 2015'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 37, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='How it works\\nThe following predictions are made for each cell in an S x S grid.\\nC conditional class probabilities Pr(Classi | Obj)\\nB bounding boxes (4 parameters each)\\nB confidence scores Pr(Obj)*IoU\\nOutput is S x S  x (5B+C) tensor\\nhttps://arxiv.org/pdf/1506.02640v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 38, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Architecture\\nhttps://arxiv.org/pdf/1506.02640v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 39, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Performance (VOC 2007) \\nhttps://arxiv.org/pdf/1506.02640v5.pdf\\nYolo\\nFaster R-CNN (VGG-16)\\nmAP\\n63.4\\n73.2\\nFPS\\n45\\n7\\nTrained on Pascal VOC 2007 + 2012 dataset'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 40, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Limitations of Yolo\\nStruggles with small objects\\nStruggles with unusual aspect ratios\\nPoor localization'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 41, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='SSD Single Shot Detector\\nFaster than Yolo, as accurate as Faster R-CNN\\nPredicts categories and box offsets\\nUses small convolutional filters applied to feature maps\\nMakes predictions using feature maps of different scales\\nSSD: Single shot multibox detector\\nWei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander \\nC. Berg \\nDec 2015'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 42, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Comparison to Yolo\\nhttps://arxiv.org/pdf/1512.02325v5.pdf\\nSSD\\nYolo'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 43, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Default Boxes\\nMultiple aspect ratios per cell.\\nSimilar to Faster R-CNN Anchor Boxes.\\n-\\nApplied to many feature maps.\\nhttps://arxiv.org/pdf/1512.02325v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 44, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='SSD Detector\\nDetectors are convolutional filters.\\nEach detector outputs a single value.\\nPredict class probabilities.\\nPredict bounding box offsets.\\n(classes + 4) detectors are needed for a detection.\\n(classes + 4) x (#default boxes) x m x n outputs for a mxn feature map.'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 45, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Results (VOC 2007)\\nhttps://arxiv.org/pdf/1512.02325v5.pdf\\nSSD*\\nYolo*\\nFaster R-CNN*\\nmAP\\n74.3\\n66.4\\n73.2\\nFPS\\n46\\n21\\n7\\n*VGG16\\nTrained on Pascal VOC 2007 + 2012 dataset'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 46, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Others\\nPart III'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 47, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Feature Pyramid Networks\\nUses ConvNet as Feature Pyramid\\nIncludes low level feature maps to detect small objects\\nTop down pathway provides contextual information\\nFeature Pyramid Networks for Object Detection. \\nTsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie.\\nDec 2016'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 48, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Comparison to prior methods\\na.\\nAccurate but slow.\\nb.\\nMisses low level \\ninformation. (Yolo)\\nc.\\nMisses context in low \\nlevel predictions. \\n(SSD)\\nd.\\nAccurate and fast.\\nhttps://arxiv.org/pdf/1512.02325v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 49, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Top down pathway\\n-\\nHigh level (semantically strong) \\nfeature maps are upsampled. \\n-\\nLateral connections merge \\nfeature maps from bottom up \\npathway. \\nhttps://arxiv.org/pdf/1512.02325v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 50, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Feature Pyramid Networks for RPN\\n-\\nReplace single scale feature \\nmap with FPN.\\n-\\nSingle scale anchors at each \\nlevel.\\nhttps://arxiv.org/pdf/1512.02325v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 51, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Results\\n-\\nCOCO\\n-\\nState of the art single-model\\nhttps://arxiv.org/pdf/1512.02325v5.pdf\\nFaster R-CNN on FPN*\\nFaster R-CNN +++*\\nION**\\nmAP\\n36.2\\n34.9\\n31.2\\nmAP (small images)\\n18.2\\n15.6\\n12.8\\n* ResNet-101\\n** VGG-16'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 52, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='ION : Inside-Outside Network\\nUse multi-scale Conv features for inside region\\nUse four direction RNN features for outside region\\n \\nInside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks\\nSean Bell, C.Lawrence Zitnick, Kavita Bala, Ross Girshick\\nCornell University, Microsoft Research\\nCVPR 2016\\nhttps://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 53, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='ION: Inside-Outside Net\\n                                              https://www.robots.ox.ac.uk/~vgg/rg/slides/ion-coco.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 56, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Uses RNNs to capture context info from outside bounding box.'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 57, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Stack 2 RNNs together'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 58, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='ION: Inside-Outside Net\\nMain Changes:\\n-\\nInside: Skip connection with L2 normalization\\n-\\nOutside: Stacked 4-direction RNNs for context'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 59, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Results (VOC 2007)\\n                                              https://www.robots.ox.ac.uk/~vgg/rg/slides/ion-coco.pdf\\nTrained on Pascal VOC 2007 + 2012 dataset'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 60, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Summary and Comparison\\nPart IV'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 61, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Speed / Accuracy Trade-off\\nUnified tensorflow architecture\\nCompare speed, accuracy and memory usage\\n \\nSpeed/Accuracy trade-offs for modern convolutional object detectors\\nJonathan Huang, Kevin Murphy et al.\\nNov 2016\\nhttps://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 62, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Same Architectures\\n                                                                                       https://pan.baidu.com/s/1pKIKIIB\\nFeature \\nExtractor\\nFaster \\nRCNN\\nR-FCN\\nSSD\\nSpeed\\nAccuracy\\nMemory\\n...'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 63, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Recap: Faster RCNN\\n                                                                                       https://pan.baidu.com/s/1pKIKIIB'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 64, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Recap: R-FCN\\n                                                                                       https://pan.baidu.com/s/1pKIKIIB'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 65, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Recap: SSD\\n                                                                                       https://pan.baidu.com/s/1pKIKIIB'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 66, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Accuracy VS Speed'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 67, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='1. Different Feature Extractor'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 68, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='2. Detect Object Size'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 69, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='3. Image Resolution'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 70, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='4. Region Proposal Number'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 71, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='5. GPU Time'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 72, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='6. Memory'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 73, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Summary\\n●\\nSpeed First: SSD\\n●\\nBalance Speed and Accuracy:  R-FCN\\n●\\nAccuracy First: Faster RCNN (Reduce proposals, it can speed up a lot with \\nsome accuracy loss)'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 74, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Thanks!\\nQuestions?'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 76, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='References\\nGirshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra, Rich feature hierarchies for accurate object detection and semantic segmentation, CVPR 2014\\nHe, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian, Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition, ECCV 2014\\nGirshick, Ross, Fast R-CNN, ICCV 2015\\nRen, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian, Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks, CVPR 2015\\nJifeng Dai, Yi Li, Kaiming He, Jian Sun R-FCN: Object Detection via Region-based Fully Convolutional Networks, NIPS 2016\\nErhan, Dumitru and Szegedy, Christian and Toshev, Alexander and Anguelov, Dragomir, Scalable Object Detection using Deep Neural Networks, CVPR 2014\\nBell, Sean and Lawrence Zitnick, C and Bala, Kavita and Girshick, Ross, Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks, CVPR 2016'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 76, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Bell, Sean and Lawrence Zitnick, C and Bala, Kavita and Girshick, Ross, Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks, CVPR 2016\\nRedmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali, You Only Look Once: Unified, Real-Time Object Detection, CVPR 2016\\nLiu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C, SSD: Single Shot MultiBox Detector, ECCV \\n2016\\nTsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie, Feature Pyramid Networks for Object Detection, arXiv 2016\\nHuang, Jonathan and Rathod, Vivek and Sun, Chen and Zhu, Menglong and Korattikara, Anoop and Fathi, Alireza and Fischer, Ian and Wojna, Zbigniew and Song, Yang and \\nGuadarrama, Sergio and others,Speed/accuracy trade-offs for modern convolutional object detectors, arXiv 2016'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 77, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Bonus Material\\nPart V'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 78, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Yolo v2 Faster, Better Stronger'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 79, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Performance on  MS COCO \\n         Method                    Data                      IoU                      Area                  #Dets                 Area\\nAvg. Precision\\nAvg. Recall'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 80, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Fast RCNN vs Faster RCNN'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 81, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='SPP-Net\\nhttps://arxiv.org/pdf/1406.4729v4.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 82, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='SPP-Net\\nConvolution \\nand Pooling\\nFully connected layer\\nSoftmax loss\\nSoftmax loss\\nSPP pooling to a fix length \\nlayer (max pooling)\\nCrop & Warp'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 83, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='SPP-Net\\nhttps://arxiv.org/pdf/1406.4729v4.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 84, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Multi-Box'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 85, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Multi-Box\\nGoal: Achieve a class-agnostic scalable object detection by predicting a set of \\nbounding boxes.\\nTrain a neural network to directly predict: \\n-\\nThe upper-left and lower-right coordinates of each bounding box\\n-\\nThe confidence score for the box containing an object'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 86, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Train Objective\\nProduce fixed number of bounding boxes with confidence, such as K=100 or 200.'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 87, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Number of Windows')]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chunks = split_documents(all_pdf_documents)\n",
        "chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e03b1d7",
      "metadata": {},
      "source": [
        "Embeddings and Vectorstore DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f3951cab",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "import uuid\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "da5bf41a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading embedding model: all-MiniLM-L6-v2\n",
            "Model loaded successfully. Embedding dimension: 384\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<__main__.EmbeddingStore at 0x1feb203c830>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class EmbeddingStore:\n",
        "    def __init__(self, embedding_model_name: str = 'all-MiniLM-L6-v2'):\n",
        "        \"\"\"\n",
        "        Initialize the embedding store with a specified embedding model and ChromaDB client.\n",
        "        \n",
        "        Args:\n",
        "            model_name: HuggingFace model name for sentence embeddings.\n",
        "        \"\"\"\n",
        "        self.model_name = embedding_model_name\n",
        "        self.model = None\n",
        "        self._load_model() \n",
        "    \n",
        "    def _load_model(self):\n",
        "        \"\"\"Load the sentence transformer model\"\"\"\n",
        "        try:\n",
        "            print(f\"Loading embedding model: {self.model_name}\")\n",
        "            self.model = SentenceTransformer(self.model_name)\n",
        "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {self.model_name}: {e}\")\n",
        "            raise e\n",
        "        \n",
        "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Generate embeddings for a list of texts.\n",
        "        \n",
        "        Args:\n",
        "            texts: List of strings to embed.\n",
        "\n",
        "        Returns:\n",
        "            numpy array of embeddings with shape (len(texts), embedding_dimension).\n",
        "        \"\"\"\n",
        "        if not self.model:\n",
        "            raise ValueError(\"Embedding model is not loaded.\")\n",
        "        \n",
        "        print(f\"Generating embeddings for {len(texts)} texts.\")\n",
        "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
        "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
        "        return embeddings\n",
        "    \n",
        "    def get_embedding_dimension(self) -> int:\n",
        "        \"\"\"Get the dimension of the embeddings produced by the model.\"\"\"\n",
        "        if not self.model:\n",
        "            raise ValueError(\"Embedding model is not loaded.\")\n",
        "        return self.model.get_sentence_embedding_dimension()\n",
        "    \n",
        "# Initialize the embedding store\n",
        "embedding_store = EmbeddingStore()\n",
        "embedding_store\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96e06cb7",
      "metadata": {},
      "source": [
        "VectoreStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3be32227",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChromaDB client initialized. Collection: pdf_documents\n",
            "Existing documents in collection: 0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<__main__.VectorStore at 0x1feb39baa50>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class VectorStore:\n",
        "    \"\"\"Manages storage and retrieval of document embeddings using ChromaDB.\"\"\"\n",
        "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
        "        \"\"\"\n",
        "        Initialize the vector store with ChromaDB client and collection.\n",
        "        \n",
        "        Args:\n",
        "            collection_name: Name of the ChromaDB collection.\n",
        "            persist_directory: Directory to persist the ChromaDB data.\n",
        "        \"\"\"\n",
        "        self.collection_name = collection_name\n",
        "        self.persist_directory = persist_directory\n",
        "        self.client = None\n",
        "        self.collection = None\n",
        "        self._initialize_store()\n",
        "\n",
        "    def _initialize_store(self):\n",
        "        \"\"\"Initialize the ChromaDB client and collection.\"\"\"\n",
        "        try:\n",
        "            os.makedirs(self.persist_directory, exist_ok=True)\n",
        "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
        "\n",
        "            self.collection = self.client.get_or_create_collection(\n",
        "                name=self.collection_name,\n",
        "                metadata={\"description\": \"Collection of PDF document embeddings\"}\n",
        "            )\n",
        "            print(f\"ChromaDB client initialized. Collection: {self.collection_name}\")\n",
        "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error initializing ChromaDB client: {e}\")\n",
        "            raise e\n",
        "        \n",
        "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
        "        \"\"\"\n",
        "        Add documents and their embeddings to the vector store.\n",
        "        \n",
        "        Args:\n",
        "            documents: List of document objects with 'page_content' and 'metadata'.\n",
        "            embeddings: numpy array of embeddings corresponding to the documents.\n",
        "        \"\"\"\n",
        "        if len(documents) != embeddings.shape[0]:\n",
        "            raise ValueError(\"Number of documents and embeddings must match.\")\n",
        "        \n",
        "        print(f\"Adding {len(documents)} documents to the vector store.\")\n",
        "\n",
        "        # Prepare data for insertion in ChromaDB\n",
        "        ids = []\n",
        "        metadatas = []\n",
        "        document_texts = []\n",
        "        embeddings_list = []\n",
        "\n",
        "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
        "            # Generate a unique ID for each document\n",
        "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
        "            ids.append(doc_id)\n",
        "\n",
        "            # Prepare metadata\n",
        "            metadata = dict(doc.metadata)\n",
        "            metadata['doc_index'] = i\n",
        "            metadata['content_length'] = len(doc.page_content)\n",
        "            metadatas.append(metadata)\n",
        "\n",
        "            document_texts.append(doc.page_content)\n",
        "            embeddings_list.append(embedding.tolist())\n",
        "        \n",
        "        # Add to ChromaDB collection\n",
        "        try:\n",
        "            self.collection.add(\n",
        "                ids=ids,\n",
        "                embeddings=embeddings_list,\n",
        "                metadatas=metadatas,\n",
        "                documents=document_texts\n",
        "            )\n",
        "            print(f\"Successfully added {len(documents)} documents to the vector store.\")\n",
        "            print(f\"Total documents in collection after addition: {self.collection.count()}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error adding documents to vector store: {e}\")\n",
        "            raise e\n",
        "        \n",
        "# Initialize the vector store\n",
        "vector_store = VectorStore()\n",
        "vector_store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3874602f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 0, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 0, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='entirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1\\nIntroduction\\nRecurrent neural networks, long short-term memory [12] and gated recurrent [7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [29, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 0, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='transduction problems such as language modeling and machine translation [29, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 0, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='efﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 1, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Recurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsigniﬁcant improvements in computational efﬁciency through factorization tricks [18] and conditional\\ncomputation [26], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 1, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 16]. In all but a few cases [22], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2\\nBackground\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[20], ByteNet [15] and ConvS2S [8], all of which use convolutional neural networks as basic building'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 1, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[20], ByteNet [15] and ConvS2S [8], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difﬁcult to learn dependencies between distant positions [11]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 1, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='described in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 22, 23, 19].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [28].\\nTo the best of our knowledge, however, the Transformer is the ﬁrst transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 1, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [14, 15] and [8].\\n3\\nModel Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 29].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\\n[9], consuming the previously generated symbols as additional input when generating the next.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1\\nEncoder and Decoder Stacks\\nEncoder:'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 1, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1\\nEncoder and Decoder Stacks\\nEncoder:\\nThe encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position-\\n2'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 2, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Figure 1: The Transformer - model architecture.\\nwise fully connected feed-forward network. We employ a residual connection [10] around each of\\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder:\\nThe decoder is also composed of a stack of N = 6 identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 2, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='around each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3.2\\nAttention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1\\nScaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\n3'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 3, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Scaled Dot-Product Attention\\nMulti-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V ) = softmax(QKT\\n√dk\\n)V\\n(1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof\\n1\\n√dk . Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 3, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='1\\n√dk . Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efﬁcient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by\\n1\\n√dk .\\n3.2.2\\nMulti-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneﬁcial to linearly project the queries, keys and values h times with different, learned'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 3, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='we found it beneﬁcial to linearly project the queries, keys and values h times with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\noutput values. These are concatenated and once again projected, resulting in the ﬁnal values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = Pdk\\ni=1 qiki, has mean 0 and variance dk.\\n4'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 4, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='MultiHead(Q, K, V ) = Concat(head1, ..., headh)W O\\nwhere headi = Attention(QW Q\\ni , KW K\\ni , V W V\\ni )\\nWhere the projections are parameter matrices W Q\\ni\\n∈Rdmodel×dk, W K\\ni\\n∈Rdmodel×dk, W V\\ni\\n∈Rdmodel×dv\\nand W O ∈Rhdv×dmodel.\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3\\nApplications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[31, 2, 8].'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 4, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='position in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[31, 2, 8].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation ﬂow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3\\nPosition-wise Feed-Forward Networks'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 4, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='of the softmax which correspond to illegal connections. See Figure 2.\\n3.3\\nPosition-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0, xW1 + b1)W2 + b2\\n(2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4\\nEmbeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 4, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Similarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [24]. In the embedding layers, we multiply those weights by √dmodel.\\n3.5\\nPositional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\n5'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 5, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\\nLayer Type\\nComplexity per Layer\\nSequential\\nMaximum Path Length\\nOperations\\nSelf-Attention\\nO(n2 · d)\\nO(1)\\nO(1)\\nRecurrent\\nO(n · d2)\\nO(n)\\nO(n)\\nConvolutional\\nO(k · n · d2)\\nO(1)\\nO(logk(n))\\nSelf-Attention (restricted)\\nO(r · n · d)\\nO(1)\\nO(n/r)\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and ﬁxed [8].\\nIn this work, we use sine and cosine functions of different frequencies:\\nPE(pos,2i) = sin(pos/100002i/dmodel)\\nPE(pos,2i+1) = cos(pos/100002i/dmodel)\\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 5, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='PE(pos,2i) = sin(pos/100002i/dmodel)\\nPE(pos,2i+1) = cos(pos/100002i/dmodel)\\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any ﬁxed offset k, PEpos+k can be represented as a linear function of\\nPEpos.\\nWe also experimented with using learned positional embeddings [8] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4\\nWhy Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 5, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='during training.\\n4\\nWhy Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 5, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='dependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [11]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\nlength n is smaller than the representation dimensionality d, which is most often the case with'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 5, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='computational complexity, self-attention layers are faster than recurrent layers when the sequence\\nlength n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[31] and byte-pair [25] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\\n6'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 6, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='the input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k < n does not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [15], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [6], however, decrease the complexity\\nconsiderably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 6, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='convolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side beneﬁt, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5\\nTraining\\nThis section describes the training regime for our models.\\n5.1\\nTraining Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 6, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='target vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [31]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2\\nHardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3\\nOptimizer\\nWe used the Adam optimizer [17] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\\nrate over the course of training, according to the formula:'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 6, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='(3.5 days).\\n5.3\\nOptimizer\\nWe used the Adam optimizer [17] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate = d−0.5\\nmodel · min(step_num−0.5, step_num · warmup_steps−1.5)\\n(3)\\nThis corresponds to increasing the learning rate linearly for the ﬁrst warmup_steps training steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps = 4000.\\n5.4\\nRegularization\\nWe employ three types of regularization during training:\\nResidual Dropout\\nWe apply dropout [27] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\n7'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 7, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU\\nTraining Cost (FLOPs)\\nEN-DE\\nEN-FR\\nEN-DE\\nEN-FR\\nByteNet [15]\\n23.75\\nDeep-Att + PosUnk [32]\\n39.2\\n1.0 · 1020\\nGNMT + RL [31]\\n24.6\\n39.92\\n2.3 · 1019\\n1.4 · 1020\\nConvS2S [8]\\n25.16\\n40.46\\n9.6 · 1018\\n1.5 · 1020\\nMoE [26]\\n26.03\\n40.56\\n2.0 · 1019\\n1.2 · 1020\\nDeep-Att + PosUnk Ensemble [32]\\n40.4\\n8.0 · 1020\\nGNMT + RL Ensemble [31]\\n26.30\\n41.16\\n1.8 · 1020\\n1.1 · 1021\\nConvS2S Ensemble [8]\\n26.36\\n41.29\\n7.7 · 1019\\n1.2 · 1021\\nTransformer (base model)\\n27.3\\n38.1\\n3.3 · 1018\\nTransformer (big)\\n28.4\\n41.0\\n2.3 · 1019\\nLabel Smoothing\\nDuring training, we employed label smoothing of value ϵls = 0.1 [30]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6\\nResults\\n6.1\\nMachine Translation'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 7, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='hurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6\\nResults\\n6.1\\nMachine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The conﬁguration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 7, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='previous state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty α = 0.6 [31]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [31].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of ﬂoating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision ﬂoating-point capacity of each GPU 5.\\n6.2\\nModel Variations'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 7, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='model by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision ﬂoating-point capacity of each GPU 5.\\n6.2\\nModel Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 8, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN\\ndmodel\\ndff\\nh\\ndk\\ndv\\nPdrop\\nϵls\\ntrain\\nPPL\\nBLEU\\nparams\\nsteps\\n(dev)\\n(dev)\\n×106\\nbase\\n6\\n512\\n2048\\n8\\n64\\n64\\n0.1\\n0.1\\n100K\\n4.92\\n25.8\\n65\\n(A)\\n1\\n512\\n512\\n5.29\\n24.9\\n4\\n128\\n128\\n5.00\\n25.5\\n16\\n32\\n32\\n4.91\\n25.8\\n32\\n16\\n16\\n5.01\\n25.4\\n(B)\\n16\\n5.16\\n25.1\\n58\\n32\\n5.01\\n25.4\\n60\\n(C)\\n2\\n6.11\\n23.7\\n36\\n4\\n5.19\\n25.3\\n50\\n8\\n4.88\\n25.5\\n80\\n256\\n32\\n32\\n5.75\\n24.5\\n28\\n1024\\n128\\n128\\n4.66\\n26.0\\n168\\n1024\\n5.12\\n25.4\\n53\\n4096\\n4.75\\n26.2\\n90\\n(D)\\n0.0\\n5.77\\n24.6\\n0.2\\n4.95\\n25.5\\n0.0\\n4.67\\n25.3\\n0.2\\n5.47\\n25.7\\n(E)\\npositional embedding instead of sinusoids\\n4.92\\n25.7\\nbig\\n6\\n1024\\n4096\\n16\\n0.3\\n300K\\n4.33\\n26.4\\n213\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 8, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='(E)\\npositional embedding instead of sinusoids\\n4.92\\n25.7\\nbig\\n6\\n1024\\n4096\\n16\\n0.3\\n300K\\n4.33\\n26.4\\n213\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneﬁcial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-ﬁtting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [8], and observe nearly identical\\nresults to the base model.\\n7\\nConclusion\\nIn this work, we presented the Transformer, the ﬁrst sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 8, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='multi-headed self-attention.\\nFor translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efﬁciently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements\\nWe are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 8, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='tensorflow/tensor2tensor.\\nAcknowledgements\\nWe are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\n9'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 9, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='References\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 9, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='machine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[9] Alex Graves.\\nGenerating sequences with recurrent neural networks.\\narXiv preprint\\narXiv:1308.0850, 2013.\\n[10] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770–778, 2016.\\n[11] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient ﬂow in'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 9, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Recognition, pages 770–778, 2016.\\n[11] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient ﬂow in\\nrecurrent nets: the difﬁculty of learning long-term dependencies, 2001.\\n[12] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735–1780, 1997.\\n[13] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[14] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[15] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[16] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 9, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='2017.\\n[16] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[17] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[18] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[19] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[20] Samy Bengio Łukasz Kaiser. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n10'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 10, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='[21] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n[22] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing, 2016.\\n[23] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[24] Oﬁr Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[25] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[26] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 10, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.\\n[27] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overﬁtting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.\\n[28] Sainbayar Sukhbaatar, arthur szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\\nInc., 2015.\\n[29] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[30] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.'),\n",
              " Document(metadata={'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\attention.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 10, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='networks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[30] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\\n[31] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.\\n[32] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n11'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 0, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='What are embeddings\\nVicki Boykis'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 1, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Abstract\\nOver the past decade, embeddings — numerical representations of\\nmachine learning features used as input to deep learning models — have\\nbecome a foundational data structure in industrial machine learning\\nsystems. TF-IDF, PCA, and one-hot encoding have always been key tools\\nin machine learning systems as ways to compress and make sense of\\nlarge amounts of textual data. However, traditional approaches were\\nlimited in the amount of context they could reason about with increasing\\namounts of data. As the volume, velocity, and variety of data captured\\nby modern applications has exploded, creating approaches specifically\\ntailored to scale has become increasingly important.\\nGoogle’s Word2Vec paper made an important step in moving from\\nsimple statistical representations to semantic meaning of words. The\\nsubsequent rise of the Transformer architecture and transfer learning, as\\nwell as the latest surge in generative methods has enabled the growth'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 1, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='subsequent rise of the Transformer architecture and transfer learning, as\\nwell as the latest surge in generative methods has enabled the growth\\nof embeddings as a foundational machine learning data structure. This\\nsurvey paper aims to provide a deep dive into what embeddings are,\\ntheir history, and usage patterns in industry.\\nColophon\\nThis paper is typeset with LATEX. The cover art is Kandinsky’s \"Circles in a\\nCircle\" , 1923. ChatGPT was used to generate some of the figures.\\nCode, LATEX, and Website\\nThe latest version of the paper and code examples are available here. The\\nwebsite for this project is here.\\nAbout the Author\\nVicki Boykis is a machine learning engineer. Her website is vickiboykis.com\\nand her semantic search side project is viberary.pizza.\\nAcknowledgements\\nI’m grateful to everyone who has graciously offered technical feedback but\\nespecially to Nicola Barbieri, Peter Baumgartner, Luca Belli, James Kirk, and'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 1, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Acknowledgements\\nI’m grateful to everyone who has graciously offered technical feedback but\\nespecially to Nicola Barbieri, Peter Baumgartner, Luca Belli, James Kirk, and\\nRavi Mody. All remaining errors, typos, and bad jokes are mine. Thank you to\\nDan for your patience, encouragement, for parenting while I was in the latent\\nspace, and for once casually asking, \"How do you generate these ’embeddings’,\\nanyway?\"\\nLicense\\nThis work is licensed under a Creative Commons\\n“Attribution-NonCommercial-ShareAlike 3.0 Un-\\nported” license.\\n2'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 2, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Contents\\n1\\nIntroduction\\n4\\n2\\nRecommendation as a business problem\\n9\\n2.1\\nBuilding a web app . . . . . . . . . . . . . . . . . . . . . . . . .\\n11\\n2.2\\nRules-based systems versus machine learning\\n. . . . . . . . .\\n13\\n2.3\\nBuilding a web app with machine learning\\n. . . . . . . . . . .\\n15\\n2.4\\nFormulating a machine learning problem . . . . . . . . . . . .\\n17\\n2.4.1\\nThe Task of Recommendations . . . . . . . . . . . . . .\\n20\\n2.4.2\\nMachine learning features . . . . . . . . . . . . . . . . .\\n22\\n2.5\\nNumerical Feature Vectors . . . . . . . . . . . . . . . . . . . . .\\n23\\n2.6\\nFrom Words to Vectors in Three Easy Pieces . . . . . . . . . . .\\n24\\n3\\nHistorical Encoding Approaches\\n25\\n3.1\\nEarly Approaches . . . . . . . . . . . . . . . . . . . . . . . . . .\\n26\\n3.2\\nEncoding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n26\\n3.2.1\\nIndicator and one-hot encoding . . . . . . . . . . . . . .\\n27\\n3.2.2\\nTF-IDF . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n31\\n3.2.3'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 2, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='26\\n3.2.1\\nIndicator and one-hot encoding . . . . . . . . . . . . . .\\n27\\n3.2.2\\nTF-IDF . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n31\\n3.2.3\\nSVD and PCA . . . . . . . . . . . . . . . . . . . . . . . .\\n37\\n3.3\\nLDA and LSA . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n38\\n3.4\\nLimitations of traditional approaches . . . . . . . . . . . . . . .\\n39\\n3.4.1\\nThe curse of dimensionality . . . . . . . . . . . . . . . .\\n39\\n3.4.2\\nComputational complexity\\n. . . . . . . . . . . . . . . .\\n40\\n3.5\\nSupport Vector Machines . . . . . . . . . . . . . . . . . . . . . .\\n41\\n3.6\\nWord2Vec . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n42\\n4\\nModern Embeddings Approaches\\n50\\n4.1\\nNeural Networks . . . . . . . . . . . . . . . . . . . . . . . . . .\\n51\\n4.1.1\\nNeural Network architectures . . . . . . . . . . . . . . .\\n51\\n4.2\\nTransformers . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n53\\n4.2.1\\nEncoders/Decoders and Attention . . . . . . . . . . . .\\n54\\n4.3'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 2, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='51\\n4.2\\nTransformers . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n53\\n4.2.1\\nEncoders/Decoders and Attention . . . . . . . . . . . .\\n54\\n4.3\\nBERT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n59\\n4.4\\nGPT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n60\\n5\\nEmbeddings in Production\\n60\\n5.1\\nEmbeddings in Practice\\n. . . . . . . . . . . . . . . . . . . . . .\\n62\\n5.1.1\\nPinterest . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n62\\n5.1.2\\nYouTube and Google Play Store . . . . . . . . . . . . . .\\n63\\n5.1.3\\nTwitter . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n66\\n5.2\\nEmbeddings as an Engineering Problem . . . . . . . . . . . . .\\n69\\n5.2.1\\nEmbeddings Generation . . . . . . . . . . . . . . . . . .\\n71\\n5.2.2\\nStorage and Retrieval\\n. . . . . . . . . . . . . . . . . . .\\n72\\n5.2.3\\nDrift Detection, Versioning, and Interpretability . . . .\\n74\\n5.2.4\\nInference and Latency . . . . . . . . . . . . . . . . . . .\\n75\\n5.2.5'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 2, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='. . . . . . . . . . . . . . . . . . .\\n72\\n5.2.3\\nDrift Detection, Versioning, and Interpretability . . . .\\n74\\n5.2.4\\nInference and Latency . . . . . . . . . . . . . . . . . . .\\n75\\n5.2.5\\nOnline and Offline Model Evaluation . . . . . . . . . .\\n76\\n5.2.6\\nWhat makes embeddings projects successful . . . . . .\\n76\\n6\\nConclusion\\n76\\n3'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 3, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nIntroduction\\nImplementing deep learning models has become an increasingly important\\nmachine learning strategy1 for companies looking to build data-driven prod-\\nucts. In order to build and power deep learning models, companies collect and\\nfeed hundreds of millions of terabytes of multimodal2 data into deep learning\\nmodels. As a result, embeddings — deep learning models’ internal represen-\\ntations of their input data — are quickly becoming a critical component of\\nbuilding machine learning systems.\\nFor example, they make up a significant part of Spotify’s item recom-\\nmender systems [27], YouTube video recommendations of what to watch [11],\\nand Pinterest’s visual search [31]. Even if they are not explicitly presented\\nto the user through recommendation system UIs, embeddings are also used\\ninternally at places like Netflix to make content decisions around which shows\\nto develop based on user preference popularity.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 3, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='to the user through recommendation system UIs, embeddings are also used\\ninternally at places like Netflix to make content decisions around which shows\\nto develop based on user preference popularity.\\nFigure 1: Left to right: Products that use embeddings used to generate recommended items:\\nSpotify Radio, YouTube Video recommendations, visual recommendations at Pinterest, BERT\\nEmbeddings in suggested Google search results\\nThe usage of embeddings to generate compressed, context-specific repre-\\nsentations of content exploded in popularity after the publication of Google’s\\nWord2Vec paper [47].\\n1Check out the machine learning industrial view Matt Turck puts together every year, which\\nhas exploded in size.\\n2Multimodal means a variety of data usually including text, video, audio, and more recently\\nas shown in Meta’s ImageBind, depth, thermal, and IMU.\\n4'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 4, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 2: Embeddings papers in arXiv by month. It’s interesting to note the decline in\\nfrequency of embeddings-specific papers, possibly in tandem with the rise of deep learning\\narchitectures like GPT source\\nBuilding and expanding on the concepts in Word2Vec, the Transformer\\n[66] architecture, with its self-attention mechanism, a much more specialized\\ncase of calculating context around a given word, has become the de-facto\\nway to learn representations of growing multimodal vocabularies, and its rise\\nin popularity both in academia and in industry has caused embeddings to\\nbecome a staple of deep learning workflows.\\nHowever, the concept of embeddings can be elusive because they’re neither\\ndata flow inputs or output results - they are intermediate elements that live\\nwithin machine learning services to refine models. So it’s helpful to define\\nthem explicitly from the beginning.\\nAs a general definition, embeddings are data that has been transformed'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 4, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='within machine learning services to refine models. So it’s helpful to define\\nthem explicitly from the beginning.\\nAs a general definition, embeddings are data that has been transformed\\ninto n-dimensional matrices for use in deep learning computations. The\\nprocess of embedding (as a verb):\\n• Transforms multimodal input into representations that are easier to\\nperform intensive computation on, in the form of vectors, tensors, or\\ngraphs [51]. For the purpose of machine learning, we can think of\\nvectors as a list (or array) of numbers.\\n• Compresses input information for use in a machine learning task — the\\ntype of methods available to us in machine learning to solve specific\\nproblems — such as summarizing a document or identifying tags or\\nlabels for social media posts or performing semantic search on a large\\ntext corpus. The process of compression changes variable feature\\ndimensions into fixed inputs, allowing them to be passed efficiently'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 4, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='text corpus. The process of compression changes variable feature\\ndimensions into fixed inputs, allowing them to be passed efficiently\\ninto downstream components of machine learning systems.\\n• Creates an embedding space that is specific to the data the embeddings\\nwere trained on but that, in the case of deep learning representations,\\ncan also generalize to other tasks and domains through transfer\\nlearning — the ability to switch contexts — which is one of the\\nreasons embeddings have exploded in popularity across machine\\nlearning applications\\n5'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 5, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='What do embeddings actually look like? Here is one single embedding,\\nalso called a vector, in three dimensions. We can think of this as a repre-\\nsentation of a single element in our dataset. For example, this hypothetical\\nembedding represents a single word \"fly\", in three dimensions. Generally, we\\nrepresent individual embeddings as row vectors.\\n\\x02\\n1\\n4\\n9\\n\\x03\\n(1)\\nAnd here is a tensor, also known as a matrix3, which is a multidimensional\\ncombination of vector representations of multiple elements. For example, this\\ncould be the representation of \"fly\", and \"bird.\"\\n\\x141\\n4\\n9\\n4\\n5\\n6\\n\\x15\\n(2)\\nThese embeddings are the output of the process of learning embeddings,\\nwhich we do by passing raw input data into a machine learning model. We\\ntransform that multidimensional input data by compressing it, through the\\nalgorithms we discuss in this paper, into a lower-dimensional space. The\\nresult is a set of vectors in an embedding space.\\nWord\\nSentence\\nImage\\nMultimodal data\\n[1, 4, 9]\\n[1, 4, 7]\\n[12, 0, 3]'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 5, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='algorithms we discuss in this paper, into a lower-dimensional space. The\\nresult is a set of vectors in an embedding space.\\nWord\\nSentence\\nImage\\nMultimodal data\\n[1, 4, 9]\\n[1, 4, 7]\\n[12, 0, 3]\\nEmbedding Space\\nAlgorithm\\nFigure 3: The process of embedding.\\nWe often talk about item embeddings being in X dimensions, ranging\\nanywhere from 100 to 1000, with diminishing returns in usefulness somewhere\\nbeyond 768 in the context of using them for machine learning problems4. This\\nmeans that each item (image, song, word, etc) is represented by a vector of\\nlength X, where each value is a coordinate in an X-dimensional space. For\\nmore on growing embedding context sizes, see this addendum post written in\\n2025.\\nWe just made up an embedding for \"bird\", but let’s take a look at what a\\nreal one for the word \"hold\" would look like in the quote, as generated by the\\nBERT deep learning model,\\n\"Hold fast to dreams, for if dreams die, life is a broken-winged bird that\\ncannot fly.\" — Langston Hughes'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 5, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='BERT deep learning model,\\n\"Hold fast to dreams, for if dreams die, life is a broken-winged bird that\\ncannot fly.\" — Langston Hughes\\nWe’ve highlighted this quote because we’ll be working with this sentence\\nas our input example throughout this text.\\n3The difference between a matrix and a tensor is that it’s a matrix if you’re doing linear\\nalgebra and a tensor if you’re an AI researcher.\\n4Embedding size is tunable as a hyperparameter but so far there have only been a few\\npapers on optimal embedding size, with most of the size of embeddings set through magic and\\nguesswork\\n6'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 6, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nimport torch\\n2\\nfrom transformers import BertTokenizer, BertModel\\n3\\n4\\n# Load pre-trained model tokenizer (vocabulary)\\n5\\ntokenizer = BertTokenizer.from_pretrained(\\'bert-base-uncased\\')\\n6\\n7\\ntext = \"\"\"Hold fast to dreams, for if dreams die, life is a broken-winged bird\\nthat cannot fly.\"\"\"\\n,→\\n8\\n9\\n# Tokenize the sentence with the BERT tokenizer.\\n10\\ntokenized_text = tokenizer.tokenize(text)\\n11\\n12\\n# Print out the tokens.\\n13\\nprint (tokenized_text)\\n14\\n15\\n[\\'[CLS]\\', \\'hold\\', \\'fast\\', \\'to\\', \\'dreams\\', \\',\\', \\'for\\', \\'if\\', \\'dreams\\', \\'die\\',\\n\\',\\', \\'life\\', \\'is\\', \\'a\\', \\'broken\\', \\'-\\', \\'winged\\', \\'bird\\', \\'that\\', \\'cannot\\',\\n\\'fly\\', \\'.\\', \\'[SEP]\\']\\n,→\\n,→\\n16\\n17\\n# BERT code truncated to show the final output, an embedding\\n18\\n19\\n[tensor([-3.0241e-01, -1.5066e+00, -9.6222e-01,\\n1.7986e-01, -2.7384e+00,\\n20\\n-1.6749e-01,\\n7.4106e-01,\\n1.9655e+00,\\n4.9202e-01,\\n-2.0871e+00,\\n,→\\n21\\n-5.8469e-01,\\n1.5016e+00,\\n8.2666e-01,\\n8.7033e-01,\\n8.5101e-01,\\n,→\\n22\\n5.5919e-01, -1.4336e+00,\\n2.4679e+00,\\n1.3920e+00,\\n-3.9291e-01,\\n,→\\n23\\n-1.2054e+00,'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 6, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1.9655e+00,\\n4.9202e-01,\\n-2.0871e+00,\\n,→\\n21\\n-5.8469e-01,\\n1.5016e+00,\\n8.2666e-01,\\n8.7033e-01,\\n8.5101e-01,\\n,→\\n22\\n5.5919e-01, -1.4336e+00,\\n2.4679e+00,\\n1.3920e+00,\\n-3.9291e-01,\\n,→\\n23\\n-1.2054e+00,\\n1.4637e+00,\\n1.9681e+00,\\n3.6572e-01,\\n3.1503e+00,\\n,→\\n24\\n-4.4693e-01, -1.1637e+00,\\n2.8804e-01, -8.3749e-01,\\n1.5026e+00,\\n,→\\n25\\n-2.1318e+00,\\n1.9633e+00, -4.5096e-01, -1.8215e+00,\\n3.2744e+00,\\n,→\\n26\\n5.2591e-01,\\n1.0686e+00,\\n3.7893e-01, -1.0792e-01,\\n5.1342e-01,\\n,→\\n27\\n-1.0443e+00,\\n1.7513e+00,\\n1.3895e-01, -6.6757e-01,\\n-4.8434e-01,\\n,→\\n28\\n-2.1621e+00, -1.5593e+01,\\n1.5249e+00,\\n1.6911e+00,\\n-1.2916e+00,\\n,→\\n29\\n1.2339e+00, -3.6064e-01, -9.6036e-01,\\n1.3226e+00,\\n1.6427e+00,\\n,→\\n30\\n1.4588e+00, -1.8806e+00,\\n6.3620e-01,\\n1.1713e+00,\\n1.1050e+00, ...\\n,→\\n31\\n2.1277e+00])\\n32\\nFigure 4: Analyzing Embeddings with BERT. See full notebook source\\nWe can see that this embedding is a PyTorch tensor object, a multidimen-\\n7'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 7, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='sional matrix containing multiple levels of embeddings, and that’s because\\nin BERT’s embedding representation, we have 13 different layers. One em-\\nbedding layer is computed for each layer of the neural network. Each level\\nrepresents a different view of our given token — or simply a sequence of\\ncharacters. We can get the final embedding by pooling several layers, details\\nwe’ll get into as we work our way up to understanding embeddings generated\\nusing BERT.\\nWhen we create an embedding for a word, sentence, or image that rep-\\nresents the artifact in the multidimensional space, we can do any number\\nof things with this embedding. For example, for tasks that focus on content\\nunderstanding in machine learning, we are often interested in comparing two\\ngiven items to see how similar they are. Projecting text as a vector allows us\\nto do so with mathematical rigor and compare words in a shared embedding\\nspace.\\nx\\ny\\nbird\\ndog\\nfly\\nFigure 5: Projecting words into a shared embedding space'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 7, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='to do so with mathematical rigor and compare words in a shared embedding\\nspace.\\nx\\ny\\nbird\\ndog\\nfly\\nFigure 5: Projecting words into a shared embedding space\\nFigure 6: Embeddings in the context of an application.\\nEngineering systems based on embeddings can be computationally ex-\\npensive to build and maintain [61]. The need to create, store, and manage\\nembeddings has also recently resulted in the explosion of an entire ecosystem\\nof related products. For example, the recent rise in the development of vector\\ndatabases to facilitate production-ready use of nearest neighbors semantic\\nqueries in machine learning systems5, and the rise of embeddings as a service6.\\nAs such, it’s important to understand their context both as end-consumers,\\nproduct management teams, and as developers who work with them. But in\\nmy deep-dive into the embeddings reference material, I found that there are\\ntwo types of resources: very deeply technical academic papers, for people who'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 7, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='my deep-dive into the embeddings reference material, I found that there are\\ntwo types of resources: very deeply technical academic papers, for people who\\n5For a survey of the vector database space today, refer to this article\\n6Embeddings now are a key differentiator in pricing between on-demand ML services\\n8'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 8, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='are already NLP experts, and surface-level marketing spam blurbs for people\\nlooking to buy embeddings-based tech, and that neither of these overlap in\\nwhat they cover.\\nIn Systems Thinking, Donella Meadows writes, “You think that because\\nyou understand ’one’ that you must therefore understand ’two’ because one\\nand one make two. But you forget that you must also understand ’and.’\"\\n[45] In order to understand the current state of embedding architectures and\\nbe able to decide how to build them, we must understand how they came\\nto be. In building my own understanding, I wanted a resource that was\\ntechnical enough to be useful enough to ML practitioners, but one that also\\nput embeddings in their correct business and engineering contexts as they\\nbecome more often used in ML architecture stacks. This is, hopefully, that text.\\nIn this text, we’ll examine embeddings from three perspectives, working\\nour way from the highest level view to the most technical. We’ll start with'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 8, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='In this text, we’ll examine embeddings from three perspectives, working\\nour way from the highest level view to the most technical. We’ll start with\\nthe business context, followed by the engineering implementation, and finally\\nlook at the machine learning theory, focusing on the nuts and bolts of how\\nthey work. On a parallel axis, we’ll also travel through time, surveying the\\nearliest approaches and moving towards modern embedding approaches.\\nIn writing this text, I strove to balance the need to have precise technical\\nand mathematical definitions for concepts and my desire to stay away from\\nexplanations that make people’s eyes glaze over. I’ve defined all technical\\njargon when it appears for the first time to build context. I include code as\\na frame of reference for practitioners, but don’t go as deep as a code tutorial\\nwould7. So, it would be helpful for the reader to have some familiarity with\\nprogramming and machine learning basics, particularly after the sections that'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 8, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='would7. So, it would be helpful for the reader to have some familiarity with\\nprogramming and machine learning basics, particularly after the sections that\\ndiscuss business context. But, ultimately the goal is to educate anyone who is\\nwilling to sit through this, regardless of level of technical understanding.\\nIt’s worth also mentioning what this text does not try to be: it does not try\\nto explain the latest advancements in GPT and generative models, it does not\\ntry to explain transformers in their entirety, and it does not try to cover all\\nof the exploding field of vector databases and semantic search. I’ve tried my\\nbest to keep it simple and focus on really understanding the core concept of\\nembeddings.\\n2\\nRecommendation as a business problem\\nLet’s step back and look at the larger context with a concrete example before\\ndiving into implementation details. Let’s build a social media network, Flutter,\\nthe premier social network for all things with wings. Flutter is a web and'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 8, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='diving into implementation details. Let’s build a social media network, Flutter,\\nthe premier social network for all things with wings. Flutter is a web and\\nmobile app where birds can post short snippets of text, videos, images, and\\nsounds, to let other birds, insects and bats in the area know what’s up. Its\\nbusiness model is based on targeted advertising, and its app architecture\\nincludes a \"home\" feed based on birds that you follow, made up of small\\npieces of multimedia content called “flits”, which can be either text, videos,\\nor photos. The home feed itself is by default in reverse chronological order\\n7In other words, I wanted to straddle the \"explanation\" and \"reference\" quadrants of the\\nDiátaxis framework\\n9'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 9, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='that is curated by the user. But we also would like to offer personalized,\\nrecommended flits so that the user finds interesting content on our platform\\nthat they might have not known about before.\\nFigure 7: Flutter’s content timeline in a social feed with a blend of organic followed content,\\nadvertising, and recommendations.\\nHow do we solve the problem of what to show in the timeline here so that\\nour users find the content relevant and interesting, and balance the needs of\\nour advertisers and business partners?\\nIn many cases, we can approach engineering solutions without involving\\nmachine learning. In fact, we should definitely start without it [76] because\\nmachine learning adds a tremendous amount of complexity to our working\\napplication [57]. In the case of the Flutter home feed, though, machine learning\\nforms a business-critical function part of the product offering. From the\\nbusiness product perspective, the objective is to offer Flutter’s users content'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 9, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='forms a business-critical function part of the product offering. From the\\nbusiness product perspective, the objective is to offer Flutter’s users content\\nthat is relevant8, interesting, and novel so they continue to use the platform.\\nIf we do not build discovery and personalization into our content-centric\\nproduct, Flutter users will not be able to discover more content to consume\\nand will disengage from the platform.\\nThis is the case for many content-based businesses, all of which have feed-\\nlike surface areas for recommendations, including Netflix, Pinterest, Spotify,\\nand Reddit. It also covers e-commerce platforms, which must surface relevant\\n8The specific definition of a relevant item in the recommendations space varies and is under\\nintense academic and industry debate, but generally it means an item that is of interest to the\\nuser\\n10'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 10, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='items to the user, and information retrieval platforms like search engines,\\nwhich must provide relevant answers to users upon keyword queries. There\\nis a new category of hybrid applications involving question-and-answering\\nin semantic search contexts that is arising as a result of work around the GPT\\nseries of models, but for the sake of simplicity, and because that landscape\\nchanges every week, we’ll stick to understanding the fundamental underlying\\nconcepts.\\nIn subscription-based platforms9, there is clear business objective that’s\\ntied directly to the bottom line, as outlined in this 2015 paper [64] about\\nNetflix’s recsys:\\nThe main task of our recommender system at Netflix is to help\\nour members discover content that they will watch and enjoy\\nto maximize their long-term satisfaction. This is a challenging\\nproblem for many reasons, including that every person is unique,\\nhas a multitude of interests that can vary in different contexts, and'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 10, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='to maximize their long-term satisfaction. This is a challenging\\nproblem for many reasons, including that every person is unique,\\nhas a multitude of interests that can vary in different contexts, and\\nneeds a recommender system most when they are not sure what\\nthey want to watch. Doing this well means that each member gets\\na unique experience that allows them to get the most out of Netflix.\\nAs a monthly subscription service, member satisfaction is tightly\\ncoupled to a person’s likelihood to retain with our service, which\\ndirectly impacts our revenue.\\nKnowing this business context, and given that personalized content is\\nmore relevant and generally gets higher rates of engagement [30] than non-\\npersonalized forms of recommendation on online platforms,10 how and why\\nmight we use embeddings in machine learning workflows in Flutter to show\\nusers flits that are interesting to them personally? We need to first understand\\nhow web apps work and where embeddings fit into them.\\n2.1'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 10, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='users flits that are interesting to them personally? We need to first understand\\nhow web apps work and where embeddings fit into them.\\n2.1\\nBuilding a web app\\nMost of the apps we use today — Spotify, Gmail, Reddit, Slack, and Flutter\\n— are all designed based on the same foundational software engineering\\npatterns. They are all apps available on web and mobile clients. They all have\\na front-end where the user interacts with the various product features of the\\napplications, an API that connects the front-end to back-end elements, and a\\ndatabase that processes data and remembers state.\\n9In ad-based services, the line between retention and revenue is a bit murkier, and we have\\noften what’s known as a multi-stakeholder problem, where the actual optimized function is a\\nbalance between meeting the needs of the user and meeting the needs of the advertiser [75]. In\\nreal life, this can often result in a process of enshittification [15] of the platform that leads to'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 10, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='balance between meeting the needs of the user and meeting the needs of the advertiser [75]. In\\nreal life, this can often result in a process of enshittification [15] of the platform that leads to\\nextremely suboptimal end-user experiences. So, when we create Flutter, we have to be very\\ncareful to balance these concerns, and we’ll also assume for the sake of simplification that\\nFlutter is a Good service that loves us as users and wants us to be happy.\\n10For more, see this case study on personalized recommendations as well as the intro section\\nof this paper which covers many personalization use-cases.\\n11'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 11, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='As an important note, features have many different definitions in machine\\nlearning and engineering. In this specific case, we mean collections of\\ncode that make up some front-end element, such as a button or a panel of\\nrecommendations. We’ll refer to these as product features, in contrast with\\nmachine learning features, which are input data into machine learning\\nmodels.\\nThis application architecture is commonly known as model-view-\\ncontroller pattern [20], or in common industry lingo, a CRUD app, named for\\nthe basic operations that its API allows to manage application state: create,\\nread, update, and delete.\\nFigure 8: Typical CRUD web app architecture\\nWhen we think of structural components in the architectures of these ap-\\nplications, we might think first in terms of product features. In an application\\nlike Slack, for example, we have the ability to post and read messages, man-\\nage notifications, and add custom emojis. Each of these can be seen as an'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 11, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='like Slack, for example, we have the ability to post and read messages, man-\\nage notifications, and add custom emojis. Each of these can be seen as an\\napplication feature. In order to create features, we have to combine common\\nelements like databases, caches, and web services. All of this happens as\\nthe client talks to the API, which talks to the database to process data. At a\\nmore granular, program-specific level, we might think of foundational data\\nstructures like arrays or hash maps, and lower still, we might think about\\nmemory management and network topologies. These are all foundational\\nelements of modern programming.\\nAt the feature level, though, we see that it not only includes the typical\\nCRUD operations, such as the ability to post and read Slack messages, but\\nalso elements that are more than operations that alter database state. Some\\nfeatures such as personalized channel suggestions, returning relevant results'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 11, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='also elements that are more than operations that alter database state. Some\\nfeatures such as personalized channel suggestions, returning relevant results\\nthrough search queries, and predicting Slack connection invites necessitates\\nthe use of machine learning.\\n12'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 12, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 9: CRUD App with Machine learning service\\n2.2\\nRules-based systems versus machine learning\\nTo understand where embeddings fit into these systems, it first makes sense to\\nunderstand where machine learning fits in at Flutter, or any given company,\\nas a whole. In a typical consumer company, the user-facing app is made up\\nof product features written in code, typically written as services or parts of\\nservices. To add a new web app feature, we write code based on a set of\\nbusiness logic requirements. This code acts on data in the app to develop our\\nnew feature.\\nIn a typical data-centric software development lifecycle, we start with the\\nbusiness logic. For example, let’s take the ability to post messages. We’d like\\nusers to be able to input text and emojis in their language of choice, have the\\nmessages sorted chronologically, and render correctly on web and mobile.\\nThese are the business requirements. We use the input data, in this case, user'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 12, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='messages sorted chronologically, and render correctly on web and mobile.\\nThese are the business requirements. We use the input data, in this case, user\\nmessages, and format them correctly and sort chronologically, at low latency,\\nin the UI.\\nFigure 10: A typical application development lifecycle\\nMachine learning-based systems are typically also services in the backend\\nof web applications. They are integrated into production workflows. But, they\\nprocess data much differently. In these systems, we don’t start with business\\nlogic. We start with input data that we use to build a model that will suggest\\nthe business logic for us. For more on the specifics of how to think about these\\ndata-centric engineering systems, see Kleppmann[35].\\nThis requires thinking about application development slightly differently,\\nand when we write an application that includes machine learning models as\\ninput, however, we’re inverting the traditional app lifecycle. What we have'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 12, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='and when we write an application that includes machine learning models as\\ninput, however, we’re inverting the traditional app lifecycle. What we have\\ninstead, is data plus our desired outcome. The data is combined into a model,\\nand it is this model which instead generates our business logic that builds\\nfeatures.\\nFigure 11: ML Development lifecycle\\n13'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 13, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='In short, the difference between programming and machine learning de-\\nvelopment is that we are not generating answers through business rules, but\\nbusiness rules through data. These rules are then re-incorporated into the\\napplication.\\nFigure 12: Generating answers via machine learning. The top chart shows a classical\\nprogramming approach with rules and data as inputs, while the bottom chart shows a machine\\nlearning approach with data and answers as inputs. [8]\\nAs an example, with Slack, for the channel recommendations product\\nfeature, we are not hard-coding a list of channels that need to be called from\\nthe organization’s API. We are feeding in data about the organization’s users\\n(what other channels they’ve joined, how long they’ve been users, what\\nchannels the people they’ve interacted the most with Slack in), and building a\\nmodel on that data that recommends a non-deterministic, personalized list of\\nchannels for each user that we then surface through the UI.\\n14'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 14, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 13: Traditional versus ML architecture and infra\\n2.3\\nBuilding a web app with machine learning\\nAll machine learning systems can be examined through how they accomplish\\nthese four steps. When we build models, our key questions should be, \"what\\nkind of input do we have and how is it formatted\", and \"what do we get as a\\nresult.\" We’ll be asking this for each of the approaches we look at. When we\\nbuild a machine learning system, we start by processing data and finish by\\nserving a learned model artifact.\\nThe four components of a machine learning system are11:\\n• Input data - processing data from a database or streaming from a\\nproduction application for use in modeling\\n• Feature Engineering and Selection - The process of examining the\\ndata and cleaning it to pick features. In this case, we mean features\\nas attributes of any given element that we use as inputs into machine\\nlearning. Examples of features are: user name, geographic location,'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 14, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='as attributes of any given element that we use as inputs into machine\\nlearning. Examples of features are: user name, geographic location,\\nhow many times they’ve clicked on a button for the past 5 days, and\\nrevenue. This piece always takes the longest in any given machine\\nlearning system, and is also known as finding representations [4] of\\nthe data that best fit the machine learning algorithm. This is where,\\nin the new model architectures, we use embeddings as input.\\n• Model Building - We select the features that are important and train\\nour model, iterating on different performance metrics over and over\\nagain until we have an acceptable model we can use. Embeddings\\nare also the output of this step that we can use in other, downstream\\nsteps.\\n11There are infinitely many layers of horror in ML systems [37]. These are still the founda-\\ntional components.\\n15'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 15, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• Model Serving - Now that we have a model we like, we serve it to\\nproduction, where it hits a web service, potentially cache, and our\\nAPI where it then propagates to the front-end for the user to consume\\nas part of our web app\\nFigure 14: CRUD app with ML\\nWithin machine learning, there are many approaches we can use to fit\\ndifferent tasks. Machine learning workflows that are most effective are formu-\\nlated as solutions to both a specific business need and a machine learning task.\\nTasks can best be thought of as approaches to modeling within the categorized\\nsolution space. For example, learning a regression model is a specific case\\nof a task. Others include clustering, machine translation, anomaly detection,\\nsimilarity matching, or semantic search. The three highest-level types of ML\\ntasks are supervised, where we have training data that can tell us whether the\\nresults the model predicted are correct according to some model of the world.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 15, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='tasks are supervised, where we have training data that can tell us whether the\\nresults the model predicted are correct according to some model of the world.\\nThe second is unsupervised, where there is not a single ground-truth answer.\\nAn example here is clustering of our customer base. A clustering model can\\ndetect patterns in your data but won’t explicitly label what those patterns are.\\nThe third is reinforcement learning which is separate from these two cate-\\ngories and formulated as a game theory problem: we have an agent moving\\nthrough an environment and we’d like to understand how to optimally move\\nthem through a given environment using explore-exploit techniques. We’ll\\nfocus on supervised learning, with a look at unsupervised learning with PCA\\nand Word2Vec.\\n16'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 16, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Machine Learning\\nSupervised Machine Learning\\nSVM\\nRegression\\nNeural\\nNetworks\\nUnsupervised\\nMachine\\nLearning\\nClustering\\nDimensionality\\nReduction\\nPCA\\nReinforcement\\nLearning\\nFigure 15: Machine learning task solution space and model families\\n2.4\\nFormulating a machine learning problem\\nAs we saw in the last section, machine learning is a process that takes data\\nas input to produce rules for how we should classify something or filter it\\nor recommend it, depending on the task at hand. In any of these cases, for\\nexample, to generate a set of potential candidates, we need to construct a\\nmodel.\\nA machine learning model is a set of instructions for generating a given\\noutput from data. The instructions are learned from the features of the input\\ndata itself. For Flutter, an example of a model we’d like to build is a candidate\\ngenerator that picks flits similar to flits our birds have already liked, because\\nwe think users will like those, too. For the sake of building up the intuition'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 16, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='generator that picks flits similar to flits our birds have already liked, because\\nwe think users will like those, too. For the sake of building up the intuition\\nfor a machine learning workflow, let’s pick a super-simple example that is not\\nrelated to our business problem, linear regression, which gives us a continuous\\nvariable as output in response.\\nFor example, let’s say, given the number of posts a user has made and how\\nmany posts they’ve liked, we’d like to predict how many days they’re likely to\\ncontinue to stay on Flutter. For traditional supervised modeling approaches\\nusing tabular data, we start with our input data, or a corpus as it’s generally\\nknown in machine learning problems that deal with text in the field known as\\nNLP (natural language processing).\\nWe’re not doing NLP yet, though, so our input data may look something\\nlike this, where we have a UID (userid) and some attributes of that user, such\\nas the number of times they’ve posted and number of posts they’ve liked.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 16, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='like this, where we have a UID (userid) and some attributes of that user, such\\nas the number of times they’ve posted and number of posts they’ve liked.\\nThese are our machine learning features.\\n17'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 17, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Table 1: Tabular Input Data for Flutter Users\\nbird_id\\nbird_posts\\nbird_likes\\n012\\n2\\n5\\n013\\n0\\n4\\n056\\n57\\n70\\n612\\n0\\n120\\nWe’ll need part of this data to train our model, part of it to test the accuracy\\nof the model we’ve trained, and part to tune meta-aspects of our model. These\\nare known as hyperparameters.\\nWe take two parts of this data as holdout data that we don’t feed into the\\nmodel. The first part, the test set, we use to validate the final model on data\\nit’s never seen before. We use the second split, called the validation set, to\\ncheck our hyperparameters during the model training phase. In the case of\\nlinear regression, there are no true hyperparameters, but we’ll need to keep in\\nmind that we will need to tune the model’s metadata for more complicated\\nmodels.\\nLet’s assume we have 100 of these values. A usual accepted split is to use\\n80% of data for training and 20% for testing. The reasoning is we want our\\nmodel to have access to as much data as possible so it learns a more accurate'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 17, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='80% of data for training and 20% for testing. The reasoning is we want our\\nmodel to have access to as much data as possible so it learns a more accurate\\nrepresentation.\\nIn general, our goal is to feed our input into the model, through a function\\nthat we pick, and get some predicted output, f (X) →y.\\nFigure 16: How inputs map to outputs in ML functions [34]\\nFor our simple dataset, we can use the linear regression equation:\\ny = x1β1 + x2β2 + ε\\n(3)\\nThis tells us that the output, y, can be predicted by two input variables, x1\\n(bird posts) and x2 (bird likes) with their given weights, β1 and β2, plus an\\nerror term ε, or the distance between each data point and the regression line\\ngenerated by the equation. Our task is to find the smallest sum of squared\\n18'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 18, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='differences between each point and the line, in other words to minimize the\\nerror, because it will mean that, at each point, our predicted y is as close to our\\nactual y as we can get it, given the other points.\\ny = x1β1 + x2β2 + ε\\n(4)\\nThe heart of machine learning is this training phase, which is the process of\\nfinding a combination of model instructions and data that accurately represent\\nour real data, which, in supervised learning, we can validate by checking the\\ncorrect \"answers\" from the test set.\\nFigure 17: The cycle of machine learning model development\\nAs the first round of training starts, we have our data. We train — or\\nbuild — our model by initializing it with a set of inputs, X. These are from the\\ntraining data. β1 and β2 are either initialized by setting to zero or initialized\\nrandomly (depending on the model, different approaches work best), and we\\ncalculate ˆy, our predicted value for the model. ϵ is derived from the data and'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 18, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='randomly (depending on the model, different approaches work best), and we\\ncalculate ˆy, our predicted value for the model. ϵ is derived from the data and\\nthe estimated coefficients once we get an output.\\ny = 2β1 + 5β2 + ε\\n(5)\\nHow do we know our model is good? We initialize it with some set of\\nvalues, weights, and we iterate on those weights, usually by minimizing a cost\\nfunction. The cost function is a function that models the difference between\\nour model’s predicted value and the actual output for the training data. The\\nfirst output may not be the most optimal, so we iterate over the model space\\nmany times, optimizing for the specific metric that will make the model as\\nrepresentative of reality as possible and minimize the difference between the\\nactual and predicted values. So in our case, we compare ˆy to y. The average\\nsquared difference between an observation’s actual and predicted values is\\nthe cost, otherwise known as MSE - mean squared error.\\nMSE = 1\\nN\\nn\\n∑\\ni=1\\n(yi −(mxi + b))2'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 18, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='squared difference between an observation’s actual and predicted values is\\nthe cost, otherwise known as MSE - mean squared error.\\nMSE = 1\\nN\\nn\\n∑\\ni=1\\n(yi −(mxi + b))2\\n(6)\\nWe’d like to minimize this cost, and we do so with gradient descent. When\\nwe say that the model learns, we mean that we can learn what the correct\\ninputs into a model are through an of iterative process where we feed the\\nmodel data, evaluate the output, and to see if the predictions it generates\\n19'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 19, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='improve through the process of gradient descent. We’ll know because our loss\\nshould incrementally decrease in every training iteration.\\nWe have finally trained our model. Now, we test the model’s predictions\\non the 20 values that we’ve used as a hold-out set; i.e. the model has not seen\\nthese before and we can confidently assume that they won’t influence the\\ntraining data. We compare how many elements of the hold-out set the model\\nwas able to predict correctly to see what the model’s accuracy was.\\n2.4.1\\nThe Task of Recommendations\\nWe just saw a simple example of machine learning as it relates to predicting\\ncontinuous response variables. When our business question is, \"What would\\nbe good content to show our users,\" we are facing the machine learning task for\\nrecommendation. Recommender systems are systems set up for information\\nretrieval, a field closely related to NLP that’s focused on finding relevant in-\\nformation in large collections of documents. The goal of information retrieval'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 19, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='retrieval, a field closely related to NLP that’s focused on finding relevant in-\\nformation in large collections of documents. The goal of information retrieval\\nis to synthesize large collections of unstructured text documents. Within infor-\\nmation retrieval, there are two complementary solutions in how we can offer\\nusers the correct content in our app: search, and recommendations.\\nSearch is the problem of directed [17] information seeking, i.e. the user\\noffers the system a specific query and would like a set of refined results.\\nSearch engines at this point are a well-established traditional solution in\\nthe space.\\nRecommendation is a problem where \"man is the query.\" [58] Here,\\nwe don’t know what the person is looking for exactly, but we would like\\nto infer what they like, and recommend items based on their learned tastes\\nand preferences.\\nThe first industrial recommender systems were created to filter messages\\nin email and newsgroups [22] at the Xerox Palo Alto Research Center based'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 19, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='and preferences.\\nThe first industrial recommender systems were created to filter messages\\nin email and newsgroups [22] at the Xerox Palo Alto Research Center based\\non a growing need to filter incoming information from the web. The most\\ncommon recommender systems today are those at Netflix, YouTube, and other\\nlarge-scale platforms that need a way to surface relevant content to users.\\nThe goal of recommender systems is surface items that are relevant to the\\nuser. Within the framework of machine learning approaches for recommenda-\\ntion, the main machine learning task is to determine which items to show to a\\nuser in a given situation. [5]. There are several common ways to approach the\\nrecommendation problem.\\n• Collaborative filtering - The most common approach for creating\\nrecommendations is to formulate our data as a problem of finding\\nmissing user-item interactions in a given set of user-item interaction\\nhistory. We start by collecting either explicit (ratings) data or implicit'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 19, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='missing user-item interactions in a given set of user-item interaction\\nhistory. We start by collecting either explicit (ratings) data or implicit\\nuser interaction data like clicks, pageviews, or time spent on items,\\nand compute. The simplest form of interactions are neighborhood\\nmodels, where ratings are predicted initially by finding users similar\\nto our given target user. We use similarity functions to compute the\\n20'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 20, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='closeness of users. Another common approach is using methods\\nsuch matrix factorization, the process of representing users and\\nitems in a feature matrix made up of low-dimensional factor vectors,\\nwhich in our case, are also known as embeddings, and learning those\\nfeature vectors through the process of minimizing a cost function.\\nThis process can be thought of as similar to Word2Vec [43], a deep\\nlearning model which we’ll discuss in depth in this document. There\\nare many different approaches to collaborative filtering, including\\nmatrix factorization and factorization machines.\\n• Content filtering - This approach uses metadata available about our\\nitems (for example in movies or music, the title, year released, genre,\\nand so on) as initial or additional features input into models and\\nwork well when we don’t have much information about user activ-\\nity, although they are often used in combination with collaborative\\nfiltering approaches. Many embeddings architectures fall into this'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 20, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='work well when we don’t have much information about user activ-\\nity, although they are often used in combination with collaborative\\nfiltering approaches. Many embeddings architectures fall into this\\ncategory since they help us model the textual features for our items.\\n• Learn to Rank - Learn to rank methods focus on ranking items in\\nrelation to each other based on a known set of preferred rankings\\nand the error is the number of cases when pairs or lists of items\\nare ranked incorrectly. Here, the problem is not presenting a single\\nitem, but a set of items and how they interplay. This step normally\\ntakes place after candidate generation, in a filtering step, because it’s\\ncomputationally expensive to rank extremely large lists.\\n• Neural Recommendations - The process of using neural networks to\\ncapture the same relationships that matrix factorization does without\\nexplicitly having to create a user/item matrix and based on the shape'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 20, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='capture the same relationships that matrix factorization does without\\nexplicitly having to create a user/item matrix and based on the shape\\nof the input data. This is where deep learning networks, and recently,\\nlarge language models, come into play. Examples of deep learning\\narchitectures used for recommendation include Word2Vec and BERT,\\nwhich we’ll cover in this document, and convolutional and recurrent\\nneural networks for sequential recommendation (such as is found\\nin music playlists, for example). Deep learning allows us to better\\nmodel content-based recommendations and give us representations\\nof our items in an embedding space. [73]\\nRecommender systems have evolved their own unique architectures12,\\nand they usually include constructing a four-stage recommender system that’s\\nmade up of several machine learning models, each of which perform a differ-\\nent machine learning task.\\nFigure 18: Recommender systems as a machine learning problem'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 20, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='made up of several machine learning models, each of which perform a differ-\\nent machine learning task.\\nFigure 18: Recommender systems as a machine learning problem\\n12For a good survey on the similarities and difference between search and recommendations,\\nread this great post on system design\\n21'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 21, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• Candidate Generation - First, we ingest data from the web app. This\\ndata goes into the initial piece, which hosts our first-pass model\\ngenerating candidate recommendations. This is where collaborative\\nfiltering takes place, and we whittle our list of potential candidates\\ndown from millions to thousands or hundreds.\\n• Ranking - Finally, we need a way to order the filtered list of recom-\\nmendations based on what we think the user will prefer the most, so\\nthe next stage is ranking, and then we serve them out in the timeline\\nor the ML product interface we’re working with.\\n• Filtering - Once we have a generated list of candidates, we want to\\ncontinue to filter them, using business logic (i.e. we don’t want to\\nsee NSFW content, or items that are not on sale, for example.). This\\nis generally a heavily heuristic-based step.\\n• Retrieval - This is the piece where the web application usually hits\\na model endpoint to get the final list of items served to the user\\nthrough the product UI.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 21, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• Retrieval - This is the piece where the web application usually hits\\na model endpoint to get the final list of items served to the user\\nthrough the product UI.\\nDatabases have become the fundamental tool in building backend in-\\nfrastructure that performs data lookups. Embeddings have become similar\\nbuilding blocks in the creation of many modern search and recommendation\\nproduct architectures. Embeddings are a type of machine learning feature —\\nor model input data — that we use first as input into the feature engineering\\nstage, and the first set of results that come from our candidate generation\\nstage, that are then incorporated into downstream processing steps of ranking\\nand retrieval to produce the final items the user sees.\\n2.4.2\\nMachine learning features\\nNow that we have a high-level conceptual view of how machine learning and\\nrecommender systems work, let’s build towards a candidate generation model\\nthat will offer relevant flits.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 21, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Now that we have a high-level conceptual view of how machine learning and\\nrecommender systems work, let’s build towards a candidate generation model\\nthat will offer relevant flits.\\nLet’s start by modeling a traditional machine learning problem and con-\\ntrast it with our NLP problem. For example, let’s say that one of our business\\nproblems is predicting whether a bird is likely to continue to stay on Flutter or\\nto churn13 — disengage and leave the platform.\\nWhen we predict churn, we have a given set of machine learning feature\\ninputs for each user and a final binary output of 1 or 0 from the model, 1 if the\\nbird is likely to churn, or 0 if the user is likely to stay on the platform.\\nWe might have the following inputs:\\n• How many posts the bird has clicked through in the past month (we’ll\\ncall this bird_posts in our input data)\\n• The geographical location of the bird from the browser headers\\n(bird_geo)\\n• How many posts the bird has liked over the past month (bird_likes)'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 21, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='call this bird_posts in our input data)\\n• The geographical location of the bird from the browser headers\\n(bird_geo)\\n• How many posts the bird has liked over the past month (bird_likes)\\n13An extremely common business problem to solve in almost every industry where either\\ncustomer population or subscription based on revenues is important\\n22'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 22, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Table 2: Tabular Input Data for Flutter Users\\nbird_id\\nbird_posts\\nbird_geo\\nbird_likes\\n012\\n2\\nUS\\n5\\n013\\n0\\nUK\\n4\\n056\\n57\\nNZ\\n70\\n612\\n0\\nUK\\n120\\nWe start by selecting our model features and arranging them in tabular\\nformat. We can formulate this data as a table (which, if we look closely, is also\\na matrix) based on rows of the bird id and our bird features.\\nTabular data is any structured data. For example, for a given Flutter user\\nwe have their user id, how many posts they’ve liked, how old the account\\nis, and so on. This approach works well for what we consider traditional\\nmachine learning approaches which deal with tabular data. As a general rule,\\nthe creation of the correct formulation of input data is perhaps the heart of\\nmachine learning. I.e. if we have bad input, we will get bad output. So in\\nall cases, we want to spend our time putting together our input dataset and\\nengineering features very carefully.\\nThese are all discrete features that we can feed into our model and learn'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 22, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='all cases, we want to spend our time putting together our input dataset and\\nengineering features very carefully.\\nThese are all discrete features that we can feed into our model and learn\\nweights from, and is fairly easy as long as we have numerical features. But,\\nsomething important to note here is that, in our bird interaction data, we have\\nboth numerical and textual features (bird geography). So what do we do with\\nthese textual features? How do we compare \"US\" to \"UK\"?\\nThe process of formatting data correctly to feed into a model is called fea-\\nture engineering. When we have a single continuous, numerical feature, like\\n“the age of the flit in days”, it’s easy to feed these features into a model. But,\\nwhen we have textual data, we need to turn it into numerical representations\\nso that we can compare these representations.\\n2.5\\nNumerical Feature Vectors\\nWithin the context of working with text in machine learning, we represent'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 22, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content=\"so that we can compare these representations.\\n2.5\\nNumerical Feature Vectors\\nWithin the context of working with text in machine learning, we represent\\nfeatures as numerical vectors. We can think of each row in our tabular feature\\ndata as a vector. And a collection of features, or our tabular representation,\\nis a matrix. For example, in the vector for our first user, [012, 2, 'US', 5],\\nwe can see that this particular value is represented by four features. When\\nwe create vectors, we can run mathematical computations over them and use\\nthem as inputs into ML models in the numerical form we require.\\nMathematically, vectors are collections of coordinates that tell us where\\na given point is in space among many dimensions. For example, in two\\ndimensions, we have a point [2, 5], representing bird_posts and bird_likes.\\nIn three dimensions, with three features including the bird id, we would\\nhave a vector\\n\\x02\\n12\\n2\\n5\\n\\x03\\n(7)\\nwhich tells us where that user falls on all three axes.\"),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 22, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='In three dimensions, with three features including the bird id, we would\\nhave a vector\\n\\x02\\n12\\n2\\n5\\n\\x03\\n(7)\\nwhich tells us where that user falls on all three axes.\\nBut how do we represent \"US\" or \"UK\" in this space? Because modern\\nmodels converge by performing operations on matrices [39], we need to\\n23'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 23, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='x\\ny\\nz\\n(.12, 0, 0)\\n(0, .2, 0)\\n(0, 0, .5)\\nFigure 19: Projecting a vector into the 3d space\\nencode geography as some sort of numerical value so that the model can\\ncalculate them as inputs14. So, once we have a combination of vectors, we can\\ncompare it to other points. So in our case, each row of data tells us where to\\nposition each bird in relation to any other given bird based on the combination\\nof features. And that’s really what our numerical features allow us to do.\\n2.6\\nFrom Words to Vectors in Three Easy Pieces\\nIn \"Operating Systems: Three Easy Pieces\", the authors write, \"Like any system\\nbuilt by humans, good ideas accumulated in operating systems over time,\\nas engineers learned what was important in their design.\" [3] Today’s large\\nlanguage models were likewise built on hundreds of foundational ideas over\\nthe course of decades. There are, similarly, several fundamental concepts that\\nmake up the work of transforming words to numerical representations.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 23, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='the course of decades. There are, similarly, several fundamental concepts that\\nmake up the work of transforming words to numerical representations.\\nThese show up over and over again, in every deep learning architecture\\nand every NLP-related task15:\\n• Encoding - We need to represent our non-numerical, multimodal\\ndata as numbers so we can create models out of them. There are\\nmany different ways of doing this.\\n• Vectors - we need a way to store the data we have encoded and\\nhave the ability to perform mathematical functions in an optimized\\nway on them. We store encodings as vectors, usually floating-point\\nrepresentations.\\n• Lookup matrices - Often times, the end-result we are looking for\\nfrom encoding and embedding approaches is to give some approxi-\\nmation about the shape and format of our text, and we need to be\\nable to quickly go from numerical to word representations across\\nlarge chunks of text. So we use lookup tables, also known as hash'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 23, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='mation about the shape and format of our text, and we need to be\\nable to quickly go from numerical to word representations across\\nlarge chunks of text. So we use lookup tables, also known as hash\\n14There are some models, specifically decision trees, where you don’t need to do text encoding\\nbecause the tree learns the categorical variables out of the box, however implementations differ,\\nfor example the two most popular implementations, scikit-learn and XGBoost [1], can’t.\\n15When we talk about tasks in NLP-based machine learning, we mean very specifically, what\\nthe machine learning problem is formulated to do. For example, we have the task of ranking,\\nrecommendation, translation, text summarization, and so on.\\n24'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 24, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='tables, also known as attention, to help us map between the words\\nand the numbers.\\nAs we go through the historical context of embeddings, we’ll build our\\nintuition from encoding to BERT and beyond16. What we’ll find as we go\\nfurther into the document is that the explanations for each concept get succes-\\nsively shorter, because we’ve already done the hard work of understanding\\nthe building blocks at the beginning.\\nFigure 20: Pyramid of fundamental concepts building to BERT\\n3\\nHistorical Encoding Approaches\\nCompressing content into lower dimensions for compact numerical repre-\\nsentations and calculations is not a new idea. For as long as humans have\\nbeen overwhelmed by information, we’ve been trying to synthesize it so that\\nwe can make decisions based on it. Early approaches have included one-hot\\nencoding, TF-IDF, bag-of-words, LSA, and LDA.\\nThe earlier approaches were count-based methods. They focused on count-\\ning how many times a word appeared relative to other words and generating'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 24, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='encoding, TF-IDF, bag-of-words, LSA, and LDA.\\nThe earlier approaches were count-based methods. They focused on count-\\ning how many times a word appeared relative to other words and generating\\nencodings based on that. LDA and LSA can be considered statistical ap-\\nproaches, but they are still concerned with inferring the properties of a dataset\\nthrough heuristics rather than modeling. Prediction-based approaches came\\nlater and instead learned the properties of a given text through models such\\nas support vector machines, Word2Vec, BERT, and the GPT series of models,\\nall of which use learned embeddings instead.\\n16Original diagram from this excellent guide on BERT\\n25'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 25, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Embedding Methods\\nCount-based Methods\\nTF-IDF\\nOne-Hot Encoding\\nBag-of-words\\nLSA\\nLDA\\nPrediction-based Methods\\nSVM\\nWord2Vec\\nBERT family\\nGPT family\\nFigure 21: Embedding Method Solution Space\\nA Note on the Code In looking at these approaches programmatically,\\nwe’ll start by using scikit-learn, the de-facto standard machine learning\\nlibrary for smaller datasets, with some implementations in native Python\\nfor clarity in understanding functionality that scikit-learn wraps. As we\\nmove into deep learning, we’ll move to PyTorch, a deep learning library\\nthat’s quickly becoming industry-standard for deep learning implemen-\\ntation. There are many different ways of implementing the concepts we\\ndiscuss here, these are just the easiest to illustrate using Python’s ML\\nlingua franca libraries.\\n3.1\\nEarly Approaches\\nThe first approaches to generating textual features were count-based, relying\\non simple counts or high-level understanding of statistical properties: they'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 25, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='3.1\\nEarly Approaches\\nThe first approaches to generating textual features were count-based, relying\\non simple counts or high-level understanding of statistical properties: they\\nwere descriptive instead of models, which are predictive and attempt to guess\\na value based on a set of input values. The first methods were encoding\\nmethods, a precursor to embedding. Encoding is often a process that still\\nhappens as the first stage of data preparation for input into more complex\\nmodeling approaches. There are several methods to create text features using\\na process known as encoding so that we can map the geography feature into\\nthe vector space:\\n• Ordinal encoding\\n• Indicator encoding\\n• One-Hot encoding\\nIn all these cases, what we are doing is creating a new feature that maps\\nto the text feature column but is a numerical representation of the variable so\\nthat we can project it into that space for modeling purposes. We’ll motivate'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 25, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='to the text feature column but is a numerical representation of the variable so\\nthat we can project it into that space for modeling purposes. We’ll motivate\\nthese examples with simple code snippets from scikit-learn, the most common\\nlibrary for demonstrating basic ML concepts. We’ll start with count-based\\napproaches.\\n3.2\\nEncoding\\nOrdinal encoding Let’s again come back to our dataset of flits. We encode our\\ndata using sequential numbers. For example, \"1\" is \"finch\", \"2\" is \"bluejay\" and\\nso on. We can use this method only if the variables have a natural ordered\\nrelationship to each other. For example, in this case \"bluejay\" is not \"more\"\\n26'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 26, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='than \"finch\" and so would be incorrectly represented in our model. The case is\\nthe same, if, in our flit data, we encode \"US\" as 1 and \"UK\" as 2.\\nTable 3: Bird Geographical Location Encoding\\nbird_id\\nbird_posts\\nbird_geo\\nbird_likes\\nenc_bird_geo\\n012\\n2\\nUS\\n5\\n2\\n013\\n0\\nUK\\n4\\n1\\n056\\n57\\nNZ\\n70\\n0\\n612\\n0\\nUK\\n120\\n1\\n1\\nfrom sklearn.preprocessing import OrdinalEncoder\\n2\\n3\\ndata = [[\\'US\\'], [\\'UK\\'], [\\'NZ\\']]\\n4\\n>>> print(data)\\n5\\n[[\\'US\\']\\n6\\n[\\'UK\\']\\n7\\n[\\'NZ\\']]\\n8\\n9\\n# our label features\\n10\\nencoder = OrdinalEncoder()\\n11\\nresult = encoder.fit_transform(data)\\n12\\n>>> print(result)\\n13\\n[[2.]\\n14\\n[1.]\\n15\\n[0.]]\\nFigure 22: Ordinal Encoding in Scikit-Learn source\\n3.2.1\\nIndicator and one-hot encoding\\nIndicator encoding, given n categories (i.e. \"US\", \"UK\", and \"NZ\"), encodes\\nthe variables into n −1 categories, creating a new feature for each category.\\nSo, if we have three variables, indicator encoding encodes into two indicator\\nvariables. Why would we do this? If the categories are mutually exclusive,'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 26, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='So, if we have three variables, indicator encoding encodes into two indicator\\nvariables. Why would we do this? If the categories are mutually exclusive,\\nas they usually are in point-in-time geolocation estimates, if someone is in\\nthe US, we know for sure they’re not in the UK and not in NZ, so it reduces\\ncomputational overhead.\\nIf we instead use all the variables and they are very closely correlated,\\nthere is a chance we’ll fall into something known as the indicator variable\\ntrap. We can predict one variable from the others, which means we no longer\\nhave feature independence. This generally isn’t a risk for geolocation since\\nthere are more than 2 or 3 and if you’re not in the US, it’s not guaranteed that\\nyou’re in the UK. So, if we have US = 1, UK = 2, and NZ = 3, and prefer more\\ncompact representations, we can use indicator encoding. However, many\\nmodern ML approaches don’t require linear feature independence and use L1'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 26, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='compact representations, we can use indicator encoding. However, many\\nmodern ML approaches don’t require linear feature independence and use L1\\nregularization17 to prune feature inputs that don’t minimize the error, and as\\n17Regularization is a way to prevent our model from overfitting. Overfitting means our\\n27'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 27, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content=\"such only use one-hot encoding.\\nOne-hot encoding is the most commonly-used of the count-based methods.\\nThis process creates a new variable for each feature that we have. Everywhere\\nthe element is present in the sentence, we place a “1” in the vector. We are\\ncreating a mapping of all the elements in the feature space, where 0 indicates a\\nnon-match and 1 indicates a match, and comparing how similar those vectors\\nare.\\n1\\nfrom sklearn.preprocessing import OneHotEncoder\\n2\\nimport numpy as np\\n3\\n4\\nenc = OneHotEncoder(handle_unknown='ignore')\\n5\\ndata = np.asarray([['US'], ['UK'], ['NZ']])\\n6\\nenc.fit(data)\\n7\\nenc.categories_\\n8\\n>>> [array(['NZ', 'UK', 'US'], dtype='<U2')]\\n9\\nonehotlabels = enc.transform(data).toarray()\\n10\\nonehotlabels\\n11\\n>>>\\n12\\narray([[0., 0., 1.],\\n13\\n[0., 1., 0.],\\n14\\n[1., 0., 0.]])\\nFigure 23: One-Hot Encoding in scikit-learnsource\\nTable 4: Our one-hot encoded data with labels\\nbird_id\\nUS\\nUK\\nNZ\\n012\\n1\\n0\\n0\\n013\\n0\\n1\\n0\\n056\\n0\\n0\\n1\"),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 27, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='array([[0., 0., 1.],\\n13\\n[0., 1., 0.],\\n14\\n[1., 0., 0.]])\\nFigure 23: One-Hot Encoding in scikit-learnsource\\nTable 4: Our one-hot encoded data with labels\\nbird_id\\nUS\\nUK\\nNZ\\n012\\n1\\n0\\n0\\n013\\n0\\n1\\n0\\n056\\n0\\n0\\n1\\nNow that we’ve encoded our textual features as vectors, we can feed them\\ninto the model we’re developing to predict churn. The function we’ve been\\nlearning will minimize the loss of the model, or the distance between the\\nmodel’s prediction and the actual value, by predicting correct parameters for\\neach of these features. The learned model will then return a value from 1\\nto 0 that is a probability that the event, either churn or no-churn, has taken\\nplace, given the input features of our particular bird. Since this is a supervised\\nmodel, we then evaluate this model for accuracy by feeding our test data\\ninto the model and comparing the model’s prediction against the actual data,\\nwhich tells us whether the bird has churned or not.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 27, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='into the model and comparing the model’s prediction against the actual data,\\nwhich tells us whether the bird has churned or not.\\nWhat we’ve built is a standard logistic regression model. Generally these\\ndays the machine learning community has converged on using gradient-\\nboosted decision tree methods for dealing with tabular data, but we’ll see\\nmodel can exactly predict outcomes based on the training data, but it can’t learn new inputs\\nthat we show it, which means it can’t generalize\\n28'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 28, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='that neural networks build on simple linear and logistic regression models to\\ngenerate their output, so it’s a good starting point.\\nEmbeddings as larger feature inputs\\nOnce we have encoded our feature data, we can use this input for any type\\nof model that accepts tabular features. In our machine learning task, we\\nwere looking for output that indicated whether a bird was likely to leave the\\nplatform based on their location and some usage data. Now, we’d like to focus\\nspecifically on surfacing flits that are similar to other flits the user has already\\ninteracted with so we’ll need feature representations of either/or our users or\\nour content.\\nLet’s go back to the original business question we posed at the beginning\\nof this document: how do we recommend interesting new content for Flutter\\nusers given that we know that past content they consumed (i.e. liked and\\nshared)?\\nIn the traditional collaborative filtering approach to recommendations,'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 28, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='users given that we know that past content they consumed (i.e. liked and\\nshared)?\\nIn the traditional collaborative filtering approach to recommendations,\\nwe start by constructing a user-item matrix based on our input data that, when\\nfactored, gives us the latent properties of each flit and allows us to recommend\\nsimilar ones.\\nIn our case, we have Flutter users who might have liked a given flit. What\\nother flits would we recommend given the textual properties of that one?\\nHere’s an example. We have a flit that our bird users liked.\\n\"Hold fast to dreams, for if dreams die, life is a broken-winged bird that\\ncannot fly.\"\\nWe also have other flits we may or may not want to surface in our bird’s\\nfeed.\\n\"No bird soars too high if he soars with his own wings.\"\\n“A bird does not sing because it has an answer, it sings because it has a\\nsong.”\\nHow would we turn this into a machine learning problem that takes\\nfeatures as input and a prediction as an output, knowing what we know about'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 28, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='song.”\\nHow would we turn this into a machine learning problem that takes\\nfeatures as input and a prediction as an output, knowing what we know about\\nhow to do this already? First, in order to build this matrix, we need to turn\\neach word into a feature that’s a column value and each user remains a row\\nvalue.\\nThe best way to think of the difference between tabular and free-form\\nrepresentations as model inputs is that a row of tabular data looks like\\nthis, [012,2,\"US\", 5], and a \"row\" or document of text data looks like this,\\n[\"No bird soars too high if he soars with his own wings.\"] In both\\ncases, each of these are vectors, or a list of values that represents a single bird.\\n29'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 29, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='In traditional machine learning, rows are our user data about a single bird\\nand columns are features about the bird. In recommendation systems, our\\nrows are the individual data about each user, and our column data represents\\nthe given data about each flit. If we can factor this matrix, that is decompose it\\ninto two matrices (Q and PT) that, when multiplied, the product is our original\\nmatrix (R), we can learn the \"latent factors\" or features that allow us to group\\nsimilar users and items together to recommend them.\\nAnother way to think about this is that in traditional ML, we have to\\nactively engineer features, but they are then available to us as matrices. In\\ntext and deep-learning approaches, we don’t need to do feature engineering,\\nbut need to perform the extra step of generating valuable numeric features\\nanyway.\\n1\\n3\\n5\\n5\\n4\\n5 4\\n4\\n2 1 3\\n2 4\\n1 2\\n3\\n4 3 5\\n2 4\\n5\\n4\\n2\\n4 3 4 2\\n2 5\\n1\\n3\\n3\\n2\\n4\\nR\\nusers\\nwords\\n≈\\nusers\\nlatent factors\\nQ\\n×\\nlatent factors\\nwords\\nPT'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 29, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='anyway.\\n1\\n3\\n5\\n5\\n4\\n5 4\\n4\\n2 1 3\\n2 4\\n1 2\\n3\\n4 3 5\\n2 4\\n5\\n4\\n2\\n4 3 4 2\\n2 5\\n1\\n3\\n3\\n2\\n4\\nR\\nusers\\nwords\\n≈\\nusers\\nlatent factors\\nQ\\n×\\nlatent factors\\nwords\\nPT\\nThe factorization of our feature matrix into these two matrices, where the\\nrows in Q are actually embeddings [43] for users and the rows in matrix P\\nare embeddings for flits, allows us to fill in values for flits that Flutter users\\nhave not explicitly liked, and then perform a search across the matrix to find\\nother words they might be interested in. The end-result is our generated\\nrecommendation candidates, which we then filter downstream and surface to\\nthe user because the core of the recommendation problem is to recommend\\nitems to the user.\\nIn this base-case scenario, each column could be a single word in the entire\\nvocabulary of every flit we have and the vector we create, shown in the matrix\\nfrequency table, would be an insanely large, sparse vector that has a 0 of\\noccurrence of words in our vocabulary. The way we can build toward this'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 29, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='frequency table, would be an insanely large, sparse vector that has a 0 of\\noccurrence of words in our vocabulary. The way we can build toward this\\nrepresentation is to start with a structure known as a bag of words, or simply\\nthe frequency of appearance of text in a given document (in our case, each flit\\nis a document.) This matrix is the input data structure for many of the early\\napproaches to embedding.\\nIn scikit-learn, we can create an initial matrix of our inputs across docu-\\nments using ‘CountVectorizer‘.\\n30'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 30, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nfrom sklearn.feature_extraction.text import CountVectorizer\\n2\\nimport pandas as pd\\n3\\n4\\nvect = CountVectorizer(binary=True)\\n5\\nvects = vect.fit_transform(flits)\\n6\\n7\\nresponses = [\"Hold fast to dreams, for if dreams die, life is a broken-winged\\nbird that cannot fly.\", \"No bird soars too high if he soars with his own\\nwings.\", \"A bird does not sing because it has an answer, it sings because\\nit has a song.\"]\\n,→\\n,→\\n,→\\n8\\n9\\ndoc = pd.DataFrame(list(zip(responses)))\\n10\\n11\\ntd = pd.DataFrame(vects.todense()).iloc[:5]\\n12\\ntd.columns = vect.get_feature_names_out()\\n13\\nterm_document_matrix = td.T\\n14\\nterm_document_matrix.columns = [\\'flit \\'+str(i) for i in range(1, 4)]\\n15\\nterm_document_matrix[\\'total_count\\'] = term_document_matrix.sum(axis=1)\\n16\\n17\\nprint(term_document_matrix.drop(columns=[\\'total_count\\']).head(10))\\n18\\n19\\nflit_1\\nflit_2\\nflit_3\\n20\\nan\\n0\\n0\\n1\\n21\\nanswer\\n0\\n0\\n1\\n22\\nbecause\\n0\\n0\\n1\\n23\\nbird\\n1\\n1\\n1\\n24\\nbroken\\n1\\n0\\n0\\n25\\ncannot\\n1\\n0\\n0\\n26\\ndie\\n1\\n0\\n0\\n27\\ndoes\\n0\\n0\\n1\\n28\\ndreams\\n1\\n0\\n0\\n29\\nfast\\n1\\n0\\n0\\n30\\n31'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 30, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='18\\n19\\nflit_1\\nflit_2\\nflit_3\\n20\\nan\\n0\\n0\\n1\\n21\\nanswer\\n0\\n0\\n1\\n22\\nbecause\\n0\\n0\\n1\\n23\\nbird\\n1\\n1\\n1\\n24\\nbroken\\n1\\n0\\n0\\n25\\ncannot\\n1\\n0\\n0\\n26\\ndie\\n1\\n0\\n0\\n27\\ndoes\\n0\\n0\\n1\\n28\\ndreams\\n1\\n0\\n0\\n29\\nfast\\n1\\n0\\n0\\n30\\n31\\nFigure 24: Creating a matrix frequency table to create a user-item matrix source\\n3.2.2\\nTF-IDF\\nOne-hot encoding just deals with presence and absence of a single term in\\na single document. However, when we have large amounts of data, we’d\\nlike to consider the weights of each term in relation to all the other terms in a\\ncollection of documents.\\nTo address the limitations of one-hot encoding, TF-IDF, or term frequency-\\ninverse document frequency was developed. TF-IDF was introduced in the\\n1970s18 as a way to create a vector representation of a document by averaging\\nall the document’s word weights. It worked really well for a long time and\\n18By Karen Spärck Jones, whose paper, \"Synonymy and semantic classification\" is fundamen-\\ntal to the field of NLP\\n31'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 31, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='still does in many cases. For example, one of the most-used search functions,\\nBM25, uses TF-IDF as a baseline [56] as a default search strategy in Elastic-\\nsearch/Opensearch 19. It extends TF-IDF to develop a probability associated\\nwith the probability of relevance for each pair of words in a document and it\\nis still being applied in neural search today [65].\\nTF-IDF will tell you how important a single word is in a corpus by assign-\\ning it a weight and, at the same time, down-weight common words like, \"a\",\\n\"and\", and \"the\". This calculated weight gives us a feature for a single word\\nTF-IDF, and also the relevance of the features across the vocabulary.\\nWe take all of our input data that’s structured in sentences and break it up\\ninto individual words, and perform counts on its values, generating the bag\\nof words. TF is term frequency, or the number of times a term appears in a\\ndocument relative to the other terms in the document.\\ntf(t, d) =\\nft,d\\n∑t′∈d ft′,d\\n(8)'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 31, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='of words. TF is term frequency, or the number of times a term appears in a\\ndocument relative to the other terms in the document.\\ntf(t, d) =\\nft,d\\n∑t′∈d ft′,d\\n(8)\\nAnd IDF is the inverse frequency of the term across all documents in our\\nvocabulary.\\nidf(t, D) = log\\nN\\n|{d ∈D : t ∈d}|\\n(9)\\nLet’s take a look at how to implement it from scratch:\\n19You can read about how Elasticsearch implements BM25 here\\n32'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 32, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\n2\\nimport math\\n3\\n4\\n# Process documents into individual words\\n5\\ndocumentA\\n= [\\'Hold\\',\\'fast\\',\\'to\\',\\'dreams\\',\\'for\\',\\'if\\',\\'dreams\\',\\'die,\\'\\n,\\'life\\',\\'is\\',\\'a\\',\\'broken-winged\\',\\'bird\\',\\'that\\',\\'cannot\\',\\'fly\\']\\n,→\\n6\\ndocumentB =\\n[\\'No\\',\\'bird\\',\\'soars\\',\\'too\\',\\'high\\',\\'if\\',\\n\\'he\\',\\'soars\\',\\'with\\',\\'his\\',\\'own\\',\\'wings\\']\\n,→\\n7\\n8\\ndef tf(doc_dict: dict, doc_elements: list[str]) -> dict:\\n9\\n\"\"\"Term frequency of a word in a document\\nover total words in\\ndocument\"\"\"\\n,→\\n10\\ntf_dict = {}\\n11\\ncorpus_count = len(doc_elements)\\n12\\nfor word, count in doc_dict.items():\\n13\\ntf_dict[word] = count / float(corpus_count)\\n14\\nreturn tf_dict\\n15\\n16\\ndef idf(doc_list: list[str]) -> dict:\\n17\\n\"\"\"The number of documents in which the term appears per term\"\"\"\\n18\\nidf_dict = {}\\n19\\nN = len(doc_list)\\n20\\nidf_dict = dict.fromkeys(doc_list[0].keys(), 0)\\n21\\nfor word, val in idf_dict.items():\\n22\\nidf_dict[word] = math.log10(N / (float(val) + 1))\\n23\\nreturn idf_dict\\n24\\n25\\n# inverse document frequencies for all words\\n26'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 32, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='21\\nfor word, val in idf_dict.items():\\n22\\nidf_dict[word] = math.log10(N / (float(val) + 1))\\n23\\nreturn idf_dict\\n24\\n25\\n# inverse document frequencies for all words\\n26\\n# dicts are frequency counts of words per doc e.g. dict.fromkeys(corpus, 0)\\n27\\nidfs = idf([dict_a, dict_b])\\n28\\n29\\ndef tfidf(doc_elements: list[str], idfs)-> dict:\\n30\\n\"\"\"TF * IDF per word given a word and number of docs the term appears\\nin\"\"\"\\n,→\\n31\\ntfidf_dict = {}\\n32\\nfor word, val in doc_elements.items():\\n33\\ntfidf_dict[word] = val * idfs[word]\\n34\\nreturn tfidf_dict\\n35\\n36\\n# Calculate the term frequency for each document individually\\n37\\ntf_a = tf(dict_a, document_a)\\n38\\ntf_b = tf(dict_b, document_b)\\n39\\n40\\n# Calculate the inverse document frequency given each term frequency\\n41\\ntfidf_a = tfidf(tf_a, idfs)\\n42\\ntfidf_b = tfidf(tf_b, idfs)\\n43\\n44\\n# Return weight of each word in each document wrt to the total corpus\\n45\\ndocument_tfidf = pd.DataFrame([tfidf_a, tfidf_b])\\n46\\ndocument_tfidf.T\\n47\\n#\\ndoc 0\\ndoc 1\\n48\\na\\n0.018814\\n0.000000\\n49\\ndreams'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 32, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='43\\n44\\n# Return weight of each word in each document wrt to the total corpus\\n45\\ndocument_tfidf = pd.DataFrame([tfidf_a, tfidf_b])\\n46\\ndocument_tfidf.T\\n47\\n#\\ndoc 0\\ndoc 1\\n48\\na\\n0.018814\\n0.000000\\n49\\ndreams\\n0.037629\\n0.000000\\n50\\nNo\\n0.000000\\n0.025086\\nFigure 25: Truncated implementation of TF-IDF, see full source\\n33'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 33, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Once we understand the underlying fundamental concept, we can use the\\nscikit-learn implementation which does the same thing, and also surfaces the\\nTF-IDF of each word in the vocabulary.\\n1\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n2\\nimport pandas as pd\\n3\\n4\\ncorpus = [\\n5\\n\"Hold fast to dreams, for if dreams die, life is a broken-winged bird\\nthat cannot fly.\",\\n,→\\n6\\n\"No bird soars too high if he soars with his own wings.\",\\n7\\n]\\n8\\n9\\n# langston hughes and william blake\\n10\\ntext_titles = [\"quote_lh\", \"quote_wb\"]\\n11\\n12\\nvectorizer = TfidfVectorizer()\\n13\\nvector = vectorizer.fit_transform(corpus)\\n14\\ndict(zip(vectorizer.get_feature_names_out(), vector.toarray()[0]))\\n15\\n16\\ntfidf_df = pd.DataFrame(vector.toarray(), index=text_titles,\\ncolumns=vectorizer.get_feature_names_out())\\n,→\\n17\\n18\\ntfidf_df.loc[\\'doc_freq\\'] = (tfidf_df > 0).sum()\\n19\\ntfidf_df.T\\n20\\n21\\n# How common or unique a word is in a given document wrt to the vocabulary\\n22\\nquote_lh\\nquote_wb\\ndoc_freq\\n23\\nbird\\n0.172503\\n0.197242\\n2.0'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 33, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='19\\ntfidf_df.T\\n20\\n21\\n# How common or unique a word is in a given document wrt to the vocabulary\\n22\\nquote_lh\\nquote_wb\\ndoc_freq\\n23\\nbird\\n0.172503\\n0.197242\\n2.0\\n24\\nbroken\\n0.242447\\n0.000000\\n1.0\\n25\\ncannot\\n0.242447\\n0.000000\\n1.0\\n26\\ndie\\n0.242447\\n0.000000\\n1.0\\nFigure 26: Implementation of TF-IDF in scikit-learn source\\nGiven that inverse document frequency is a measure of whether the word\\nis common or not across the documents, we can see that \"dreams\" is important\\nbecause they are rare across the documents and therefore interesting to us\\nmore so than \"bird.\" We see that the tf-idf for a given word, \"dreams\", is slightly\\ndifferent for each of these implementations, and that’s because Scikit-learn\\nnormalizes the denominator and uses a slightly different formula. You’ll also\\nnote that in the first implementation we separate the corpus words ourselves,\\ndon’t remove any stop words, and don’t lowercase everything. Many of these\\nsteps are done automatically in scikit-learn or can be set as parameters into'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 33, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='don’t remove any stop words, and don’t lowercase everything. Many of these\\nsteps are done automatically in scikit-learn or can be set as parameters into\\nthe processing pipeline. We’ll see later that these are critical NLP steps that\\nwe perform each time we work with text.\\nTF-IDF enforces several important ordering rules on our text corpus:\\n• Uprank term frequency when it occurs many times in a small number of\\ndocuments\\n34'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 34, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• Downrank term frequency when it occurs many times in many docu-\\nments, aka is not relevant\\n• Really downrank the term when it appears across your entire document\\nbase [56].\\nThere are numerous ways to calculate and create weights for individual\\nwords in TF-IDF. In each case, we calculate a score for each word that tells\\nus how important that word is in relation to each other word in our corpus,\\nwhich gives it a weight. Once we figure out how common each word is in\\nthe set of all possible flits and get a weighted score for the entire sentence in\\nrelation to other sentences.\\nGenerally, when we work with textual representations, we’re trying to\\nunderstand which words, phrases, or concepts are similar to each other. Within\\nour specific recommendations task, we are trying to understand which pieces\\nof content are similar to each other, so that we can recommend content that\\nusers will like based on either their item history or the user history of users\\nsimilar to them.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 34, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='of content are similar to each other, so that we can recommend content that\\nusers will like based on either their item history or the user history of users\\nsimilar to them.\\nSo, when we perform embedding in the context of recommender systems,\\nwe are looking to create neighborhoods from items and users, based on the\\nactivity of those users on our platform. This is the initial solution to the\\nproblem of “how do we recommend flits that are similar to flit that the user\\nhas liked.” This is the process of collaborative filtering.\\nThere are many approaches to collaborative filtering including a\\nneighborhood-based approach, which looks at weighted averages of user\\nratings and computes cosine similarity, between users. It then finds groups,\\nor neighborhoods of users which are similar to each other.\\nA key problem that makes up the fundamental problem in collaborative\\nfiltering and in recommendation systems in general is the ability to find similar'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 34, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='A key problem that makes up the fundamental problem in collaborative\\nfiltering and in recommendation systems in general is the ability to find similar\\nsets of items among very large collections [42].\\nMathematically, we can do this by looking at the distance metric between\\nany two given sets of items, and there are a number of different approaches,\\nincluding Euclidean distance, edit distance (more specifically, Levenshtein\\ndistance and Hamming distance), cosine distance, and more advanced com-\\npression approaches like minhashing.\\nThe most commonly used approach in most models where we’re trying\\nto ascertain the semantic closeness of two items is cosine similarity, which is\\nthe cosine of the angle between two objects represented as vectors, bounded\\nbetween -1 and 1. -1 means the two items are completely \"opposite\" of each\\nother and 1 means they are completely the same item, assuming unit length.\\nZero means that you should probably use a distance measure other than cosine'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 34, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='other and 1 means they are completely the same item, assuming unit length.\\nZero means that you should probably use a distance measure other than cosine\\nsimilarity because the vectors are completely orthogonal to each other. One\\npoint of clarification here is that cosine distance is the actual distance measure\\nand is calculated as 1 −similarity(⃗a,⃗b).\\nsimilarity(⃗a,⃗b) = ⃗a ·⃗b\\n|⃗a||⃗b|\\n=\\nn\\n∑\\ni=1\\naibi\\ns\\nn\\n∑\\ni=1\\na2\\ni\\ns\\nn\\n∑\\ni=1\\nb2\\ni\\n(10)\\n35'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 35, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='We use cosine similarity over other measures like Euclidean distance for\\nlarge text corpuses, for example, because in very large, sparse spaces, the\\ndirection of the vectors is just as, and even more important, than the actual\\nvalues.\\nThe higher the cosine similarity is for two words or documents, the better.\\nWe can use TF-IDF as a way to look at cosine similarity. Once we’ve given\\neach of our words a tf-idf score, we can also assign a vector to each word in\\nour sentence, and create a vector out of each quote to assess how similar they\\nare.\\nx\\ny\\nbird\\nwings\\nθ\\nθ\\nϕ\\nFigure 27: Illustration of cosine similarity between bird and wings vectors.\\nLet’s take a look at the actual equation for cosine similarity. We start with\\nthe dot product between two vectors, which is just the sum of each value\\nmultiplied by the corresponding value in our second vector, and then we\\ndivide by the normalized dot product.\\n1\\nv1 = [0,3,4,5,6]\\n2\\nv2 = [4,5,6,7,8]\\n3\\n4\\ndef dot(v1, v2):\\n5'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 35, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content=\"multiplied by the corresponding value in our second vector, and then we\\ndivide by the normalized dot product.\\n1\\nv1 = [0,3,4,5,6]\\n2\\nv2 = [4,5,6,7,8]\\n3\\n4\\ndef dot(v1, v2):\\n5\\ndot_product = sum((a * b) for a,b in zip(v1,v2))\\n6\\nreturn dot_product\\n7\\n8\\ndef cosine_similarity(v1, v2):\\n9\\n'''\\n10\\n(v1 dot v2)/||v1|| *||v2||)\\n11\\n'''\\n12\\nproducts = dot(v1,v2)\\n13\\ndenominator = ( (dot(v1,v1) **.5) * (dot(v2,v2) ** .5) )\\n14\\nsimilarity = products / denominator\\n15\\nreturn similarity\\n16\\n17\\nprint(cosine_similarity(v1, v2))\\n18\\n# 0.9544074144996451\\nFigure 28: Implementation of cosine similarity from scratch source\\nOr, once again, in scikit-learn, as a pairwise metric:\\n36\"),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 36, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nfrom sklearn.metrics import pairwise\\n2\\n3\\nv1 = [0,3,4,5,6]\\n4\\nv2 = [4,5,6,7,8]\\n5\\n6\\n# need to be in numpy data format\\n7\\npairwise.cosine_similarity([v1],[v2])\\n8\\n# array([[0.95440741]])\\n9\\nFigure 29: Implementation of cosine similarity in scikitsource\\nOther commonly-used distance measures in semantic similarity and rec-\\nommendations include:\\n• Euclidean distance - calculates the straight-line distance between two\\npoints\\n• Manhattan Distance - Measures the distance between two points by\\nsumming the absolute differences of their coordinates\\n• Jaccard Distance - Computes the dissimilarity between two sets by\\ndividing the size of their intersection by the size of their union.\\n• Hamming Distance - Measures the dissimilarity between two strings\\nby counting the positions in which they differ\\n3.2.3\\nSVD and PCA\\nThere is a problem with the vectors we created in one-hot encoding and TF-\\nIDF: they are sparse. A sparse vector is one that is mostly populated by zeroes.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 36, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='3.2.3\\nSVD and PCA\\nThere is a problem with the vectors we created in one-hot encoding and TF-\\nIDF: they are sparse. A sparse vector is one that is mostly populated by zeroes.\\nThey are sparse because most sentences don’t contain all the same words as\\nother sentences. For example, in our flit, we might encounter the word \"bird\"\\nin two sentences simultaneously, but the rest of the words will be completely\\ndifferent.\\n1\\nsparse_vector = [1,0,0,0,0,0,0,0,0,0]\\n2\\ndense_vector = [1,2,2,3,0,4,5,8,8,5]\\nFigure 30: Two types of vectors in text processing\\nSparse vectors result in a number of problems, among these cold start—the\\nidea that we don’t know to recommend items that haven’t been interacted with,\\nor for users who are new. What we’d like, instead, is to create dense vectors,\\nwhich will give us more information about the data, the most important of\\nwhich is accounting for the weight of a given word in proportion to other\\nwords. This is where we leave one-hot encodings and TD-IDF to move into'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 36, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='which is accounting for the weight of a given word in proportion to other\\nwords. This is where we leave one-hot encodings and TD-IDF to move into\\napproaches that are meant to solve for this sparsity. Dense vectors are just\\nvectors that have mostly non-zero values. We call these dense representations\\ndynamic representations [68].\\n37'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 37, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Several other related early approaches were used in lieu of TF-IDF for\\ncreating compact representations of items: principal components analysis\\n(PCA) and singular value decomposition (SVD).\\nSVD and PCA are both dimensionality reduction techniques that, applied\\nthrough matrix transformations to our original text input data, show us the\\nlatent relationship between two items by breaking items down into latent\\ncomponents through matrix transformations.\\nSVD is a type of matrix factorization that represents a given input feature\\nmatrix as the product of three matrices. It then uses the component matrices\\nto create linear combinations of features that are the largest differences from\\neach other and which are directionally different based on the variance of the\\nclusters of points from a given line. Those clusters represent the “feature\\nclusters” of the compressed features.\\nIn the process of performing SVD and decomposing these matrices, we'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 37, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='clusters of points from a given line. Those clusters represent the “feature\\nclusters” of the compressed features.\\nIn the process of performing SVD and decomposing these matrices, we\\ngenerate a matrix representation that includes the eigenvectors and eigenvalue\\npairs or the sample covariance pairs.\\nPCA uses the same initial input feature matrix, but whereas one-hot en-\\ncoding simply converts the text features into numerical features that we can\\nwork with, PCA also performs compression and projects our items into a\\ntwo-dimensional feature space. The first principal component is the scaled\\neigenvector of the data, the weights of the variables that describe your data\\nbest, and the second is the weights of the next set of variables that describe\\nyour data best.\\nThe resulting model is a projection of all the words, clustered into a single\\nspace based on these dimensions. While we can’t get individual meanings\\nof all these components, it’s clear that the clusters of words, aka features, are'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 37, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='space based on these dimensions. While we can’t get individual meanings\\nof all these components, it’s clear that the clusters of words, aka features, are\\nsemantically similar, that is they are close to each other in meaning20.\\nThe difference between the two is often confusing (people admitted as\\nmuch in the 80s [21] when these approaches were still being worked out),\\nand for the purposes of this survey paper we’ll say that PCA can often be\\nimplemented using SVD 21.\\n3.3\\nLDA and LSA\\nBecause PCA performs computation on each combination of features to gen-\\nerate the two dimensions, it becomes immensely computationally expensive\\nas the number of features grows. Many of these early methods, like PCA,\\nworked well for smaller datasets, like many of the ones used in traditional\\nNLP research, but as datasets continued to grow, they didn’t quite scale.\\nOther approaches grew out of TF-IDF and PCA to address their limitations,'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 37, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='NLP research, but as datasets continued to grow, they didn’t quite scale.\\nOther approaches grew out of TF-IDF and PCA to address their limitations,\\nincluding latent semantic analysis (LSA) and latent Dirichlet allocation\\n(LDA) [12]. Both of these approaches start with the input document matrix\\nthat we built in the last section. The underlying principle behind both of\\n20There are many definitions of semantic similarity - what does it mean for \"king\" and\\n\"queen\" to be close to each other? - but a high-level approach involves using original sources\\nlike thesauri and dictionaries to create a structured knowledge base and offer a structured\\nrepresentation of terms and concepts based on nodes and edges, aka how often they appear\\nnear each other. [6]\\n21This is how it’s implemented in the scikit-learn package\\n38'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 38, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='these models is that words that occur close together more frequently have\\nmore important relationships. LSA uses the same word weighting that we\\nused for TF-IDF and looks to combine that matrix into a lower rank matrix,\\na cosine similarity matrix. In the matrix, the values for the cells range from\\n[-1,1], where -1 represents documents that are complete opposites and 1 means\\nthe documents are identical. LSA then runs over the matrix and groups items\\ntogether.\\nLDA takes a slightly different approach. Although it uses the same matrix\\nfor input, it instead outputs a matrix where the rows are words and columns\\nare documents. The distance measure, instead of cosine similarity, is the\\nnumerical value for the topic that the intersection of the word and document\\nprovide. The assumption is that any sentence we input will contain a collection\\nof topics, based on proportions of representation in relation to the input\\ncorpus, and that there are a number of topics that we can use to classify'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 38, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='of topics, based on proportions of representation in relation to the input\\ncorpus, and that there are a number of topics that we can use to classify\\na given sentence. We initialize the algorithm by assuming that there is a\\nnon-zero probability that each word could appear in a topic. LDA initially\\nassigns words to topics at random, and then iterates until it converges to a\\npoint where it maximizes the probability for assigning a current word to a\\ncurrent topic. In order to do the word-to-topic mapping, LDA generates an\\nembedding that creates a space of clusters of words or sentences that work\\ntogether semantically.\\n3.4\\nLimitations of traditional approaches\\nAll of these traditional methods look to address the problem of generating\\nrelationships between items in our corpus in various ways in the latent space -\\nthe relationships between words that are not explicitly stated but that we can\\ntease out based on how we model the data.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 38, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='the relationships between words that are not explicitly stated but that we can\\ntease out based on how we model the data.\\nHowever, in all these cases, as our corpus starts to grow, we start to run\\ninto two problems: the curse of dimensionality and compute scale.\\n3.4.1\\nThe curse of dimensionality\\nAs we one-hot encode more features, our tabular data set grows. Going\\nback to our churn model, what happens once we have 181 instead of two\\nor three countries? We’ll have to encode each of them into their own vector\\nrepresentations. What happens if we have millions of vocabulary words, for\\nexample thousands of birds posting millions of messages every day? Our\\nsparse matrix for tf-idf becomes computationally intensive to factor.\\nWhereas our input vectors for tabular machine learning and naive text\\napproaches is only three entries because we only use three features, multi-\\nmodal data effectively has a dimensionality of the number of written words'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 38, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='approaches is only three entries because we only use three features, multi-\\nmodal data effectively has a dimensionality of the number of written words\\nin existence and image data has a dimensionality of height times width in\\npixels, for each given image. Video and audio data have similar exponential\\nproperties. We can profile the performance of any code we write using Big\\nO notation, which will classify an algorithm’s runtime. There are programs\\nthat perform worse and those that perform better based on the number of\\nelements the program processes. This means that one-hot encodings, in terms\\nof computing performance, are O(n) in the worst case complexity. So, if our\\n39'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 39, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='text is a corpus of a million unique words, we’ll get to a million columns, or\\nvectors, each of which will be sparse, since most sentences will not contain the\\nwords of other sentences.\\nLet’s take a more concrete case. Even in our simple case of our initial\\nbird quote, we have 28 features, one for each word in the sentence, assuming\\nwe don’t remove and process the most common stop words — extremely\\ncommon words like \"the\", \"who\", and \"is\" that appear in most texts but don’t\\nadd semantic meaning. How can we create a model that has 28 features?\\nThat’s fairly simple if tedious - we encode each word as a numerical value.\\nTable 5: One-hot encoding and the growing curse of dimensionality for our flit\\nflit_id\\nbird_id\\nhold\\nfast\\ndreams\\ndie\\nlife\\nbird\\n9823420\\n012\\n1\\n1\\n1\\n1\\n1\\n1\\n9823421\\n013\\n1\\n0\\n0\\n0\\n0\\n1\\nNot only will it be hard to run computations over a linearly increasing\\nset, once we start generating a large number of features (columns), we start'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 39, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='9823420\\n012\\n1\\n1\\n1\\n1\\n1\\n1\\n9823421\\n013\\n1\\n0\\n0\\n0\\n0\\n1\\nNot only will it be hard to run computations over a linearly increasing\\nset, once we start generating a large number of features (columns), we start\\nrunning into the curse of dimensionality, which means that, the more features\\nwe accumulate, the more data we need in order to accurately statistically\\nconfidently say anything about them, which results in models that may not\\naccurately represent our data [29] if we have extremely sparse features, which\\nis generally the case in user/item interactions in recommendations.\\n3.4.2\\nComputational complexity\\nIn production machine learning systems, the statistical properties of our al-\\ngorithm are important. But just as critical is how quickly our model returns\\ndata, or the system’s efficiency. System efficiency can be measured in many\\nways, and it is critical in any well-performing system to find the performance\\nbottleneck that leads to latency, or the time spent waiting before an operation'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 39, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='ways, and it is critical in any well-performing system to find the performance\\nbottleneck that leads to latency, or the time spent waiting before an operation\\nis performed [26]. If you have a recommendation system in production, you\\ncannot risk showing the user an empty feed or a feed that takes more than\\na few milliseconds to render. If you have a search system, you cannot risk\\nthe results taking more than a few milliseconds to return, particularly in e-\\ncommerce settings [2]. From the holistic systems perspective then, we can also\\nhave latency in how long it takes to generate data for a model, read in data,\\nand train the model.\\nThe two big drivers of latency are:\\n• I/O processing - We can only send as many items over the network as\\nour network speed allows\\n• CPU processing - We can only process as many items as we have memory\\navailable to us in any given system22\\nGenerally, TF-IDF performs well in terms of identifying key terms in the'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 39, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• CPU processing - We can only process as many items as we have memory\\navailable to us in any given system22\\nGenerally, TF-IDF performs well in terms of identifying key terms in the\\ndocument. However, since the algorithm processes all the elements in a\\n22there has been discussion over the past few years on whether IO or CPU are really the\\nbottleneck in any modern data-intensive application.\\n40'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 40, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='given corpus, the time complexity grows for both the numerator and the\\ndenominator in the equation and overall, the time-complexity of computing\\nthe TF-IDF weights for all the terms in all the documents is O(Nd), where N\\nis the total number of terms in the corpus and d is the number of documents\\nin the corpus. Additionally, because TF-IDF creates a matrix as output, what\\nwe end up doing is processing enormous state matrices. For example, if you\\nhave 100k documents and need to store frequency counts and features for the\\ntop five thousand words appearing in those documents, we get a matrix of\\nsize 100000 ∗5000. This complexity only grows.\\nThis linear time complexity growth becomes an issue when we’re trying\\nto process millions or hundreds of millions of tokens – usually a synonym\\nfor words but can also be sub-words such as syllables. This is a problem that\\nbecame especially prevalent as, over time in industry, storage became cheap.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 40, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='for words but can also be sub-words such as syllables. This is a problem that\\nbecame especially prevalent as, over time in industry, storage became cheap.\\nFrom newsgroups to emails, and finally, to public internet text, we began\\nto generate a lot of digital exhaust and companies collected it in the form of\\nappend-only logs [36], a sequence of records ordered by time, that’s configured\\nto continuously append records.23 .\\nCompanies started emitting, keeping, and using these endless log streams\\nfor data analysis and machine learning. All of a sudden, the algorithms that\\nhad worked well on a collection of less than a million documents struggled to\\nkeep up.\\nCapturing log data at scale began the rise of the Big Data era, which\\nresulted in a great deal of variety, velocity, and volume of data movement.\\nThe rise in data volumes coincided with data storage becoming much cheaper,\\nenabling companies to store everything they collected on racks of commodity\\nhardware.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 40, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='The rise in data volumes coincided with data storage becoming much cheaper,\\nenabling companies to store everything they collected on racks of commodity\\nhardware.\\nCompanies were already retaining analytical data needed to run critical\\nbusiness operations in relational databases, but access to that data was struc-\\ntured and processed in batch increments on a daily or weekly basis. This new\\nlogfile data moved quickly, and with a level of variety absent from traditional\\ndatabases.\\nThe resulting corpuses for NLP, search, and recommendation problems\\nalso exploded in size, leading people to look for more performant solutions.\\n3.5\\nSupport Vector Machines\\nThe first modeling approaches were shallow models — models that perform\\nmachine learning tasks using only one layer of weights and biases [9]. Support\\nvector machines (SVM), developed at Bell Laboratories in the mid-1990s,\\nwere used in high-dimensional spaces for NLP tasks like text categorization'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 40, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='vector machines (SVM), developed at Bell Laboratories in the mid-1990s,\\nwere used in high-dimensional spaces for NLP tasks like text categorization\\n[32]. SVMs separate data clusters into points that are linearly separable by a\\nhyperplane, a decision boundary that separates elements into separate classes.\\nIn a two-dimensional vector space, the hyperplane is a line, in a three or more\\ndimensional space, the separator also comes in many dimensions.\\nThe goal of the SVM is to find the optimal hyperplane such that the dis-\\ntance between new projections of objects (words in our case) into the space\\n23Jay Kreps’ canonical posts on how logging works are a must-read\\n41'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 41, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='maximizes the distance between the plane and the elements so there’s less\\nchance of mis-classifying them.\\nw · x + b > 1\\nw · x + b = 0\\nw · x + b < −1\\nMargin\\nFigure 31: Example of points in the vector space in an SVM separated by a hyperplane\\nExamples of supervised machine learning tasks performed with SVMs\\nincluded next word prediction, predicting the missing word in a given se-\\nquence, and predicting words that occur in a window. As an example, the\\nclassical word embedding inference task is autocorrect when we’re typing on\\nour phones. We type a word, and it’s the job of the autocorrect to predict the\\ncorrect word based on both the word itself and the surrounding context in the\\nsentence. It therefore needs to learn a vocabulary of embeddings that will give\\nit probabilities that it is selecting the correct word.\\nHowever, as in other cases, when we reach high dimensions, SVMs com-\\npletely fail to work with sparse data because they rely on computing distances'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 41, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='However, as in other cases, when we reach high dimensions, SVMs com-\\npletely fail to work with sparse data because they rely on computing distances\\nbetween points to determine the decision boundaries. Because in our sparse\\nvector representations of elements most of the distances are zero, the hyper-\\nplane will fail to cleanly separate the boundaries and classify words incorrectly.\\n3.6\\nWord2Vec\\nTo get around the limitations of earlier textual approaches and keep up with\\ngrowing size of text corpuses, in 2013, researchers at Google came up with an\\nelegant solution to this problem using neural networks, called Word2Vec [47].\\nSo far, we’ve moved from simple heuristics like one-hot encoding, to\\nmachine learning approaches like LSA and LDA that look to learn a dataset’s\\nmodeled features. Previously, like our original one-hot encodings, all the\\napproaches to embedding focused on generating sparse vectors that can give\\nan indication that two words are related, but not that there is a semantic'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 41, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='approaches to embedding focused on generating sparse vectors that can give\\nan indication that two words are related, but not that there is a semantic\\nrelationship between them. For example, “The dog chased the cat” and “the\\ncat chased the dog” would have the same distance in the vector space, even\\nthough they’re two completely different sentences.\\nWord2Vec is a family of models that has several implementations, each\\nof which focus on transforming the entire input dataset into vector represen-\\n42'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 42, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='tations and, more importantly, focusing not only on the inherent labels of\\nindividual words, but on the relationship between those representations.\\nThere are two modeling approaches to Word2Vec - continuous bag of\\nwords (CBOW) and skipgrams, both of which generate dense vectors of\\nembeddings but model the problem slightly differently. The end-goal of the\\nWord2Vec model in either case is to learn the parameters that maximize that\\nprobability of a given word or group of words being an accurate prediction\\n[23].\\nIn training skipgrams, we take a word from the initial input corpus and\\npredict the probability that a given set of words surround it. In the case of\\nour initial flit quote, \"Hold fast to dreams for if dreams die, life is a broken-\\nwinged bird that cannot fly\", the model’s intermediate steps generate a set of\\nembeddings that’s the distance between all the words in the dataset and fill\\nin the next several probabilities for the entire phrase, using the word \"fast\" as\\ninput.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 42, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='embeddings that’s the distance between all the words in the dataset and fill\\nin the next several probabilities for the entire phrase, using the word \"fast\" as\\ninput.\\nFigure 32: Word2Vec Architecture\\nIn training CBOW, we do the opposite: we remove a word from the middle\\nof a phrase known as the context window and train a model to predict the\\nprobability that a given word fills the blank, shown in the equation below\\nwhere we attempt to maximize.\\narg max\\nθ\\n∏\\nw∈Text\\n\"\\n∏\\nc∈C(w)\\np(c|w; θ)\\n#\\n(11)\\nIf we optimize these parameters - theta - and maximize the probability that\\n43'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 43, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='the word belongs in the sentences, we’ll learn good embeddings for our input\\ncorpus.\\nLet’s focus on a detailed implementation of CBOW to better understand\\nhow this works. This time, for the code portion, we’ll move on from scikit-\\nlearn, which works great for smaller data, to PyTorch for neural net operations.\\nAt a high level, we have a list of input words that are processed through a\\nsecond layer, the embedding layer, and then through the output layer, which\\nis just a linear model that returns probabilities.\\nWord #1\\nWord #2\\nWord #3\\nWord #4\\nOutput Probability\\nEmbeddings\\nInput\\nCorpus\\nLinear\\nRegression\\nFigure 33: Word2Vec CBOW Neural Network architecture\\nWe’ll run this implementation in PyTorch, the popular library for building\\nneural network models. The best way to implement Word2Vec, especially if\\nyou’re dealing with smaller datasets, is using Gensim, but Gensim abstracts\\naway the layers into inner classes, which makes for a fantastic user experi-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 43, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='you’re dealing with smaller datasets, is using Gensim, but Gensim abstracts\\naway the layers into inner classes, which makes for a fantastic user experi-\\nence. But, since we’re just learning about them, we’d like to see a bit more\\nexplicitly how they work, and PyTorch, although it does not have a native\\nimplementation of Word2Vec, lets us see the inner workings a bit more clearly.\\nTo model our problem in PyTorch, we’ll use the same approach as with\\nany problem in machine learning:\\n• Inspect and clean our input data.\\n• Build the layers of our model. (For traditional ML, we’ll have only\\none)\\n• Feed the input data into the model and track the loss curve\\n• Retrieve the trained model artifact and use it to make predictions on\\nnew items that we analyze\\n44'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 44, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 34: Steps for creating Word2Vec model\\nLet’s start from our input data. In this case, our corpus is all of the flits\\nwe’ve collected. We first need to process them as input into our model.\\n1\\nresponses = [\"Hold fast to dreams, for if dreams die, life is a broken-winged\\nbird that cannot fly.\", \"No bird soars too high if he soars with his own\\nwings.\", \"A bird does not sing because it has an answer, it sings because\\nit has a song.\"]\\n,→\\n,→\\n,→\\nFigure 35: Our Word2Vec input dataset\\nLet’s start with our input training data, which is our list of flits. To prepare\\ninput data for PyTorch, we can use the DataLoader or Vocab classes, which\\nsplits our text into tokens and tokenizes — or creates smaller, word-level\\nrepresentations of each sentence — for processing. For each line in the file, we\\ngenerate tokens by splitting each line into single words, removing whitespace\\nand punctuation, and lowercasing each individual word.\\nThis kind of processing pipeline is extremely common in NLP and spend-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 44, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='and punctuation, and lowercasing each individual word.\\nThis kind of processing pipeline is extremely common in NLP and spend-\\ning time to get this step right is extremely critical so that we get clean, correct\\ninput data. It typically includes [48]:\\n• Tokenization - transforming a sentence or a word into its component\\ncharacter by splitting it\\n• Removing noise - Including URLs, punctuation, and anything else in\\nthe text that is not relevant to the task at hand\\n• Word segmentation - Splitting our sentences into individual words\\n• Correcting spelling mistakes\\n45'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 45, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nclass TextPreProcessor:\\n2\\ndef __init__(self) -> None:\\n3\\nself.input_file = input_file\\n4\\n5\\ndef generate_tokens(self):\\n6\\nwith open(self.input_file, encoding=\"utf-8\") as f:\\n7\\nfor line in f:\\n8\\nline = line.replace(\"\\\\\\\\\", \"\")\\n9\\nyield line.strip().split()\\n10\\n11\\ndef build_vocab(self) -> Vocab:\\n12\\nvocab = build_vocab_from_iterator(\\n13\\nself.generate_tokens(), specials=[\"<unk>\"], min_freq=100\\n14\\n)\\n15\\nreturn vocab\\nFigure 36: Processing our input vocabulary and building a Vocabulary object from our\\ndataset in PyTorch\\nNow that we have an input vocabulary object we can work with, the next\\nstep is to create one-hot encodings of each word to a numerical position, and\\neach position back to a word, so that we can easily reference both our words\\nand vectors. The goal is to be able to map back and forth when we do lookups\\nand retrieval.\\nThis occurs in the Embedding layer. Within the Embedding layer of Py-\\nTorch, we initialize an Embedding matrix based on the size we specify and'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 45, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='and retrieval.\\nThis occurs in the Embedding layer. Within the Embedding layer of Py-\\nTorch, we initialize an Embedding matrix based on the size we specify and\\nsize of our vocabulary, and the layer indexes the vocabulary into a dictionary\\nfor retrieval. The embedding layer is a lookup table24 that matches a word to\\nthe corresponding word vector on an index by index basis. Initially, we create\\nour one-hot encoded word to term dictionary. Then, we create a mapping of\\neach word to a dictionary entry and a dictionary entry to each word. This\\nis known as bijection. In this way, the Embedding layer is like a one-hot\\nencoded matrix, and allows us to perform lookups. The lookup values in this\\nlayer are initialized to a set of random weights, which we next pass onto the\\nlinear layer.\\nEmbeddings resemble hash maps and also have their performance char-\\nacteristics (O(1) retrieval and insert time), which is why they can scale easily'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 45, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='linear layer.\\nEmbeddings resemble hash maps and also have their performance char-\\nacteristics (O(1) retrieval and insert time), which is why they can scale easily\\nwhen other approaches cannot. In the embedding layer, Word2Vec where each\\nvalue in the vector represents the word on a specific dimension, and more\\nimportantly, unlike many of the other methods, the value of each vector is in\\ndirect relationship to the other words in the input dataset.\\n24Embedding Layer PyTorch documents\\n46'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 46, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content=\"1\\nclass CBOW(torch.nn.Module):\\n2\\ndef __init__(self):\\n# we pass in vocab_size and embedding_dim as hyperparams\\n3\\nsuper(CBOW, self).__init__()\\n4\\nself.num_epochs = 3\\n5\\nself.context_size = 2\\n# 2 words to the left, 2 words to the right\\n6\\nself.embedding_dim = 100\\n# Size of your embedding vector\\n7\\nself.learning_rate = 0.001\\n8\\nself.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n9\\n10\\nself.vocab = TextPreProcessor().build_vocab()\\n11\\nself.word_to_ix = self.vocab.get_stoi()\\n12\\nself.ix_to_word = self.vocab.get_itos()\\n13\\nself.vocab_list = list(self.vocab.get_stoi().keys())\\n14\\nself.vocab_size = len(self.vocab)\\n15\\n16\\nself.model = None\\n17\\n18\\n# out: 1 x embedding_dim\\n19\\nself.embeddings = nn.Embedding(\\n20\\nself.vocab_size, self.embedding_dim\\n21\\n)\\n# initialize an Embedding matrix based on our inputs\\n22\\nself.linear1 = nn.Linear(self.embedding_dim, 128)\\n23\\nself.activation_function1 = nn.ReLU()\\n24\\n25\\n# out: 1 x vocab_size\\n26\\nself.linear2 = nn.Linear(128, self.vocab_size)\\n27\"),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 46, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='22\\nself.linear1 = nn.Linear(self.embedding_dim, 128)\\n23\\nself.activation_function1 = nn.ReLU()\\n24\\n25\\n# out: 1 x vocab_size\\n26\\nself.linear2 = nn.Linear(128, self.vocab_size)\\n27\\nself.activation_function2 = nn.LogSoftmax(dim=-1)\\nFigure 37: Word2Vec CBOW implementation in Pytorch. source\\nOnce we have our lookup values, we can process all our words. For CBOW,\\nwe take a single word and we pick a sliding window, in our case, two words\\nbefore, and two words after, and try to infer what the actual word is. This is\\ncalled the context vector, and in other cases, we’ll see that it’s called attention.\\nFor example, if we have the phrase \"No bird [blank] too high\", we’re trying to\\npredict that the answer is \"soars\" with a given softmax probability, aka ranked\\nagainst other words. Once we have the context vector, we look at the loss —\\nthe difference between the true word and the predicted word as ranked by\\nprobability — and then we continue.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 46, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='against other words. Once we have the context vector, we look at the loss —\\nthe difference between the true word and the predicted word as ranked by\\nprobability — and then we continue.\\nThe way we train this model is through context windows. For each given\\nword in the model, we create a sliding window that includes that word and 2\\nwords before it, and 2 words after it.\\nWe activate the linear layer with a ReLu activation function, which decides\\nwhether a given weight is important or not. In this case, ReLu squashes all the\\nnegative values we initialize our embeddings layer with down to zero since\\nwe can’t have inverse word relationships, and we perform linear regression\\nby learning the weights of the model of the relationship of the words. Then,\\nfor each batch we examine the loss, the difference between the real word and\\nthe word that we predicted should be there given the context window - and\\n47'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 47, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='we minimize it.\\nAt the end of each epoch, or pass through the model, we pass the weights,\\nor backpropagate them, back to the linear layer, and then again, update the\\nweights of each word, based on the probability. The probability is calculated\\nthrough a softmax function, which converts a vector of real numbers into a\\nprobability distribution - that is, each number in the vector, i.e. the value of the\\nprobability of each words, is in the interval between 0 and 1 and all of the word\\nnumbers add up to one. The distance, as backpropagated to the embeddings\\ntable, should converge or shrink depending on the model understanding how\\nclose specific words are.\\n48'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 48, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\n2\\ndef make_context_vector(self, context, word_to_ix) -> torch.LongTensor:\\n3\\n\"\"\"\\n4\\nFor each word in the vocab, find sliding windows of [-2,1,0,1,2] indexes\\n5\\nrelative to the position of the word\\n6\\n:param vocab: list of words in the vocab\\n7\\n:return: torch.LongTensor\\n8\\n\"\"\"\\n9\\nidxs = [word_to_ix[w] for w in context]\\n10\\ntensor = torch.LongTensor(idxs)\\n11\\n12\\n13\\ndef train_model(self):\\n14\\n15\\n# Loss and optimizer\\n16\\nself.model = CBOW().to(self.device)\\n17\\noptimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\\n18\\nloss_function = nn.NLLLoss()\\n19\\n20\\nlogging.warning(\\'Building training data\\')\\n21\\ndata = self.build_training_data()\\n22\\n23\\nlogging.warning(\\'Starting forward pass\\')\\n24\\nfor epoch in tqdm(range(self.num_epochs)):\\n25\\n# we start tracking how accurate our initial words are\\n26\\ntotal_loss = 0\\n27\\n28\\n# for the x, y in the training data:\\n29\\nfor context, target in data:\\n30\\ncontext_vector = self.make_context_vector(context, self.word_to_ix)\\n31\\n32\\n# we look at loss\\n33'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 48, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='26\\ntotal_loss = 0\\n27\\n28\\n# for the x, y in the training data:\\n29\\nfor context, target in data:\\n30\\ncontext_vector = self.make_context_vector(context, self.word_to_ix)\\n31\\n32\\n# we look at loss\\n33\\nlog_probs = self.model(context_vector)\\n34\\n35\\n# compare loss\\n36\\ntotal_loss += loss_function(\\n37\\nlog_probs, torch.tensor([self.word_to_ix[target]])\\n38\\n)\\n39\\n40\\n# optimize at the end of each epoch\\n41\\noptimizer.zero_grad()\\n42\\ntotal_loss.backward()\\n43\\noptimizer.step()\\n44\\n45\\n# Log out some metrics to see if loss decreases\\n46\\nlogging.warning(\"end of epoch {} | loss {:2.3f}\".format(epoch, total_loss))\\n47\\n48\\ntorch.save(self.model.state_dict(), self.model_path)\\n49\\nlogging.warning(f\\'Save model to {self.model_path}\\')\\nFigure 38: W\\nord2Vec CBOW implementation in PyTorch\\nsee full implementation here\\n49'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 49, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Once we’ve completed our iteration through our training set, we have\\nlearned a model that retrieves both the probability of a given word being the\\ncorrect word, and the entire embedding space for our vocabulary.\\n4\\nModern Embeddings Approaches\\nWord2Vec became one of the first neural network architectures to use the con-\\ncept of embedding to create a fixed feature vocabulary. But neural networks\\nas a whole were gaining popularity for natural language modeling because\\nof several key factors. First, in the 1980s, researchers made advancements in\\nusing the technique of backpropagation for training neural networks learning\\n[53]. Backpropagation is how a model learns to converge by calculating the\\ngradient of the loss function with respect to the weights of the neural network,\\nusing the chain rule, a concept from calculus which allows us to calculate\\nthe derivative of a function made up of multiple functions. This mechanism'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 49, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='using the chain rule, a concept from calculus which allows us to calculate\\nthe derivative of a function made up of multiple functions. This mechanism\\nallows the model to understand when it’s reached a global minimum for loss\\nand picks the correct weights for the model parameters, but training models\\nthrough gradient descent. Earlier approaches, such as the perceptron learning\\nrule, tried to do this, but had limitations, such as being able to work only\\non simple layer architectures, took a long time to converge, and experienced\\nvanishing gradients, which made it hard to effectively update the model’s\\nweights.\\nThese advances gave rise to the first kinds of multi-level neural networks,\\nfeed-forward neural networks. In 1998, a paper used backpropagation over\\nmultilayer perceptrons to correctly perform the task of recognizing handwrit-\\nten digit images [40], demonstrating a practical use-case practitioners and\\nresearchers could apply. This MNIST dataset is now one of the canonical'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 49, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='ten digit images [40], demonstrating a practical use-case practitioners and\\nresearchers could apply. This MNIST dataset is now one of the canonical\\n\"Hello World\" examples of deep learning.\\nSecond, in the 2000s, the rise of petabytes of aggregated log data resulted\\nin the creation of large databases of multimodal input data scraped from the\\ninternet. This made it possible to conduct wide-ranging experiments to prove\\nthat neural networks work on large amounts of data. For example, ImageNet\\nwas developed by researchers at Stanford who wanted to focus on improving\\nmodel performance by creating a gold set of neural network input data, the\\nfirst step in processing. FeiFei Li assembled a team of students and paid\\ngig workers from Amazon Turk to correctly label a set of 3.2 million images\\nscraped from the internet and organized based on categories according to\\nWordNet, a taxonomy put together by researchers in the 1970s [55].\\nResearchers saw the power of using standard datasets. In 2015, Alex'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 49, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='WordNet, a taxonomy put together by researchers in the 1970s [55].\\nResearchers saw the power of using standard datasets. In 2015, Alex\\nKrizhevsky, in collaboration with Ilya Sutskever, who now works at OpenAI\\nas one of the leading researchers behind the GPT series of models that form the\\nbasis of the current generative AI wave, submitted an entry to the ImageNet\\ncompetition called AlexNet. This model was a convolutional neural network\\nthat outperformed many other methods. There were two things that were\\nsignificant about AlexNet. The first was that it had eight stacked layers of\\nweights and biases, which was unusual at the time. Today, 12-layer neural.\\nnetworks like BERT and other transformers are completely normal, but at the\\ntime, more than two layers was revolutionary. The second was that it ran on\\n50'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 50, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='GPUs, a new architectural concept at the time, since GPUs were used mostly\\nfor gaming.\\nNeural networks started to become popular as ways to generate represen-\\ntations of vocabularies. In particular, neural network architectures, such as\\nand recurrent neural networks (RNNs) and later long short-term memory\\nnetworks (LSTMs) also emerged as ways to deal with textual data for all kinds\\nof machine learning tasks from NLP to computer vision.\\n4.1\\nNeural Networks\\nNeural networks are extensions on traditional machine learning models, but\\nthey have a few critical special properties. Let’s think back to our definition\\nof a model when we formalized a machine learning problem. A model is a\\nfunction with a set of learnable input parameters that takes some set of inputs\\nand one set of tabular input features, and gives us an output. In traditional\\nmachine learning approaches, there is one set, or layer, of learnable parameters\\nand one model. If our data doesn’t have complex interactions, our model can'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 50, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='machine learning approaches, there is one set, or layer, of learnable parameters\\nand one model. If our data doesn’t have complex interactions, our model can\\nlearn the feature space fairly easily and make accurate predictions.\\nHowever, when we start dealing with extremely large, implicit feature\\nspaces, such as are present in text, audio, or video, we will not be able to derive\\nspecific features that wouldn’t be obvious if we were manually creating them.\\nA neural network, by stacking neurons, each of which represent some aspect\\nof the model, can tease out these latent representations. Neural networks\\nare extremely good at learning representations of data, with each level of the\\nnetwork transforming a learned representation of the level to a higher level\\nuntil we get a clear picture of our data [41].\\n4.1.1\\nNeural Network architectures\\nWe’ve already encountered our first neural network, Word2Vec, which seeks to\\nunderstand relationships between words in our text that the words themselves'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 50, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='4.1.1\\nNeural Network architectures\\nWe’ve already encountered our first neural network, Word2Vec, which seeks to\\nunderstand relationships between words in our text that the words themselves\\nwould not tell us. Within the neural network space, there are several popular\\narchitectures:\\n• Feed-forward networks that extract meaning from fixed-length in-\\nputs. Results of these model are not fed back into the model for\\niteration\\n• Convolutional neural nets (CNNs) - used mainly for image process-\\ning, which involves a convolutional layer made up of a filter that\\nmoves across an image to check for feature representations which\\nare then multiplied via dot product with the filter to pull out specific\\nfeatures\\n• recurrent neural networks, which take a sequence of items and\\nproduce a vector that summarizes the sentence\\nRNNs and CNNs are used mainly in feature extraction - they generally\\ndo not represent the entire modeling flow, but are fed later into feed-forward'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 50, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='produce a vector that summarizes the sentence\\nRNNs and CNNs are used mainly in feature extraction - they generally\\ndo not represent the entire modeling flow, but are fed later into feed-forward\\nmodels that do the final work of classification, summarization, and more.\\n51'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 51, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Neural Networks\\nFeedforward\\nSingle-layer\\nMulti-layer\\nRecurrent\\nElman\\nJordan\\nLSTM\\nGRU\\nConvolutional\\nAutoencoder\\nVanilla\\nVariational\\nGenerative Adversarial\\nRadial Basis Function\\nFigure 39: Types of Neural Networks\\nNeural networks are complex to build and manage for a number of reasons.\\nFirst, they require extremely large corpuses of clean, well-labeled data to\\nbe optimized. They also require special GPU architectures for processing,\\nand, as we’ll see in the production section, they have their own metadata\\nmanagement and latency considerations. Finally, within the network itself,\\nwe need to complete a large amount of passes we need to do over the model\\nobject using batches of our training data to get it to converge. The number of\\nfeature matrices that we need to run calculations over25, and, consequently,\\nthe amount of data we have to keep in-memory through the lifecycle of the\\nmodel ends up accumulating and requires a great deal of performance tuning.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 51, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='the amount of data we have to keep in-memory through the lifecycle of the\\nmodel ends up accumulating and requires a great deal of performance tuning.\\nThese features made developing and running neural networks pro-\\nhibitively expensive until the last fifteen years or so. First, the exponential\\nincrease in storage space provided by the growing size of commodity hard-\\nware both on-prem and in the cloud meant that we could now store that data\\nfor computation, and the explosion of log data gave companies such as Google\\na lot of training data to work with. Second, the rise of the GPU as a tool that\\ntakes advantage of the neural network’s ability to perform embarrassingly\\nparallel computation — a characteristic of computation when it’s easy to sepa-\\nrate steps out into ones that can be performed in parallel, such as word count\\nfor example. In a neural network, we can generally parallelize computation in\\nany given number of ways, including at the level of a single neuron.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 51, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='for example. In a neural network, we can generally parallelize computation in\\nany given number of ways, including at the level of a single neuron.\\n25There is no good single resource for calculating the computational complexity of a neural\\nnetwork given that there are many wide-ranging architectures but this post does a good job\\nlaying out the case that it’s essentially O(n5)\\n52'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 52, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='While GPUs were initially used for working with computer graphics, in the\\nearly 2000s [49], researchers discovered the potential to use them for general\\ncomputation, and Nvidia made an enormous bet on this kind of computing by\\nintroducing CUDA, an API layer on top of GPUs. This in turn allowed for the\\ncreation and development of high-level popular deep learning frameworks\\nlike PyTorch and Tensorflow.\\nNeural networks could now be trained and experimented with at scale. To\\ncome back to a comparison to our previous approaches, when we calculate TF-\\nIDF, we need to loop over each individual word and perform our computations\\nover the entire dataset in sequence to arrive at a score in proportion to all other\\nwords, which means that our computational complexity will be O(ND) [10].\\nHowever, with a neural network, we can either distribute the model train-\\ning across different GPUs in a process known as model parallelism, or com-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 52, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='However, with a neural network, we can either distribute the model train-\\ning across different GPUs in a process known as model parallelism, or com-\\npute batches — the size of the training data fed into the model and used in a\\ntraining loop before its hyperparameters are updated in parallel and update\\nat the end of each minibatch, which is known as data parallelism. [60].\\n4.2\\nTransformers\\nWord2Vec is a feed-forward network. The model weights and information only\\nflows from the encoding state, to the hidden embedding layer, to the output\\nprobability layer. There is no feedback between the second and third layers,\\nwhich means that each given layer doesn’t know anything about the state of\\nthe layers that follow it. It can’t make inference suggestions longer than the\\ncontext window. This works really well for machine learning problems where\\nwe’re fine with a single, static vocabulary.\\nHowever, it doesn’t work well on long ranges of text that require under-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 52, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='context window. This works really well for machine learning problems where\\nwe’re fine with a single, static vocabulary.\\nHowever, it doesn’t work well on long ranges of text that require under-\\nstanding words in context of each other. For example, over the course of a\\nconversation, we might say, \"I read that quote by Langston Hughes. I liked\\nit, but didn’t really read his later work,\" we understand that \"it\" refers to\\nthe quote, context from the previous sentence, and \"his\" refers to \"Langston\\nHughes\", mentioned two sentences ago.\\nOne of the other limitations was that Word2Vec can’t handle out-of-\\nvocabulary words — words that the model has not been trained on and\\nneeds to generalize to. This means that if our users search for a new trending\\nterm or we want to recommend a flit that was written after our model was\\ntrained, they won’t see any relevant results from our model. [14], unless the\\nmodel is retrained frequently.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 52, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='term or we want to recommend a flit that was written after our model was\\ntrained, they won’t see any relevant results from our model. [14], unless the\\nmodel is retrained frequently.\\nAnother problem is that Word2Vec encounters context collapse around\\npolysemy — the coexistence of many possible meanings for the same phrase:\\nfor example, if you have \"jail cell\" and \"cell phone\" in the same sentence, it\\nwon’t understand that the context of both words is different. Much of the\\nwork of NLP based in deep learning has been in understanding and retaining\\nthat context to propagate through the model and pull out semantic meaning.\\nDifferent approaches were proposed to overcome these limitations. Re-\\nsearchers experimented with recurrent neural networks, RNNs. An RNN\\nbuilds on traditional feed-forward networks, with the difference being that\\nlayers of the model give feedback to previous layers. This allows the model to\\n53'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 53, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='keep memory of the context around words in a sentence.\\nNeuron\\nxt\\nht\\n(a) Feedforward Neural Network\\nNeuron\\nxt\\nht\\n(b) Recurrent Neural Network\\nA problem with traditional RNNs was that because during backpropaga-\\ntion the weights had to be carried through to the previous layers of neurons,\\nthey experienced the problem of vanishing gradients. This occurs when we\\ncontinuously take the derivative such that the partial derivative used in the\\nchain rule during backpropagation approaches zero. Once we approach zero,\\nthe neural network assumes it has reached a local optimum and stops training,\\nbefore convergence.\\nA very popular variation of an RNN that worked around this problem\\nwas the long-short term memory network (LSTM), developed initially by\\nSchmidhuber26 and brought to popularity for use in text applications speech\\nrecognition and image captioning [33]. Whereas our previous model takes only\\na vector at a time as input, RNNs operate on sequences of vectors using GRUs,'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 53, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='recognition and image captioning [33]. Whereas our previous model takes only\\na vector at a time as input, RNNs operate on sequences of vectors using GRUs,\\nwhich allows the network to control how much information is passed in for\\nanalysis. While LSTMs worked fairly well, they had their own limitations.\\nBecause they were architecturally complicated, they took much longer to\\ntrain, and at a higher computational cost, because they couldn’t be trained in\\nparallel.\\n4.2.1\\nEncoders/Decoders and Attention\\nTwo concepts allowed researchers to overcome computationally expensive\\nissues with remembering long vectors for a larger context window than\\nwhat was available in RNNs and Word2Vec before it: the encoder/decoder\\narchitecture, and the attention mechanism.\\nThe encoder/decoder architecture is a neural network architecture com-\\nprised of two neural networks, an encoder that takes the input vectors from\\nour data and creates an embedding of a fixed length, and a decoder, also a'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 53, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='prised of two neural networks, an encoder that takes the input vectors from\\nour data and creates an embedding of a fixed length, and a decoder, also a\\nneural network, which takes the embeddings encoded as input and generates\\n26If you read Schmidhuber, you will come to the understanding that everything in deep\\nlearning was developed initially by Schmidhuber\\n54'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 54, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='a static set of outputs such as translated text or a text summary. In between\\nthe two types of layers is the attention mechanism, a way to hold the state\\nof the entire input by continuously performing weighted matrix multiplica-\\ntions that highlight the relevance of specific terms in relation to each other\\nin the vocabulary. We can think of attention as a very large, complex hash\\ntable that keeps track of the words in the text and how they map to different\\nrepresentations both in the input and the output.\\n-0.2\\n-0.1\\n0.1\\n0.4\\n-0.3\\n1.1\\nDecoder\\nEncoder\\nDecoder\\nTranslated\\ntext\\nInput\\ntext\\nFigure 41: The encoder/decoder architecture\\n55'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 55, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='1\\nclass EncoderDecoder(nn.Module):\\n2\\n\"\"\"\\n3\\nDefining the encoder/decoder steps\\n4\\n\"\"\"\\n5\\ndef __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\\n6\\nsuper(EncoderDecoder, self).__init__()\\n7\\nself.encoder = encoder\\n8\\nself.decoder = decoder\\n9\\nself.src_embed = src_embed\\n10\\nself.tgt_embed = tgt_embed\\n11\\nself.generator = generator\\n12\\n13\\ndef forward(self, src, tgt, src_mask, tgt_mask):\\n14\\n\"Take in and process masked src and target sequences.\"\\n15\\nreturn self.decode(self.encode(src, src_mask), src_mask,\\n16\\ntgt, tgt_mask)\\n17\\n18\\ndef encode(self, src, src_mask):\\n19\\nreturn self.encoder(self.src_embed(src), src_mask)\\n20\\n21\\ndef decode(self, memory, src_mask, tgt, tgt_mask):\\n22\\nreturn self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\\n23\\n24\\nclass Generator(nn.Module):\\n25\\n\"Define standard linear + softmax generation step.\"\\n26\\ndef __init__(self, d_model, vocab):\\n27\\nsuper(Generator, self).__init__()\\n28\\nself.proj = nn.Linear(d_model, vocab)\\n29\\n30\\ndef forward(self, x):\\n31'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 55, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='\"Define standard linear + softmax generation step.\"\\n26\\ndef __init__(self, d_model, vocab):\\n27\\nsuper(Generator, self).__init__()\\n28\\nself.proj = nn.Linear(d_model, vocab)\\n29\\n30\\ndef forward(self, x):\\n31\\nreturn F.log_softmax(self.proj(x), dim=-1)\\n32\\nFigure 42: A typical encoder/decoder architecture From the Annotated Transformer\\n\"Attention is All You Need\" [66], released in 2017, combined both of these\\nconcepts into a single architecture. The paper immediately saw a great deal\\nof success, and today Transformers are one of the de-facto models used for\\nnatural language tasks.\\nBased on the success of the original model, a great deal of variations on\\nTransformer architectures have been released, followed by GPT and BERT in\\n2018, Distilbert, a smaller and more compact version of BERT in 2019, and\\nGPT-3 in 202027.\\n27For a complete visual transformer timeline, check out this link\\n56'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 56, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Transformer\\nGPT\\nGPT-2\\nGPT-3\\nDALL-E\\nGPT-4\\nBERT\\nDistilBERT\\nRoBERTa\\nPaLM\\nFigure 43: Timeline of Transformer Models\\nTransformer architectures themselves are not new, but they contain all\\nthe concepts we’ve discussed so far: vectors, encodings, and hash maps.\\nThe goal of a transformer model is to take a piece of multimodal content,\\nand learn the latent relationships by creating multiple views of groups of\\nwords in the input corpus (multiple context windows). The self-attention\\nmechanism, implemented as scaled dot-product attention in the Transformer\\npaper, creates different context windows of the data a number of times through\\nthe six encoder and six decoder layers. The output is the result of the specific\\nmachine learning task — a translated sentence, a summarized paragraph –\\nand the next-to-last layer is the model’s embeddings, which we can use for\\ndownstream work.\\nFigure 44: View into transformer layers, inspired by multiple sources including this diagram'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 56, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='and the next-to-last layer is the model’s embeddings, which we can use for\\ndownstream work.\\nFigure 44: View into transformer layers, inspired by multiple sources including this diagram\\nThe transformer model described in the paper takes a corpus of text as\\ninput28. We first transform our text to token embeddings by tokenizing and\\nmapping every word or subword to an index. This is the same process as in\\nWord2Vec: we simply assign each word to an element in a matrix. However,\\nthese alone will not help us with context, so, on top of this, we also learn\\na positional embeddings with the help of a sine or cosine function that is\\nmapped and compressed into a matrix considering the position of all the other\\nword in the vocabulary. The final output of this process is the positional vector\\n28In theory you can use any modality for transformers without modifying the input other\\nthan to label the data with the given modality [71], but the early work, such as machine'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 56, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='28In theory you can use any modality for transformers without modifying the input other\\nthan to label the data with the given modality [71], but the early work, such as machine\\ntranslation, focuses on text, so we will as well\\n57'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 57, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='or the word encoding.\\nNext, these positional vectors are passed in parallel to the model. Within\\nthe Transformer paper, the model consists of six layers that perform encod-\\ning and six that perform decoding. We start with the encoder layer, which\\nconsists of two sub-layers: the self-attention layer, and a feed-forward neural\\nnetwork. The self-attention layer is the key piece, which performs the process\\nof learning the relationship of each term in relation to the other through scaled\\ndot-product attention. We can think of self-attention in several ways: as a\\ndifferentiable lookup table, or as a large lookup dictionary that contains both\\nthe terms and their positions, with the weights of each term in relationship to\\nthe other obtained from previous layers.\\nThe scaled dot-product attention is the product of three matrices: key,\\nquery, and value. These are initially all the same values that are outputs of\\nprevious layers - in the first pass through the model, they are initially all the'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 57, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='query, and value. These are initially all the same values that are outputs of\\nprevious layers - in the first pass through the model, they are initially all the\\nsame, initialized at random and adjusted at each step by gradient descent.\\nFor each embedding, we generate a weighted average value based on these\\nlearned attention weights. We calculate the dot product between query and\\nkey, and finally normalize the weights via softmax. Multi-head attention\\nmeans that we perform the process of calculating the scaled dot product\\nattention multiple times in parallel and concatenate the outcome into one\\nvector.\\nAttention(Q, K, V) = so f tmax(QKT\\n√dk\\n)V\\n(12)\\nWhat’s great about scaled dot-product attention (and about all of the layers\\nof the encoder) is that the work can be done in parallel across all the tokens in\\nour codebase: we don’t need to wait for one word to finish processing as we\\ndo in Word2Vec in order to process the next one, so the number of input steps'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 57, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='our codebase: we don’t need to wait for one word to finish processing as we\\ndo in Word2Vec in order to process the next one, so the number of input steps\\nremains the same, regardless of how big our vocabulary is.\\nThe decoder piece differs slightly from the encoder. It starts with a different\\ninput dataset: in the transformer paper, it’s the target language dataset we’d\\nlike to translate the text into. So for example if we were translating our Flit\\nfrom English to Italian, we’d expect to train on the Italian corpus. Otherwise,\\nwe perform all the same actions: we create indexed embeddings that we then\\nconvert into positional embeddings. We then feed the positional embeddings\\nfor the target text into a layer that has three parts: masked multi-headed\\nattention, multiheaded attention, and a feed-forward neural network. The\\nmasked multi-headed attention component is just like self-attention, with one\\nextra piece: the mask matrix introduced in this step acts as a filter to prevent'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 57, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='masked multi-headed attention component is just like self-attention, with one\\nextra piece: the mask matrix introduced in this step acts as a filter to prevent\\nthe attention head from looking at future tokens, since the input vocabulary\\nfor the decoder are our \"answers\", I.e. what the translated text should be.\\nThe output from the masked multi-head self attention layer is passed to the\\nencoder-decoder attention portion, which accepts the final input from the\\ninitial six encoder layers for the key and value, and uses the input from the\\nprevious decoder layer as the query, and then performs scaled dot-product\\nover this. Each output is then fed into the feed forward layer, to a finalized set\\nof embeddings.\\nOnce we have the hidden state for each token, we can then attach the task\\n58'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 58, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='head. In our case, this is prediction of what a word should be. At each step of\\nthe process, the decoder looks at the previous steps and generates based on\\nthose steps so we form a complete sentence [54]. We then get the predicted\\nword, just like in Word2Vec.\\nTransformers were revolutionary for a number of reasons, because they\\nsolved several problems people had been working on:\\n• Parallelization - Each step in the model is parallelizable, meaning we\\ndon’t need to wait to know the positional embedding of one word in\\norder to work on another, since each embedding lookup matrix focuses\\nattention on a specific word, with a lookup table of all other words in\\nrelationship to that word - each matrix for each word carries the context\\nwindow of the entire input text.\\n• Vanishing gradients - Previous models like RNNs can suffer from van-\\nishing or exploding gradients, which means that the model reaches a\\nlocal minimum before it’s fully-trained, making it challenging to cap-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 58, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='ishing or exploding gradients, which means that the model reaches a\\nlocal minimum before it’s fully-trained, making it challenging to cap-\\nture long-term dependencies. Transformers mitigate this problem by\\nallowing direct connections between any two positions in the sequence,\\nenabling information to flow more effectively during both forward and\\nbackward propagation.\\n• Self-attention - The attention mechanism allows us to learn the context\\nof an entire text that’s longer than a 2 or 3-word sliding context window,\\nallowing us to learn different words in different contexts and predict\\nanswers with more accuracy\\n4.3\\nBERT\\nFigure 45: Encoder-only architecture\\nAfter the explosive success of \"Attention is All you Need\", a variety of trans-\\nformer architectures arose, research and implementation in this architecture\\nexploded in deep learning. The next transformer architecture to be considered\\na significant step forward was BERT. BERT stands for Bi-Directional Encoder'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 58, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='exploded in deep learning. The next transformer architecture to be considered\\na significant step forward was BERT. BERT stands for Bi-Directional Encoder\\nand was released 2018 [13], based on a paper written by Google as a way\\nto solve common natural language tasks like sentiment analysis, question-\\nanswering, and text summarization. BERT is a transformer model, also based\\non the attention mechanism, but its architecture is such that it only includes\\nthe encoder piece. Its most prominent usage is in Google Search, where it’s\\nthe algorithm powering surfacing relevant search results. In the blog post\\nthey released on including BERT in search ranking in 2019, Google specifi-\\ncally discussed adding context to queries as a replacement for keyword-based\\n59'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 59, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='methods as a reason they did this.29\\nBERT works as a masked language model. Masking is simply what we\\ndid when we implemented Word2Vec by removing words and building our\\ncontext window. When we created our representations with Word2Vec, we\\nonly looked at sliding windows moving forward. The B in Bert is for bi-\\ndirectional, which means it pays attention to words in both ways through\\nscaled dot-product attention. BERT has 12 transformer layers. It starts by\\nusing WordPiece, an algorithm that segments words into subwords, into\\ntokens. To train BERT, the goal is to predict a token given its context.\\nThe output of BERT is latent representations of words and their context —\\na set of embeddings. BERT is, essentially, an enormous parallelized Word2Vec\\nthat remembers longer context windows. Given how flexible BERT is, it\\ncan be used for a number of tasks, from translation, to summarization, to\\nautocomplete. Because it doesn’t have a decoder component, it can’t generate'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 59, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='can be used for a number of tasks, from translation, to summarization, to\\nautocomplete. Because it doesn’t have a decoder component, it can’t generate\\ntext, which paved the way for GPT models to pick up where BERT left off.\\n4.4\\nGPT\\nAround the same time that BERT was being developed, another transformer\\narchitecture, the GPT series, was being developed at OpenAI. GPT differs\\nfrom BERT in that it encodes as well as decodes text from embeddings and\\ntherefore can be used for probabilistic inference.\\nThe original, first GPT model was trained as a 12-layer, 12-headed trans-\\nformer with only a decoder piece, based on data from Book Corpus. Sub-\\nsequent versions built on this foundation to try and improve context under-\\nstanding. The largest breakthrough was in GPT-4, which was trained with\\nreinforcement learning from Human Feedback, a property which allows it\\nto make inferences from text that feels much closer to what a human would\\nwrite.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 59, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='reinforcement learning from Human Feedback, a property which allows it\\nto make inferences from text that feels much closer to what a human would\\nwrite.\\nWe’ve now reached the forefront of what’s possible with embeddings\\nin this paper. With the rise of generative methods and methods based on\\nReinforcement Learning with Human Feedback like OpenAI’s ChatGPT, as\\nwell as the nascent open-source Llama, Alpaca, and other models, anything\\nwritten in this paper would already be impossibly out of date by the time it\\nwas published30.\\n5\\nEmbeddings in Production\\nWith the advent of Transformer models, and more importantly, BERT, gen-\\nerating representations of large, multimodal objects for use in all sorts of\\nmachine learning tasks suddenly became much easier, the representations\\nbecame more accurate, and if the company had GPUs available, computations\\ncould now be computed with speed-up in parallel. Now that we understand\\nwhat embeddings are, what should we do with them? After all, we’re not'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 59, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='could now be computed with speed-up in parallel. Now that we understand\\nwhat embeddings are, what should we do with them? After all, we’re not\\n29BERT search announcement\\n30There are already some studies about possible uses of LLMs for recommendations, includ-\\ning conversational recommender systems, but it’s still very early days. For more information\\ncheck out this post\\n60'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 60, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='doing this just as a math exercise. If there is one thing to take away from this\\nentire text, it is this:\\nThe final goal of all industrial machine learning (ML) projects is to develop\\nML products and rapidly bring them into production. [37]\\nThe model that is deployed is always better and more accurate than the\\nmodel that is only ever a prototype. We’ve gone through the process of\\ntraining embeddings end to end here, but there are several modalities for\\nworking with embeddings. We can:\\n• Train our own embeddings model - We can train BERT or some variation\\nof BERT from scratch. BERT uses an enormous amount of training\\ndata, so this is not really advantageous to us, unless we want to better\\nunderstand the internals and have access to a lot of GPUs.\\n• Use pretrained embeddings and fine-tune - There are many variations\\non BERT models and they all Variations of BERT have been used to\\ngenerate embeddings to use as downstream input into many recom-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 60, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• Use pretrained embeddings and fine-tune - There are many variations\\non BERT models and they all Variations of BERT have been used to\\ngenerate embeddings to use as downstream input into many recom-\\nmender and information retrieval systems. One of the largest gifts that\\nthe transformer architecture gives us is the ability to perform transfer\\nlearning.\\nBefore, when we learned embeddings in pre-transformer architectures,\\nour representation of whatever dataset we had at hand was fixed — we\\ncouldn’t change the weights of the words in TF-IDF without regenerating\\nan entire dataset.\\nNow, we have the ability to treat the output of the layers of BERT as input\\ninto the next neural network layer of our own, custom model. In addition to\\ntransfer learning, there are also numerous more compact models for BERT,\\nsuch as Distilbert and RoBERTA and for many of the larger models in places\\nlike the HuggingFace Model Hub31.\\nArmed with this knowledge, we can think of several use cases of embed-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 60, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='such as Distilbert and RoBERTA and for many of the larger models in places\\nlike the HuggingFace Model Hub31.\\nArmed with this knowledge, we can think of several use cases of embed-\\ndings, given their flexibility as a data structure.\\n• Feeding them into another model - For example, we can now per-\\nform collaborative filtering using both user and item embeddings\\nthat were learned from our data instead of coding the users and items\\nthemselves.\\n• Using them directly - We can use item embeddings directly for\\ncontent filtering - finding items that are closest to other items, a task\\nrecommendation shares with search. There are a host of algorithms\\nused to perform vector similarity lookups by projecting items into our\\nembedding space and performing similarity search using algorithms\\nlike faiss and HNSW.\\n31For a great writeup on the development of open-source machine learning deep learning,\\nsee \"A Call to Build Models Like We Build Open-Source Software\"\\n61'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 61, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='5.1\\nEmbeddings in Practice\\nMany companies are working with embeddings in all of these contexts today,\\nacross areas that span all aspects of information retrieval. Embeddings gen-\\nerated with deep learning models are being generated for use in wide and\\ndeep models for App Store recommendations at Google Play [73], dual em-\\nbeddings for product complementary content recommendations at Overstock\\n[38], personalization of search results at Airbnb via real-time ranking [25], us-\\ning embeddings for content understanding at Netflix [16], for understanding\\nvisual styles at Shutterstock [24], and many other examples.\\n5.1.1\\nPinterest\\nOne notable example is Pinterest. Pinterest as an application has a wide variety\\nof content that needs to be personalized and classified for recommendation to\\nusers across multiple surfaces, particularly the Homefeed and shopping tab.\\nThe scale of generated content - 350 million monthly users and 2 billion items'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 61, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='users across multiple surfaces, particularly the Homefeed and shopping tab.\\nThe scale of generated content - 350 million monthly users and 2 billion items\\n- Pins — or cards with an image described by text — necessitates a strong\\nfiltering and ranking policy.\\nTo represent a user’s interest and surface interesting content, Pinterest\\ndeveloped PinnerSage [50], which represents user interests through multiple\\n256-dimension embeddings that are clustered based on similarity and repre-\\nsented by medioids — an item that is a representative of a center of a given\\ninterest cluster.\\nThe foundation of this system is a set of embeddings developed through an\\nalgorithm called PinSage [72]. Pinsage generates embeddings using a Graph\\nConvolutional neural network, which is a neural net that takes into account the\\ngraph structure of relationships between nodes in the network. The algorithm\\nlooks at the nearest neighbors of a pin and samples from nearby pins based'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 61, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='graph structure of relationships between nodes in the network. The algorithm\\nlooks at the nearest neighbors of a pin and samples from nearby pins based\\non related neighborhood visits. The input is embeddings of a Pin: the image\\nembeddings, and the text embeddings, and finds the nearest neighbors.\\nPinsage embeddings are then passed to Pinnersage, which takes the pins\\nthe user has acted on for the past 90 days and clusters them. It computes the\\nmedioid and takes the top 3 medioids based on importance, and, given a user\\nquery that is a medioid, performs an approximate nearest neighbors search\\nusing HNSW to find the pins closest to the query in the embedding space.\\n62'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 62, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 46: Pinnersage and Pinsage embeddings-based similarity retrieval\\n5.1.2\\nYouTube and Google Play Store\\nYouTube\\nYouTube was one of the first large companies to publicly share their work on\\nembeddings used in the context of a production recommender system with\\n\"Deep Neural Networks for YouTube Recommendations.\"\\nYouTube has over 800 million pieces of content (videos) and 2.6 billion\\nactive users that they’d like to recommend those videos to. The application\\nneeds to recommend existing content to users, while also generalizing to new\\ncontent, which is uploaded frequently. They need to be able to serve these\\nrecommendations at inference time — when the user loads a new page —\\nwith low latency.\\nIn this paper [11], YouTube shares how they created a two-stage recom-\\nmender system for videos based on two deep learning models. The machine\\nlearning task is to predict the correct next video to show the user at a given\\ntime in YouTube recommendations so that they click. The final output is'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 62, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='learning task is to predict the correct next video to show the user at a given\\ntime in YouTube recommendations so that they click. The final output is\\nformulated as a classification problem: given a user’s input features and the\\ninput features of a video, can we predict a class for the user that includes the\\npredicted watch time for the user for a specific video with a specific probability.\\nFigure 47: YouTube’s end-to-end video recommender system, including a candidate generator\\nand ranker [11]\\n63'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 63, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='We set this task given a user, U and context C32\\nGiven the size of the input corpus, we need to formulate the problem as\\na two-stage recommender: the first is the candidate generator that reduces\\nthe candidate video set to hundreds of items and a second model, similar in\\nsize and shape, called a ranker that ranks these hundreds of videos by the\\nprobability that the user will click on them and watch.\\nThe candidate generator is a softmax deep learning model with several\\nlayers, all activated with ReLU activation functions – rectified linear unit\\nactivation that outputs the input directly if positive; otherwise, it’s zero. The\\nuses both embedded and tabular learning features, all of which are combined\\nand\\nTo build the model, we use two sets of embeddings as input data: one\\nthat’s the user plus context as features, and a set of video items. The model\\nhas several hundreds of features, both tabular and embeddings-based. For the\\nembeddings-based features, we include elements like:'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 63, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='has several hundreds of features, both tabular and embeddings-based. For the\\nembeddings-based features, we include elements like:\\n• User watch history - represented by a vector of sparse video ID elements\\nmapped into a dense vector representation\\n• User’s search history - Maps search term to video clicked from the search\\nterm, also in a sparse vector mapped into the same space as the user\\nwatch history\\n• User’s geography, age, and gender - mapped as tabular features\\n• The number of previous impressions a video had, normalized per user\\nover time\\nThese are all combined into a single item embedding, and in the case of\\nthe user, a single embedding that’s a blended map of all the user embedding\\nfeatures, and fed into the models’ softmax layers, which compare the distance\\nbetween the output of the softmax layer, i.e. the probability that the user will\\nclick on an item, and a set of ground truth items, i.e. a set of items that the user'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 63, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='between the output of the softmax layer, i.e. the probability that the user will\\nclick on an item, and a set of ground truth items, i.e. a set of items that the user\\nhas already interacted with. The log probability of an item is the dot product\\nof two n-dimensional vectors, i.e. the query and item embeddings.\\nWe consider this an example of Implicit feedback - feedback the user did\\nnot explicitly give, such as a rating, but that we can capture in our log data.\\nEach class response, of which there are approximately a million, is given a\\nprobability as output.\\nThe DNN is a generalization of the matrix factorization model we dis-\\ncussed earlier.\\n32In recommender systems, we often think of four relevant items to formulate our recom-\\nmender problem - user, item, context, and query. The context is usually the environment, for\\nexample the time of day or the geography of the user at inference time\\n64'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 64, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 48: YouTube’s multi-step neural network model for video recommendations using\\ninput embeddings [11]\\nGoogle Play App Store\\nSimilar work, although with a different architecture, was done in the App\\nStore in Google Play in \"Wide and Deep Learning for Recommender Systems\"\\n[7]. This one crosses the search and recommendation space because it returns\\ncorrect ranked and personalized app recommendations as the result of a search\\nquery. The input is clickstream data collected when a user visits the app store.\\nFigure 49: Wide and deep [7]\\nThe recommendations problem is formulated here as two jointly-trained\\nmodels. The weights are shared and cross-propagated between the two models\\nbetween epochs.\\nThere are two problems when we try to build models that recommend\\nitems: memorization - the model needs to learn patterns by learning how\\nitems occur together given the historical data, and generalization - the model\\nneeds to be able to give new recommendations the user has not seen before that'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 64, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='items occur together given the historical data, and generalization - the model\\nneeds to be able to give new recommendations the user has not seen before that\\nare still relevant to the user, improving recommendation diversity. Generally,\\none model alone cannot encompass both of these tradeoffs.\\nWide and deep is made up of two models that look to complement each\\nother:\\n65'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 65, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• A wide model which uses traditional tabular features to improve the\\nmodel’s memorization.\\nThis is a general linear model trained on\\nsparse, one-hot encoded features like user_installed_app=netflix\\nacross thousands of apps.\\nMemorization works here by creat-\\ning binary features that are combinations of features, such as\\nAND(user_installed_app=netflix, impression_app_pandora, allow-\\ning us to see different combinations of co-occurrence in relationship\\nto the target, i.e. likelihood to install app Y. However, this model cannot\\ngeneralize if it gets a new value outside of the training data.\\n• A deep model that supports generalization across items that the model\\nhas not seen before, using a feed-forward neural network made up\\nof categorical features that are translated to embeddings, such as user\\nlanguage, device class, and whether a given app has an impression.\\nEach of these embeddings range from 0-100 in dimensionality. They'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 65, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='language, device class, and whether a given app has an impression.\\nEach of these embeddings range from 0-100 in dimensionality. They\\nare combined jointly into a concatenated embedding space with dense\\nvectors in 1200 dimensions. and initialized randomly. The embedding\\nvalues are trained to minimize loss of the final function, which is a\\nlogistic loss function common to the deep and wide model.\\nFigure 50: The deep part of the wide and deep model [7]\\nThe model is trained on 500 billion examples, and evaluated offline using\\nAUC and online using app acquisition rate, the rate at which people download\\nthe app. Based on the paper, using this approach improved the app acquisition\\nrate on the main landing page of the app store by 3.9 % relative to the control\\ngroup.\\n5.1.3\\nTwitter\\nAt Twitter, pre-computed embeddings were a critical part recommendations\\nfor many app surface areas including user onboarding topic interest predic-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 65, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='group.\\n5.1.3\\nTwitter\\nAt Twitter, pre-computed embeddings were a critical part recommendations\\nfor many app surface areas including user onboarding topic interest predic-\\ntion, recommended Tweets, home timeline construction, users to follow, and\\n66'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 66, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='recommended ads.\\nTwitter had a number of embeddings-based models but we’ll cover two\\nprojects here: Twice [44], content embeddings for Tweets, which looks to find\\nrich representations of Tweets that include both text and visual data for use in\\nsurfacing Tweets in the home timeline, Notifications and Topics. Twitter also\\ndeveloped TwHIN [18], Twitter Heterogeneous Information Network, a set\\nof graph-based embeddings [18], developed for tasks like personalized ads\\nrankings, account follow-recommendation, offensive content detection, and\\nsearch ranking, based on nodes (such as users and advertisers) and edges that\\nrepresent entity interactions.\\nFigure 51: Twitter’s Twice Embeddings, a trained BERT model [44]\\nTwice is a BERT model trained from scratch on an input corpus of 200\\nmillion Tweets that users engaged with sampled over 90 days and also includes\\nassociations to the users themselves. The objective of the model is to optimize'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 66, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='million Tweets that users engaged with sampled over 90 days and also includes\\nassociations to the users themselves. The objective of the model is to optimize\\non several tasks: topic prediction (aka the topic associated with a Tweet, of\\nwhich there could be multiple), engagement prediction (the likelihood a user\\nis to engage with a Tweet), and language prediction to cluster Tweets of the\\nsame language to be clustered closer together.\\nTwHIN, rather than just focusing on Tweet content, considers all entities in\\nTwitter’s environment (Tweets, users, advertiser entities) as belong together\\nin a joint embedding space graph.\\nJoint embedding is performed by using data from user-Tweet engagement,\\nadvertising, and following data, to create multi-model embeddings. TWHin\\nis used for candidate generation. The candidate generator finds users to\\nfollow or Tweets to engage with an HNSW or Faiss to retrieve candidate items.\\nTWHin embeddings are then used to query candidate items and increase'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 66, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='follow or Tweets to engage with an HNSW or Faiss to retrieve candidate items.\\nTWHin embeddings are then used to query candidate items and increase\\ndiversity in the candidate pool.\\n67'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 67, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 52: Twitter’s model of the app’s heterogeneous information network [18]\\nEmbeddings at Flutter\\nOnce we synthesize enough of these architectures, we see some patterns\\nstart to emerge that we can think about adapting for developing our relevant\\nrecommendation system at Flutter.\\nFirst, we need a great deal of input data to make accurate predictions\\nfrom, and that data should have information about either explicit, or, more\\nlikely, implicit data like user clicks and purchases so that we can construct our\\nmodel of user preferences. The reason we need a lot of data is two-fold. First,\\nneural networks are data-hungry and require a large amount of training data\\nto correctly infer relationships in comparison to traditional models. Second,\\nlarge data requires a large pipeline.\\nIf we don’t have a lot of data, a simpler model will work well-enough,\\nso we need to make sure we are actually at the scale where embeddings\\nand neural networks help our business problem. It’s likely the case that we'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 67, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='so we need to make sure we are actually at the scale where embeddings\\nand neural networks help our business problem. It’s likely the case that we\\ncan start much simpler. And in fact, a recent paper by one of the original\\nresearchers who developed factorization machines, an important approach\\nin recommendations, argues that simple dot products found as the result of\\nmatrix factorization outperform neural networks [52]. Second, in order to get\\ngood embeddings, we will need to spend a great deal of time cleaning and\\nprocessing data and creating features, as we did in the YouTube paper, so the\\noutcome has to be worth the time spent.\\nSecond, we need to be able to understand the latent relationship between\\nusers and items they’ve interacted with. In traditional recommenders, we\\ncould use TF-IDF to find the weighted word features as part of a particular flit\\nand compare across documents, as long as our corpus doesn’t grow too large.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 67, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='could use TF-IDF to find the weighted word features as part of a particular flit\\nand compare across documents, as long as our corpus doesn’t grow too large.\\nIn more advanced recommendation systems, we could perform this same task\\nby looking at either naive association rules, or framing recommendation as\\nan interaction-based collaborative filtering problem not unlike Word2Vec to\\ngenerate latent features, aka embeddings, of our users and items. In fact, this\\n68'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 68, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='is exactly what Levy and Goldberg argued in \"Neural Word Embedding as Im-\\nplicit Matrix Factorization\" [43]. They looked at the skipgram implementation\\nof Word2Vec and found that implicitly it factors a word-context matrix.\\nWe could alternatively still use tabular features as input into our collabo-\\nrative filtering problem but use a neural network [28] instead of simple dot\\nproduct to converge on the correct relationships and the downstream ranking\\nfor the model.\\nGiven our new knowledge about how embeddings and recommender sys-\\ntems work, we can now incorporate embeddings into the recommendations\\nwe serve for flits at Flutter. If we want to recommend relevant content, we\\nmight do it in a number of different ways, depending on our business require-\\nments. In our corpus, we have hundreds of millions of messages that we need\\nto filter down to hundreds to show the user. So we can start with a baseline of\\nWord2Vec or similar and move on to any of the BERT or other neural network'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 68, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='to filter down to hundreds to show the user. So we can start with a baseline of\\nWord2Vec or similar and move on to any of the BERT or other neural network\\napproaches to developing model input features, vector similarity search, and\\nranking, through the power of embeddings.\\nEmbeddings are endlessly flexible and endlessly useful, and can empower\\nand improve the performance of our multimodal machine learning workflows.\\nHowever, as we just saw, there are some things to keep in mind if we do\\ndecide to use them.\\n5.2\\nEmbeddings as an Engineering Problem\\nIn general, machine learning workflows add an enormous amount of com-\\nplexity and overhead to our engineering systems, for a number of reasons\\n[57]. First, they blend data that then needs to be monitored for drift down-\\nstream. Second, they are non-deterministic in their outputs, which means they\\nneed to be tracked extremely carefully as artifacts, since we generally don’t'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 68, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='stream. Second, they are non-deterministic in their outputs, which means they\\nneed to be tracked extremely carefully as artifacts, since we generally don’t\\nversion-control data. Third, they result in processing pipeline jungles.\\nAs a special case of glue code, pipeline jungles often appear in\\ndata preparation. These can evolve organically, as new signals are\\nidentified and new information sources added. Without care, the\\nresulting system for preparing data in an ML-friendly format may\\nbecome a jungle of scrapes, joins, and sampling steps, often with\\nintermediate files output.\\nAs we can see from several system diagrams, including PinnerSage and\\nthe Wide and Deep Model, recommender systems in production utilizing\\nembeddings have many moving components.\\n69'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 69, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 53: PinnerSage model archi-\\ntecture [50]\\nFigure 54: Wide and Deep model\\narchitecture [7]\\nYou may recall that we discussed the simple stages of a recommender\\nsystem in this diagram.\\nFigure 55: Generic system processing embeddings in context\\nGiven all of our production-level requirements for a successful recom-\\nmendation system, our actual production system generally looks more like\\nthis:\\n• Generating embeddings\\n• Storing embeddings\\n• Embedding feature engineering and iteration\\n• Artifact retrieval\\n• updating embeddings\\n• versioning embeddings and data drift\\n• Inference and latency\\n• Online (A/B test) and offline (metric sweep) model evaluation\\nGiven all of our concern space, the diagram of any given production\\nsystem would look more like this\\n70'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 70, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Figure 56: Recommender systems as a machine learning problem\\n5.2.1\\nEmbeddings Generation\\nWe’ve already seen that embeddings are usually generated as a byproduct of\\ntraining neural network models, most often the penultimate layer that’s used\\nbefore a layer to classify or regress is added as the final output. We have two\\nways to build them. We can train our own models, as YouTube, Pinterest, and\\nTwitter have done. In the LLM space, there is also growing interest in being\\nable to train large language models in-house.\\nHowever, one of the large benefits of deep learning models is that we\\ncan also use pre-trained model. A pretrained model is any model that’s like\\nthe one we’re considering for our task that has already been trained on an\\nenormous corpus of training data, and can be used for downstream tasks.\\nBERT is an example of a model that has already been pre-trained and can\\nbe used for any number of machine learning tasks through the process of'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 70, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='BERT is an example of a model that has already been pre-trained and can\\nbe used for any number of machine learning tasks through the process of\\nfine-tuning. In fine-tuning, we take a model that’s already been pre-trained\\non a generic dataset. For example, BERT was trained on BookCorpus, a set of\\n11k books with 800 million words and English Wikipedia, 2.5 billion words.\\nAn aside on training data\\nTraining data is the most important part of any given model. Where does it\\ncome from for pre-trained large language models? Usually scraping large\\nparts of the internet. In the interest of competitive advantage, how these\\ntraining datasets are put together is usually not revealed, and there is a\\nfair amount of reverse-engineering and speculation. For example, \"What’s\\nin my AI\" goes into the training data behind the GPT series of models\\nand finds that GPT-3 was trained on Books1 and Books2. Books1 is likely\\nbookcorpus and books2 is likely libgen. GPT also includes the Common'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 70, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='and finds that GPT-3 was trained on Books1 and Books2. Books1 is likely\\nbookcorpus and books2 is likely libgen. GPT also includes the Common\\nCrawl, a large open-source dataset of indexed websites, WebText2, and\\nWikipedia. This information is important because when we pick a model\\n71'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 71, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='we need to at least understand at a high level what it was trained on to\\nbe a general-purpose model so we can explain what changes when we\\nfine-tune it.\\nIn fine-tuning a model, we perform all the same steps as we do for training\\nfrom scratch. We have training data, we have a model, and we minimize a\\nloss function. However, there are several differences. When we create our\\nnew model, we copy the existing, pre-trained model with the exception of\\nthe final output layer, which we initialize from scratch based on our new task.\\nWhen we train the model, we initialize these parameters at random and only\\ncontinue to adjust the parameters of the previous layers so that they focus on\\nthis task rather than starting to train from scratch. In this way, if we have a\\nmodel like BERT that’s trained to generalize across the whole internet, but our\\ncorpus for Flutter is very sensitive to trending topics and needs to be updated\\non a daily basis, we can refocus the model without having to train a new one'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 71, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='corpus for Flutter is very sensitive to trending topics and needs to be updated\\non a daily basis, we can refocus the model without having to train a new one\\nwith as few as 10k samples instead of our original hundreds of millions [74].\\nThere are, likewise, BERT embeddings available that we can fine-tune.\\nThere are other generalized corpuses available, such as GloVE, Word2Vec, and\\nFastText (also trained with CBOW). We need to make a decision whether to\\nuse these, train a model from scratch, or a third option, to query embeddings\\navailable from an API as is the case for OpenAI embeddings, although doing\\nso can potentially come at a higher cost, relative to training or fine-tuning our\\nown. Of course, all of this is subject to our particular use-case and is important\\nto evaluate when we start a project.\\n5.2.2\\nStorage and Retrieval\\nOnce we’ve trained our model, we’ll need to extract the embeddings from\\nthe trained object. Generally, when a model is trained, the resulting output is'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 71, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='5.2.2\\nStorage and Retrieval\\nOnce we’ve trained our model, we’ll need to extract the embeddings from\\nthe trained object. Generally, when a model is trained, the resulting output is\\na data structure that contains all the parameters of the model, including the\\nmodel’s weights, biases, layers and learning rate. The embeddings are part of\\nthis model object as a layer, and they initially live in-memory. When we write\\nthe model to disk, we propagate them as a model object, which is serialized\\nonto memory and loaded at re-training or inference time.\\nThe simplest form of embedding store can be an in-memory numpy ar-\\nray33.\\nBut if we are iterating on building a model with embeddings, we want to\\nbe able to do a number of things with them:\\n• Access them in batch and one-by-one at inference time\\n• Perform offline analysis on the quality of the embeddings\\n• Embedding feature engineering\\n• Update embeddings with new models\\n• Version embeddings\\n• Encode new embeddings for new documents'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 71, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='• Perform offline analysis on the quality of the embeddings\\n• Embedding feature engineering\\n• Update embeddings with new models\\n• Version embeddings\\n• Encode new embeddings for new documents\\n33From a Tweet by Andrej Karpathy in response to how he stores vector embeddings for a\\nsmall movie recommendations side project in 2023,\"np.array people keep reaching for much\\nfancier things way too fast these days. Tweet\\n72'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 72, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='The most complex and customizable software that handles many of these\\nuse-cases is a vector database, and somewhere in-between vector databases\\nand in-memory storage are vector search plugins for existing stores like Post-\\ngres and SQLite, and caches like Redis.\\nThe most important operation we’d like to perform with embeddings is\\nvector search, which allows us to find embeddings that are similar to a given\\nembedding so we can return item similarity. If we want to search embeddings,\\nwe need a mechanism that is optimized to search through our matrix data\\nstructures and perform nearest-neighbor comparisons in the same way that\\na traditional relational database is optimized to search row-based relations.\\nRelational databases use a b-tree structure to optimize reads by sorting items\\nin ascending order within a hierarchy of nodes, built on top of an indexed\\ncolumn in the database. We can’t perform columnar lookups on our vectors'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 72, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='in ascending order within a hierarchy of nodes, built on top of an indexed\\ncolumn in the database. We can’t perform columnar lookups on our vectors\\nefficiently, so we need to create different structures for them. For example,\\nmany vector stores are based on inverted indices.\\nA general-form embeddings store contains the embeddings themselves, an\\nindex to map them back from the latent space into words, pictures, or text, and\\na way to do similarity comparisons between different types of embeddings\\nusing various nearest neighbors algorithms. We talked before about cosine\\nsimilarity as a staple of comparing latent space representations. This can be-\\ncome computationally expensive over millions of sets of vectors, because we’d\\nneed to do a pairwise comparison over every pair. To solve this, approximate\\nnearest neighbors (ANN) algorithms were developed to, as in recommender\\nsystems, create neighborhoods out of elements of vectors and find a vector’s'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 72, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='nearest neighbors (ANN) algorithms were developed to, as in recommender\\nsystems, create neighborhoods out of elements of vectors and find a vector’s\\nk-nearest neighbors. The most frequently-used algorithms include HNSW\\n(hierarchical navigable small worlds) and Faiss, both of which are standalone\\nlibraries and also implemented as part of many existing vector stores.\\nThe trade-off between full and nearest neighbor search is that the latter is\\nless precise, but it’s much faster. When we switch between precision and recall\\nin evaluation, we need to be aware of the tradeoffs and think about what our\\nrequirements are with respect to how accurate our embeddings are and their\\ninference latency.\\nHere’s an example of the embeddings storage system that Twitter built for\\nexactly this use case, long before vector databases came into the picture. [62].\\nFigure 57: Twitter’s embeddings pipeline [62]\\n73'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 73, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Given that Twitter uses embeddings in multiple sources as described in\\nthe previous section, Twitter made embeddings \"first class citizens\" by creat-\\ning a centralized platform that reprocesses data and generates embeddings\\ndownstream into the feature registry.\\n5.2.3\\nDrift Detection, Versioning, and Interpretability\\nOnce we’ve trained embeddings, we might think we’re done. But embeddings,\\nlike any machine learning pipeline, need to be refreshed because we might\\nrun into concept drift. Concept drift occurs when the data underlying our\\nmodel changes. For example, let’s say that our model includes, as a binary\\nfeature, people who have landlines or not. In 2023, this would no longer be as\\nrelevant of a feature in most of the world as most people have switched to cell\\nphones as their primary telephones, so the model would lose accuracy.\\nThis phenomenon is even more prevalent with embeddings that are used\\nfor classification. For example, let’s say we use embeddings for trending topic'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 73, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='This phenomenon is even more prevalent with embeddings that are used\\nfor classification. For example, let’s say we use embeddings for trending topic\\ndetection. The model has to generalize, as in the wide and deep model, to\\ndetect new classes, but if our classes change quickly, it may not be able to, so\\nwe need to retrain your embeddings frequently. Or, for example, if we model\\nembeddings in a graph, as Pinterest does, and the relationships between nodes\\nin the graph change, we may have to update them [69]. We could also have an\\ninflux of spam or corrupted content which changes the relationship in your\\nembeddings, in which case we’ll need to retrain.\\nEmbeddings can be hard to understand (so hard that some people have\\neven written entire papers about them) and harder to interpret. What does it\\nmean for a king to be close to queen but far away from the knight? What does\\nit mean for two flits to be close to each other in a projected embedding space?'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 73, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='mean for a king to be close to queen but far away from the knight? What does\\nit mean for two flits to be close to each other in a projected embedding space?\\nWe have two ways we can think about this, intrinsic and extrinsic evalua-\\ntion. For the embeddings themselves (extrinsic evaluation), we can visualize\\nthem through either UMAP—Uniform Manifold Approximation and Projec-\\ntion for Dimension Reduction or t-sne — t-distributed stochastic neighbor\\nembedding, algorithms that allow us to visualize highly-dimensional data in\\ntwo or three dimensions, much like PCA. Or we can fit embeddings into our\\ndownstream task (for example, summarization, or classification), and analyze\\nthe same way we would with offline metrics. There are many different ap-\\nproaches [67] but the summary is that embeddings can be objectively hard to\\nevaluate and we’ll need to factor the time to perform this evaluation into our\\nmodeling time.\\nOnce we retrain our initial baseline model, we now have a secondary issue:'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 73, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='evaluate and we’ll need to factor the time to perform this evaluation into our\\nmodeling time.\\nOnce we retrain our initial baseline model, we now have a secondary issue:\\nhow do we compare the first set of embeddings to the second; that is, how do\\nwe evaluate whether they are good representations of our data, given the case\\nthat embeddings are often unsupervised; i.e. — how do we know whether\\n\"king\" should be close to \"queen\"? On their own, as a first-pass, embeddings\\ncan be hard to interpret, because in a multidimensional space it’s hard to\\nunderstand which dimension of a vector corresponds to a decision to place\\nitems next to each other [63]. When compared to other sets of embeddings,\\nwe might use the offline metrics of the final model task, precision and recall,\\nor we could measure the distance of the distribution of the embeddings in the\\n74'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 74, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='latent space by comparing the statistical distance between the two probability\\ndistributions using a metric known as Kullback–Leibler divergence.\\nFinally, now let’s say that we have two sets of embeddings, you need to\\nversion them and keep both sets so that, in case your new model doesn’t work\\nas well, you can fall back to the old one. This goes hand-in-hand with the\\nproblem of model versioning in ML operations, except in this case we need to\\nboth version the model and the output data.\\nThere are numerous different approaches to model and data versioning\\nthat involve building a system that tracks both the metadata and the location\\nof the assets that are kept in a secondary data store. Another thing to keep in\\nmind is that embedding layers, particularly for large vocabularies, can balloon\\nin size, so now we have to consider storage costs, as well.\\n5.2.4\\nInference and Latency\\nWhen working with embeddings, we are operating not only in a theoretical,'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 74, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='in size, so now we have to consider storage costs, as well.\\n5.2.4\\nInference and Latency\\nWhen working with embeddings, we are operating not only in a theoretical,\\nbut practical engineering environment. The most critical engineering part of\\nany machine learning system that works in production is inference time —\\nhow quickly does it take to query the model asset and return a result to an\\nend-user.\\nFor this, we care about latency, which we can roughly define as any time\\nspent waiting and is a critical performance metric in any production system\\n[26]. Generally speaking, it’s the time of any operation to complete – appli-\\ncation request, database query, and so on. Latency at the level of the web\\nservice is generally measured in milliseconds, and every effort is made to\\nreduce this as close to zero as realistically possible. For use-cases like search\\nand loading a feed of content, the experience needs to be instantaneous or the'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 74, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='reduce this as close to zero as realistically possible. For use-cases like search\\nand loading a feed of content, the experience needs to be instantaneous or the\\nuser experience will degrade and we could even lose revenue. In a study from\\na while back, Amazon found that every 100ms increase in latency cuts profits\\nby 1% [19].\\nGiven this, we need to think about how to reduce the footprint of our\\nmodel and all the layers in serving it so that the response to the user is\\ninstantaneous. We do this by creating observability throughout our machine\\nlearning system, starting with the hardware the system is running on, to\\nCPU and GPU utilization, the performance of our model architecture, and\\nhow that model interacts with other components. For example, when we are\\nperforming nearest neighbor lookup, the way we perform that lookup and the\\nalgorithm we use, the programming language we use to write that algorithm,\\nall compound latency concerns.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 74, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='performing nearest neighbor lookup, the way we perform that lookup and the\\nalgorithm we use, the programming language we use to write that algorithm,\\nall compound latency concerns.\\nAs an example, in the wide and deep paper, the recommender ranking\\nmodel scores over 10 million apps per second. The application was initially\\nsingle-threaded, with all candidates taking 31 milliseconds. By implementing\\nmultithreading, they were able to reduce client-side latency to 14 milliseconds\\n[7].\\nOperations of machine learning systems is an entirely other art and craft\\nof study and one that’s best left for another paper [37].\\n75'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 75, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='5.2.5\\nOnline and Offline Model Evaluation\\nWe’ve barely scratched the surface of one of the most critical parts of a model:\\nhow it performs in offline and online testing. When we talk about offline tests,\\nwe mean analyzing the statistical properties of a model to learn whether the\\nmodel is a valid model - i.e. does our loss function converge? Does the model\\noverfit or underfit? What is the precision and recall? Do we experience any\\ndrift? If it’s a recommendation ranker model, are we using metrics like NDCG\\n—normalized discounted cumulative gain— to understand whether our new\\nmodel ranks items better than the previous iteration?\\nThen, there is online evaluation, aka how successful the model actually\\nis in the production context. Usually, this is evaluated through A/B testing\\nwhere one set of users gets the old model or system and a holdout set of users\\ngets the new system, and looking at the statistical significance of metrics like'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 75, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='where one set of users gets the old model or system and a holdout set of users\\ngets the new system, and looking at the statistical significance of metrics like\\nclick-through rate, items served, and time spent on a given area of the site.\\n5.2.6\\nWhat makes embeddings projects successful\\nFinally, once we have all our algorithmic and engineering concerns lined up,\\nthere is the final matter to consider of what will make our project successful\\nfrom a business perspective. We should acknowledge that we might not\\nalways need embeddings for our machine learning problem, or that we might\\nnot need machine learning at all, initially, if our project is based entirely on a\\nhandful of heuristic rules that can be determined and analyzed by humans\\n[76].\\nIf we conclude that we are operating in a data-rich space where automati-\\ncally inferring semantic relationships between entities is correct, we need to\\nask ourselves if we’re willing to put in a great deal of effort into producing'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 75, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='cally inferring semantic relationships between entities is correct, we need to\\nask ourselves if we’re willing to put in a great deal of effort into producing\\nclean datasets, the baseline of any good machine learning model, even in cases\\nof large language models. In fact, clean, domain data is so important that\\nmany of the companies discussed here ended up training their own embed-\\ndings models, and, recently companies like Bloomberg [70] and Replit [59] are\\neven training their own large language models to improve accuracy for their\\nspecific business domain.\\nCritically, to get to a stage where we have a machine learning system\\ndealing with embeddings, we need a team that has multilevel alignment\\naround the work that needs to be done. In larger companies, the size of this\\nteam will be larger, but most specifically work with embeddings requires\\nsomeone who can speak to the use case specifically, someone who advocates'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 75, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='team will be larger, but most specifically work with embeddings requires\\nsomeone who can speak to the use case specifically, someone who advocates\\nfor the use case and gets it prioritized, and a technical person who can do the\\nwork [46].\\nIf all of these components come together, we now have an embeddings-\\nbased recommender system in production.\\n6\\nConclusion\\nWe have now walked through an end-to-end example of what embeddings\\nare. We started with a high-level overview of how embeddings fit into the\\n76'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 76, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='context of a machine learning application. We then did a deep dive on early\\napproaches to encoding, built up intuition of embeddings in Word2Vec and\\nthen moving on to transformers and BERT. Although reducing dimensionality\\nas a concept has always been important in machine learning systems to de-\\ncrease computational and storage complexity, compression has become even\\nmore important in the modern explosion of multimodal representations of\\ndata that comes from application log files, images, video, and audio, and the\\nexplosion of Transformer, generative, and diffusion models, combined with\\nthe cheap storage and explosion of data, has amended itself to architectures\\nwhere embeddings are used more and more.\\nWe’ve understood the engineering context of why we might include ma-\\nchine learning models in our application, how they work, how to incorporate\\nthem, and where embeddings —dense representations of deep learning model'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 76, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='chine learning models in our application, how they work, how to incorporate\\nthem, and where embeddings —dense representations of deep learning model\\ninput and output data – can be best leveraged. Embeddings are a powerful\\ntool in any machine learning system, but one that comes at a cost of mainte-\\nnance and interpretability. Generating embeddings using the correct method,\\nwith the correct metrics and hardware and software, is a project that takes con-\\nsiderable thought. We now hopefully have a solid grasp of the fundamentals\\nof embedding and can either leverage them – or explain why not to –in our\\nnext project. Good luck navigating embeddings, see you in the latent space!\\n77'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 77, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='References\\n1. Gabriel\\nAltay.\\nCategorical\\nvariables\\nin\\ndecision\\ntrees,\\nMar\\n2020. URL https://www.kaggle.com/code/gabrielaltay/categorical-\\nvariables-in-decision-trees.\\n2. Ioannis Arapakis, Xiao Bai, and B Barla Cambazoglu. Impact of response\\nlatency on user behavior in web search. In Proceedings of the 37th inter-\\nnational ACM SIGIR conference on Research & development in information\\nretrieval, pages 103–112, 2014.\\n3. Remzi H Arpaci-Dusseau and Andrea C Arpaci-Dusseau. Operating sys-\\ntems: Three easy pieces. Arpaci-Dusseau Books, LLC, 2018.\\n4. Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation\\nlearning: A review and new perspectives. IEEE transactions on pattern\\nanalysis and machine intelligence, 35(8):1798–1828, 2013.\\n5. Pablo Castells and Dietmar Jannach. Recommender systems: A primer.\\narXiv preprint arXiv:2302.02579, 2023.\\n6. Dhivya Chandrasekaran and Vijay Mago. Evolution of semantic similar-\\nity—a survey. ACM Computing Surveys (CSUR), 54(2):1–37, 2021.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 77, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='arXiv preprint arXiv:2302.02579, 2023.\\n6. Dhivya Chandrasekaran and Vijay Mago. Evolution of semantic similar-\\nity—a survey. ACM Computing Surveys (CSUR), 54(2):1–37, 2021.\\n7. Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar\\nChandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai,\\nMustafa Ispir, et al. Wide & deep learning for recommender systems.\\nIn Proceedings of the 1st workshop on deep learning for recommender systems,\\npages 7–10, 2016.\\n8. Francois Chollet. Deep learning with Python. Simon and Schuster, 2021.\\n9. Ronan Collobert and Jason Weston. A unified architecture for natural\\nlanguage processing: Deep neural networks with multitask learning. In\\nProceedings of the 25th international conference on Machine learning, pages\\n160–167, 2008.\\n10. Yingnan Cong, Yao-ban Chan, and Mark A Ragan. A novel alignment-free\\nmethod for detection of lateral genetic transfer based on tf-idf. Scientific\\nreports, 6(1):1–13, 2016.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 77, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='160–167, 2008.\\n10. Yingnan Cong, Yao-ban Chan, and Mark A Ragan. A novel alignment-free\\nmethod for detection of lateral genetic transfer based on tf-idf. Scientific\\nreports, 6(1):1–13, 2016.\\n11. Paul Covington, Jay Adams, and Emre Sargin. Deep neural networks for\\nyoutube recommendations. In Proceedings of the 10th ACM conference on\\nrecommender systems, pages 191–198, 2016.\\n12. Toni Cvitanic, Bumsoo Lee, Hyeon Ik Song, Katherine Fu, and David\\nRosen. Lda v. lsa: A comparison of two computational text analysis tools\\nfor the functional categorization of patents. In International Conference on\\nCase-Based Reasoning, 2016.\\n13. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert:\\nPre-training of deep bidirectional transformers for language understand-\\ning. arXiv preprint arXiv:1810.04805, 2018.\\n78'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 78, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='14. Giovanni Di Gennaro, Amedeo Buonanno, and Francesco AN Palmieri.\\nConsiderations about learning word2vec. The Journal of Supercomputing,\\npages 1–16, 2021.\\n15. Author Cory Doctorow.\\nPluralistic: Tiktok’s enshittification (21 jan\\n2023), Feb 2023. URL https://pluralistic.net/2023/01/21/potemkin-\\nai/#hey-guys.\\n16. Melody Dye, Chaitanya Ekandham, Avneesh Saluja, and Ashish Ras-\\ntogi.\\nSupporting content decision makers with machine learning,\\nDec 2020.\\nURL https://netflixtechblog.com/supporting-content-\\ndecision-makers-with-machine-learning-995b7b76006f.\\n17. Michael D Ekstrand and Joseph A Konstan. Recommender systems nota-\\ntion: proposed common notation for teaching and research. arXiv preprint\\narXiv:1902.01348, 2019.\\n18. Ahmed El-Kishky, Thomas Markovich, Serim Park, Chetan Verma, Baekjin\\nKim, Ramy Eskander, Yury Malkov, Frank Portman, Sofía Samaniego,\\nYing Xiao, et al. Twhin: Embedding the twitter heterogeneous information'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 78, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Kim, Ramy Eskander, Yury Malkov, Frank Portman, Sofía Samaniego,\\nYing Xiao, et al. Twhin: Embedding the twitter heterogeneous information\\nnetwork for personalized recommendation. In Proceedings of the 28th\\nACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages\\n2842–2850, 2022.\\n19. Tobias Flach, Nandita Dukkipati, Andreas Terzis, Barath Raghavan, Neal\\nCardwell, Yuchung Cheng, Ankur Jain, Shuai Hao, Ethan Katz-Bassett,\\nand Ramesh Govindan. Reducing web latency: the virtue of gentle aggres-\\nsion. In Proceedings of the ACM SIGCOMM 2013 conference on SIGCOMM,\\npages 159–170, 2013.\\n20. Martin Fowler. Patterns of Enterprise Application Architecture: Pattern Enterpr\\nApplica Arch. Addison-Wesley, 2012.\\n21. Jan J Gerbrands. On the relationships between svd, klt and pca. Pattern\\nrecognition, 14(1-6):375–381, 1981.\\n22. David Goldberg, David Nichols, Brian M Oki, and Douglas Terry. Using\\ncollaborative filtering to weave an information tapestry. Communications'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 78, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='recognition, 14(1-6):375–381, 1981.\\n22. David Goldberg, David Nichols, Brian M Oki, and Douglas Terry. Using\\ncollaborative filtering to weave an information tapestry. Communications\\nof the ACM, 35(12):61–70, 1992.\\n23. Yoav Goldberg and Omer Levy. word2vec explained: deriving mikolov\\net al.’s negative-sampling word-embedding method.\\narXiv preprint\\narXiv:1402.3722, 2014.\\n24. Raul Gomez Bruballa, Lauren Burnham-King, and Alessandra Sala. Learn-\\ning users’ preferred visual styles in an image marketplace. In Proceedings\\nof the 16th ACM Conference on Recommender Systems, pages 466–468, 2022.\\n25. Mihajlo Grbovic and Haibin Cheng. Real-time personalization using\\nembeddings for search ranking at airbnb. In Proceedings of the 24th ACM\\nSIGKDD international conference on knowledge discovery & data mining, pages\\n311–320, 2018.\\n79'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 79, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='26. Brendan Gregg. Systems performance: enterprise and the cloud. Pearson\\nEducation, 2014.\\n27. Casper Hansen, Christian Hansen, Lucas Maystre, Rishabh Mehrotra,\\nBrian Brost, Federico Tomasi, and Mounia Lalmas. Contextual and sequen-\\ntial user embeddings for large-scale music recommendation. In Proceedings\\nof the 14th ACM Conference on Recommender Systems, pages 53–62, 2020.\\n28. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and\\nTat-Seng Chua. Neural collaborative filtering. In Proceedings of the 26th\\ninternational conference on world wide web, pages 173–182, 2017.\\n29. Michael E Houle, Hans-Peter Kriegel, Peer Kröger, Erich Schubert, and\\nArthur Zimek. Can shared-neighbor distances defeat the curse of dimen-\\nsionality? In Scientific and Statistical Database Management: 22nd Interna-\\ntional Conference, SSDBM 2010, Heidelberg, Germany, June 30–July 2, 2010.\\nProceedings 22, pages 482–500. Springer, 2010.\\n30. Dietmar Jannach, Markus Zanker, Alexander Felfernig, and Gerhard'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 79, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='tional Conference, SSDBM 2010, Heidelberg, Germany, June 30–July 2, 2010.\\nProceedings 22, pages 482–500. Springer, 2010.\\n30. Dietmar Jannach, Markus Zanker, Alexander Felfernig, and Gerhard\\nFriedrich. Recommender systems: an introduction. Cambridge University\\nPress, 2010.\\n31. Yushi Jing, David Liu, Dmitry Kislyuk, Andrew Zhai, Jiajing Xu, Jeff\\nDonahue, and Sarah Tavel. Visual search at pinterest. In Proceedings of\\nthe 21th ACM SIGKDD International Conference on Knowledge Discovery and\\nData Mining, pages 1889–1898, 2015.\\n32. Thorsten Joachims. Text categorization with support vector machines:\\nLearning with many relevant features. In Machine Learning: ECML-98: 10th\\nEuropean Conference on Machine Learning Chemnitz, Germany, April 21–23,\\n1998 Proceedings, pages 137–142. Springer, 2005.\\n33. Andrej Karpathy. The unreasonable effectiveness of recurrent neural\\nnetworks, May 2015. URL https://karpathy.github.io/2015/05/21/\\nrnn-effectiveness/.\\n34. P.N. Klein.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 79, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='33. Andrej Karpathy. The unreasonable effectiveness of recurrent neural\\nnetworks, May 2015. URL https://karpathy.github.io/2015/05/21/\\nrnn-effectiveness/.\\n34. P.N. Klein.\\nCoding the Matrix: Linear Algebra Through Applications to\\nComputer Science. Newtonian Press, 2013. ISBN 9780615880990. URL\\nhttps://books.google.com/books?id=3AA4nwEACAAJ.\\n35. Martin Kleppmann. Designing data-intensive applications: The big ideas\\nbehind reliable, scalable, and maintainable systems. \" O’Reilly Media, Inc.\",\\n2017.\\n36. Jay Kreps. I heart logs: Event data, stream processing, and data integration. \"\\nO’Reilly Media, Inc.\", 2014.\\n37. Dominik Kreuzberger, Niklas Kühl, and Sebastian Hirschl.\\nMachine\\nlearning operations (mlops): Overview, definition, and architecture. arXiv\\npreprint arXiv:2205.02302, 2022.\\n38. Giorgi Kvernadze, Putu Ayu G Sudyanti, Nishan Subedi, and Mohammad\\nHajiaghayi. Two is better than one: Dual embeddings for complementary\\nproduct recommendations. arXiv preprint arXiv:2211.14982, 2022.\\n80'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 80, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='39. Valliappa Lakshmanan, Sara Robinson, and Michael Munn.\\nMachine\\nlearning design patterns. O’Reilly Media, 2020.\\n40. Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-\\nbased learning applied to document recognition. Proceedings of the IEEE,\\n86(11):2278–2324, 1998.\\n41. Yann LeCun, Yoshua Bengio, Geoffrey Hinton, et al. Deep learning. nature,\\n521 (7553), 436-444. Google Scholar Google Scholar Cross Ref Cross Ref, page 25,\\n2015.\\n42. Jure Leskovec, Anand Rajaraman, and Jeffrey David Ullman. Mining of\\nmassive data sets. Cambridge university press, 2020.\\n43. Omer Levy and Yoav Goldberg. Neural word embedding as implicit\\nmatrix factorization. Advances in neural information processing systems, 27,\\n2014.\\n44. Xianjing Liu, Behzad Golshan, Kenny Leung, Aman Saini, Vivek Kulkarni,\\nAli Mollahosseini, and Jeff Mo. Twice-twitter content embeddings. In\\nCIKM 2022, 2022.\\n45. Donella H Meadows. Thinking in systems: A primer. chelsea green publish-\\ning, 2008.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 80, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Ali Mollahosseini, and Jeff Mo. Twice-twitter content embeddings. In\\nCIKM 2022, 2022.\\n45. Donella H Meadows. Thinking in systems: A primer. chelsea green publish-\\ning, 2008.\\n46. Doug Meil. Ai in the enterprise. Communications of the ACM, 66(6):6–7,\\n2023.\\n47. Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient\\nestimation of word representations in vector space.\\narXiv preprint\\narXiv:1301.3781, 2013.\\n48. Usman Naseem, Imran Razzak, Shah Khalid Khan, and Mukesh Prasad.\\nA comprehensive survey on word representation models: From classical\\nto state-of-the-art word representation language models. Transactions on\\nAsian and Low-Resource Language Information Processing, 20(5):1–35, 2021.\\n49. Bogdan Oancea, Tudorel Andrei, and Raluca Mariana Dragoescu. Gpgpu\\ncomputing. arXiv preprint arXiv:1408.6923, 2014.\\n50. Aditya Pal, Chantat Eksombatchai, Yitong Zhou, Bo Zhao, Charles Rosen-\\nberg, and Jure Leskovec. Pinnersage: Multi-modal user embedding frame-'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 80, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='computing. arXiv preprint arXiv:1408.6923, 2014.\\n50. Aditya Pal, Chantat Eksombatchai, Yitong Zhou, Bo Zhao, Charles Rosen-\\nberg, and Jure Leskovec. Pinnersage: Multi-modal user embedding frame-\\nwork for recommendations at pinterest. In Proceedings of the 26th ACM\\nSIGKDD International Conference on Knowledge Discovery & Data Mining,\\npages 2311–2320, 2020.\\n51. Delip Rao and Brian McMahan. Natural language processing with PyTorch:\\nbuild intelligent language applications using deep learning. \" O’Reilly Media,\\nInc.\", 2019.\\n52. Steffen Rendle, Walid Krichene, Li Zhang, and John Anderson. Neural\\ncollaborative filtering vs. matrix factorization revisited. In Proceedings of\\nthe 14th ACM Conference on Recommender Systems, pages 240–248, 2020.\\n81'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 81, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='53. David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning\\nrepresentations by back-propagating errors. nature, 323(6088):533–536,\\n1986.\\n54. Alexander M Rush. The annotated transformer. In Proceedings of workshop\\nfor NLP open source software (NLP-OSS), pages 52–60, 2018.\\n55. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh,\\nSean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bern-\\nstein, et al. Imagenet large scale visual recognition challenge. International\\njournal of computer vision, 115:211–252, 2015.\\n56. Hinrich Schütze, Christopher D Manning, and Prabhakar Raghavan. In-\\ntroduction to information retrieval, volume 39. Cambridge University Press\\nCambridge, 2008.\\n57. David Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips,\\nDietmar Ebner, Vinay Chaudhary, and Michael Young. Machine learning:\\nThe high interest credit card of technical debt.(2014), 2014.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 81, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Dietmar Ebner, Vinay Chaudhary, and Michael Young. Machine learning:\\nThe high interest credit card of technical debt.(2014), 2014.\\n58. Nick Seaver. Computing Taste: Algorithms and the Makers of Music Recom-\\nmendation. University of Chicago Press, 2022.\\n59. Reza Shabani. How to train your own large language models, Apr 2023.\\nURL https://blog.replit.com/llm-training.\\n60. Christopher J Shallue, Jaehoon Lee, Joseph Antognini, Jascha Sohl-\\nDickstein, Roy Frostig, and George E Dahl. Measuring the effects of data\\nparallelism on neural network training. arXiv preprint arXiv:1811.03600,\\n2018.\\n61. Or Sharir, Barak Peleg, and Yoav Shoham. The cost of training nlp models:\\nA concise overview. arXiv preprint arXiv:2004.08900, 2020.\\n62. Dan Shiebler and Abhishek Tayal. Making machine learning easy with\\nembeddings. SysML http://www.sysml.cc/doc/115.pdf, 2010.\\n63. Adi Simhi and Shaul Markovitch. Interpreting embedding spaces by\\nconceptualization. arXiv preprint arXiv:2209.00445, 2022.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 81, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='embeddings. SysML http://www.sysml.cc/doc/115.pdf, 2010.\\n63. Adi Simhi and Shaul Markovitch. Interpreting embedding spaces by\\nconceptualization. arXiv preprint arXiv:2209.00445, 2022.\\n64. Harald Steck, Linas Baltrunas, Ehtsham Elahi, Dawen Liang, Yves Rai-\\nmond, and Justin Basilico. Deep learning for recommender systems: A\\nnetflix case study. AI Magazine, 42(3):7–18, 2021.\\n65. Krysta M Svore and Christopher JC Burges. A machine learning approach\\nfor improved bm25 retrieval. In Proceedings of the 18th ACM conference on\\nInformation and knowledge management, pages 1811–1814, 2009.\\n66. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\\nAidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you\\nneed. Advances in neural information processing systems, 30, 2017.\\n82'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 82, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='67. Bin Wang, Angela Wang, Fenxiao Chen, Yuncheng Wang, and C-C Jay\\nKuo. Evaluating word embedding models: Methods and experimental\\nresults. APSIPA transactions on signal and information processing, 8:e19, 2019.\\n68. Yuxuan Wang, Yutai Hou, Wanxiang Che, and Ting Liu. From static to\\ndynamic word representations: a survey. International Journal of Machine\\nLearning and Cybernetics, 11:1611–1630, 2020.\\n69. Christopher Wewer, Florian Lemmerich, and Michael Cochez.\\nUp-\\ndating embeddings for dynamic knowledge graphs.\\narXiv preprint\\narXiv:2109.10896, 2021.\\n70. Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Se-\\nbastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon\\nMann. Bloomberggpt: A large language model for finance. arXiv preprint\\narXiv:2303.17564, 2023.\\n71. Peng Xu, Xiatian Zhu, and David A Clifton. Multimodal learning with\\ntransformers: A survey. IEEE Transactions on Pattern Analysis and Machine\\nIntelligence, 2023.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 82, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='arXiv:2303.17564, 2023.\\n71. Peng Xu, Xiatian Zhu, and David A Clifton. Multimodal learning with\\ntransformers: A survey. IEEE Transactions on Pattern Analysis and Machine\\nIntelligence, 2023.\\n72. Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L\\nHamilton, and Jure Leskovec. Graph convolutional neural networks for\\nweb-scale recommender systems. In Proceedings of the 24th ACM SIGKDD\\ninternational conference on knowledge discovery & data mining, pages 974–983,\\n2018.\\n73. Shuai Zhang, Lina Yao, Aixin Sun, and Yi Tay. Deep learning based\\nrecommender system: A survey and new perspectives. ACM computing\\nsurveys (CSUR), 52(1):1–38, 2019.\\n74. Tianyi Zhang, Felix Wu, Arzoo Katiyar, Kilian Q Weinberger, and\\nYoav Artzi.\\nRevisiting few-sample bert fine-tuning.\\narXiv preprint\\narXiv:2006.05987, 2020.\\n75. Yong Zheng. Multi-stakeholder recommendation: Applications and chal-\\nlenges. arXiv preprint arXiv:1707.08913, 2017.'),\n",
              " Document(metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-21T17:36:46+00:00', 'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf', 'total_pages': 83, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-21T17:36:46+00:00', 'trapped': '', 'modDate': 'D:20250921173646Z', 'creationDate': 'D:20250921173646Z', 'page': 82, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Revisiting few-sample bert fine-tuning.\\narXiv preprint\\narXiv:2006.05987, 2020.\\n75. Yong Zheng. Multi-stakeholder recommendation: Applications and chal-\\nlenges. arXiv preprint arXiv:1707.08913, 2017.\\n76. Martin Zinkevich. Rules of machine learning: Best practices for ml engi-\\nneering. URL: https://developers. google. com/machine-learning/guides/rules-of-\\nml, 2017.\\n83'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Object Detection\\nSihao Liang\\nJiajun Lu\\nKevin Perkins'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Overview\\nIntro\\nPart I: Two Stage Detection\\nPart II: Unified Detection\\nPart III: Others\\nSummary and comparison'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='What  is object detection\\nhttp://cs231n.stanford.edu/slides/winter1516_lecture8.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Terms\\nRecall\\nPrecision\\nmAP\\nIoU\\nhttps://en.wikipedia.org/wiki/Precision_and_recall'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 4, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Detection Competitions\\nPascal VOC\\nCOCO\\nImageNet ILSVRC\\nhttp://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html#introduction\\nCOCO: 200 classes \\nVOC: 20 classes'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 5, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Before Deep Learning\\nDeformable part models (DPM)\\n-\\nUses HOG features\\n-\\nVery fast\\nhttps://cs.brown.edu/~pff/papers/lsvm-pami.pdf\\nSliding windows.\\n-\\nScore every subwindow. \\nhttp://www.pyimagesearch.com/2014/11/10/histogram-oriented-gradients-object-detection/'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 6, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Selective Search\\nhttp://www.huppelen.nl/publications/selectiveSearchDraft.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 7, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Hard Negative Mining\\nImbalance between positive and negative examples.\\nUse negative examples with higher confidence score.\\nNon Maximum Suppression\\nIf output boxes overlap, only consider the most confident.'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 8, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Regression used to find bounding box parameters\\nApplied in one of two ways\\n-\\nBounding box refinement\\n-\\nComplete object detection\\nBounding Box Regression\\nI is the set of all matching bounding boxes (Highest IoU with ground truth)\\nExample Loss Function'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 9, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Two Stage Detection\\nPart I'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 10, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='RCNN : Region Proposal + CNN \\nUse selective search to come up with regional proposal\\nFirst object detection method using CNN\\n \\nRich feature hierarchies for accurate object detection and semantic segmentation\\nRoss Girshick Jeff Donahue Trevor Darrell Jitendra Malik\\nNov 2013\\nhttps://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 11, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='RCNN : \\nhttps://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 12, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Training RCNN\\nStep1: train your own CNN model for classification ( or use existing model), using \\nImageNet dataset.\\nConvolution \\nand Pooling\\nFully connected layer\\nSoftmax loss\\n4096 * 1000\\n1000 classes scores\\nImage source : http://www.shunvmall.com/bike-pic/47539009.html'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 13, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Training RCNN\\nStep2: focus on 20 classes + 1 background. Remove the last FC layer and replace it \\nwith a smaller layer and fine-tune the model using PASCAL VOC dataset\\nConvolution \\nand Pooling\\nFully connected layer\\nSoftmax loss\\n4096 * 21\\n21 classes scores'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 14, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Training RCNN\\nStep3: extract feature\\nImage\\nProposals\\nCrop & Warp\\nConvolution \\nand Pooling\\nStore all the features \\nafter pool 5 layer and \\nsave to disk\\nIt is about ~ 200G \\nfeatures'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 15, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Training RCNN\\nStep4: train SVM for each class\\nPositive \\nsamples for \\nMotorbike \\nNegative \\nsamples for \\nMotorbike \\nFeatures \\nfrom last \\nstep\\nCrop / \\nWarp \\nimage'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 16, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Training RCNN\\nStep4: train SVM for each class\\nNegative \\nsamples for \\nBicycle\\nPositive \\nsamples for \\nBicycle\\nFeatures \\nfrom last \\nstep\\nCrop / \\nWarp \\nimage'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 17, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Fast RCNN\\nShare convolution layers for proposals from the same image\\nFaster and More accurate than RCNN\\nROI Pooling\\nFast R-CNN\\nRoss Girshick\\nApr 2015\\nhttps://arxiv.org/pdf/1504.08083v2.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 18, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Fast RCNN\\nhttps://arxiv.org/pdf/1504.08083v2.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 19, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='RoI Pooling\\nimage\\nConv layer\\nDivided into \\nh * w region\\nMax pooling\\nDifferentiable'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 20, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='What is bbox-regressor?\\nBounding box regression\\nConvolution \\nand Pooling\\nFully connected layer\\nSoftmax loss\\nL2 loss\\nOR\\nL1 loss\\n4 value \\n(x,y,w,h)\\nOverfeat, VGG\\nDeepPose, R-CNN\\nTotal loss'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 21, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Convolution \\nand Pooling\\nFully connected layer\\nSoftmax loss\\nSmooth \\nL1 loss\\n4 value \\n(x,y,w,h)\\nTotal loss'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 22, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Result compare\\nTrained using VGG 16  on Pascal VOC 2007 dataset \\nNot including proposal time\\nSource: R. Girshick\\nFast R-CNN\\nR-CNN\\nTrain time (h)\\n9.5\\n84\\n-speedup\\n8.8x\\n1x\\nTest time/image\\n0.32s \\n47.00 s\\n-test speedup\\n146x\\n1x\\nmAP\\n66.9\\n66'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 23, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Result compare\\nSource: cs231 standford\\nFast R-CNN\\nR-CNN\\nTest time/image\\n0.32s \\n47.00 s\\n-test speedup\\n146x\\n1x\\nTest time/image with proposal\\n2s \\n50 s\\n-test speedup\\n25x\\n1x'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 24, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Don’t need to have external regional proposals\\nRPN - Regional Proposal Network \\nFaster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\\nShaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun\\nJun 2015\\nFaster RCNN\\nhttps://arxiv.org/pdf/1506.01497v3.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 25, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Faster RCNN\\nhttps://arxiv.org/pdf/1506.01497v3.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 26, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Faster RCNN\\nhttps://arxiv.org/pdf/1506.01497v3.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 27, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Result compare\\nTrained using Pascal VOC 2007 dataset \\nSource: cs231 standford\\nFaster R-CNN\\nFast R-CNN\\nR-CNN\\nTest time/image\\nWith proposal\\n0.2S\\n2s \\n50s\\n-test speedup\\n250x\\n25x\\n1x\\nmAP\\n66.9\\n66.9\\n66'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 28, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='R-FCN :Region-based Fully Convolutional \\nNetworks\\nhttps://arxiv.org/pdf/1605.06409v2.pdf\\nUse position sensitive score map\\nShare all conv and fc layers between all proposals for the same image\\nR-FCN: Object Detection via Region-based Fully Convolutional Networks\\nJifeng Dai, Yi Li, Kaiming He, Jian Sun\\nMay 2016'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 29, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='R-FCN\\nhttps://arxiv.org/pdf/1605.06409v2.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 30, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='R-FCN\\nhttps://arxiv.org/pdf/1605.06409v2.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 31, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='R-FCN\\nhttps://arxiv.org/pdf/1605.06409v2.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 32, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Methodologies Compare\\nTrained using ResNet 101\\nRCNN\\nFaster RCNN\\nRFCN\\nDepth of shared \\nconvolutional \\nsubnetwork\\n0\\n91\\n101\\nDepth of ROI-wise \\nsubnetwork\\n101\\n10\\n0'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 33, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Result compare\\nTrained using ResNet 101 on Pascal VOC 2007 dataset\\nFaster R-CNN\\nR-FCN\\nTest time/image\\nWith proposal\\n0.42S\\n0.2s \\nmAP\\n76.4\\n76.6'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 34, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Unified Detection\\nPart II'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 35, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Problems with 2 step detection.\\nComplex Pipeline\\nSlow (Cannot run in real time)\\nHard to optimize each component'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 36, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Yolo: You Only Look Once\\nConsider detection a regression problem\\nUse a single ConvNet\\nRuns once on entire image. Very Fast!\\nYou only look once: Unified, real-time object detection. \\nJoseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi\\nJune 2015'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 37, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='How it works\\nThe following predictions are made for each cell in an S x S grid.\\nC conditional class probabilities Pr(Classi | Obj)\\nB bounding boxes (4 parameters each)\\nB confidence scores Pr(Obj)*IoU\\nOutput is S x S  x (5B+C) tensor\\nhttps://arxiv.org/pdf/1506.02640v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 38, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Architecture\\nhttps://arxiv.org/pdf/1506.02640v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 39, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Performance (VOC 2007) \\nhttps://arxiv.org/pdf/1506.02640v5.pdf\\nYolo\\nFaster R-CNN (VGG-16)\\nmAP\\n63.4\\n73.2\\nFPS\\n45\\n7\\nTrained on Pascal VOC 2007 + 2012 dataset'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 40, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Limitations of Yolo\\nStruggles with small objects\\nStruggles with unusual aspect ratios\\nPoor localization'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 41, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='SSD Single Shot Detector\\nFaster than Yolo, as accurate as Faster R-CNN\\nPredicts categories and box offsets\\nUses small convolutional filters applied to feature maps\\nMakes predictions using feature maps of different scales\\nSSD: Single shot multibox detector\\nWei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander \\nC. Berg \\nDec 2015'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 42, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Comparison to Yolo\\nhttps://arxiv.org/pdf/1512.02325v5.pdf\\nSSD\\nYolo'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 43, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Default Boxes\\nMultiple aspect ratios per cell.\\nSimilar to Faster R-CNN Anchor Boxes.\\n-\\nApplied to many feature maps.\\nhttps://arxiv.org/pdf/1512.02325v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 44, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='SSD Detector\\nDetectors are convolutional filters.\\nEach detector outputs a single value.\\nPredict class probabilities.\\nPredict bounding box offsets.\\n(classes + 4) detectors are needed for a detection.\\n(classes + 4) x (#default boxes) x m x n outputs for a mxn feature map.'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 45, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Results (VOC 2007)\\nhttps://arxiv.org/pdf/1512.02325v5.pdf\\nSSD*\\nYolo*\\nFaster R-CNN*\\nmAP\\n74.3\\n66.4\\n73.2\\nFPS\\n46\\n21\\n7\\n*VGG16\\nTrained on Pascal VOC 2007 + 2012 dataset'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 46, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Others\\nPart III'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 47, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Feature Pyramid Networks\\nUses ConvNet as Feature Pyramid\\nIncludes low level feature maps to detect small objects\\nTop down pathway provides contextual information\\nFeature Pyramid Networks for Object Detection. \\nTsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie.\\nDec 2016'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 48, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Comparison to prior methods\\na.\\nAccurate but slow.\\nb.\\nMisses low level \\ninformation. (Yolo)\\nc.\\nMisses context in low \\nlevel predictions. \\n(SSD)\\nd.\\nAccurate and fast.\\nhttps://arxiv.org/pdf/1512.02325v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 49, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Top down pathway\\n-\\nHigh level (semantically strong) \\nfeature maps are upsampled. \\n-\\nLateral connections merge \\nfeature maps from bottom up \\npathway. \\nhttps://arxiv.org/pdf/1512.02325v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 50, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Feature Pyramid Networks for RPN\\n-\\nReplace single scale feature \\nmap with FPN.\\n-\\nSingle scale anchors at each \\nlevel.\\nhttps://arxiv.org/pdf/1512.02325v5.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 51, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Results\\n-\\nCOCO\\n-\\nState of the art single-model\\nhttps://arxiv.org/pdf/1512.02325v5.pdf\\nFaster R-CNN on FPN*\\nFaster R-CNN +++*\\nION**\\nmAP\\n36.2\\n34.9\\n31.2\\nmAP (small images)\\n18.2\\n15.6\\n12.8\\n* ResNet-101\\n** VGG-16'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 52, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='ION : Inside-Outside Network\\nUse multi-scale Conv features for inside region\\nUse four direction RNN features for outside region\\n \\nInside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks\\nSean Bell, C.Lawrence Zitnick, Kavita Bala, Ross Girshick\\nCornell University, Microsoft Research\\nCVPR 2016\\nhttps://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 53, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='ION: Inside-Outside Net\\n                                              https://www.robots.ox.ac.uk/~vgg/rg/slides/ion-coco.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 56, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Uses RNNs to capture context info from outside bounding box.'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 57, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Stack 2 RNNs together'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 58, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='ION: Inside-Outside Net\\nMain Changes:\\n-\\nInside: Skip connection with L2 normalization\\n-\\nOutside: Stacked 4-direction RNNs for context'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 59, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Results (VOC 2007)\\n                                              https://www.robots.ox.ac.uk/~vgg/rg/slides/ion-coco.pdf\\nTrained on Pascal VOC 2007 + 2012 dataset'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 60, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Summary and Comparison\\nPart IV'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 61, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Speed / Accuracy Trade-off\\nUnified tensorflow architecture\\nCompare speed, accuracy and memory usage\\n \\nSpeed/Accuracy trade-offs for modern convolutional object detectors\\nJonathan Huang, Kevin Murphy et al.\\nNov 2016\\nhttps://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 62, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Same Architectures\\n                                                                                       https://pan.baidu.com/s/1pKIKIIB\\nFeature \\nExtractor\\nFaster \\nRCNN\\nR-FCN\\nSSD\\nSpeed\\nAccuracy\\nMemory\\n...'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 63, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Recap: Faster RCNN\\n                                                                                       https://pan.baidu.com/s/1pKIKIIB'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 64, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Recap: R-FCN\\n                                                                                       https://pan.baidu.com/s/1pKIKIIB'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 65, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Recap: SSD\\n                                                                                       https://pan.baidu.com/s/1pKIKIIB'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 66, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Accuracy VS Speed'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 67, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='1. Different Feature Extractor'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 68, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='2. Detect Object Size'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 69, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='3. Image Resolution'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 70, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='4. Region Proposal Number'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 71, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='5. GPU Time'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 72, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='6. Memory'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 73, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Summary\\n●\\nSpeed First: SSD\\n●\\nBalance Speed and Accuracy:  R-FCN\\n●\\nAccuracy First: Faster RCNN (Reduce proposals, it can speed up a lot with \\nsome accuracy loss)'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 74, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Thanks!\\nQuestions?'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 76, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='References\\nGirshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra, Rich feature hierarchies for accurate object detection and semantic segmentation, CVPR 2014\\nHe, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian, Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition, ECCV 2014\\nGirshick, Ross, Fast R-CNN, ICCV 2015\\nRen, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian, Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks, CVPR 2015\\nJifeng Dai, Yi Li, Kaiming He, Jian Sun R-FCN: Object Detection via Region-based Fully Convolutional Networks, NIPS 2016\\nErhan, Dumitru and Szegedy, Christian and Toshev, Alexander and Anguelov, Dragomir, Scalable Object Detection using Deep Neural Networks, CVPR 2014\\nBell, Sean and Lawrence Zitnick, C and Bala, Kavita and Girshick, Ross, Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks, CVPR 2016'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 76, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Bell, Sean and Lawrence Zitnick, C and Bala, Kavita and Girshick, Ross, Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks, CVPR 2016\\nRedmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali, You Only Look Once: Unified, Real-Time Object Detection, CVPR 2016\\nLiu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C, SSD: Single Shot MultiBox Detector, ECCV \\n2016\\nTsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie, Feature Pyramid Networks for Object Detection, arXiv 2016\\nHuang, Jonathan and Rathod, Vivek and Sun, Chen and Zhu, Menglong and Korattikara, Anoop and Fathi, Alireza and Fischer, Ian and Wojna, Zbigniew and Song, Yang and \\nGuadarrama, Sergio and others,Speed/accuracy trade-offs for modern convolutional object detectors, arXiv 2016'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 77, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Bonus Material\\nPart V'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 78, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Yolo v2 Faster, Better Stronger'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 79, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Performance on  MS COCO \\n         Method                    Data                      IoU                      Area                  #Dets                 Area\\nAvg. Precision\\nAvg. Recall'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 80, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Fast RCNN vs Faster RCNN'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 81, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='SPP-Net\\nhttps://arxiv.org/pdf/1406.4729v4.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 82, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='SPP-Net\\nConvolution \\nand Pooling\\nFully connected layer\\nSoftmax loss\\nSoftmax loss\\nSPP pooling to a fix length \\nlayer (max pooling)\\nCrop & Warp'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 83, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='SPP-Net\\nhttps://arxiv.org/pdf/1406.4729v4.pdf'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 84, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Multi-Box'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 85, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Multi-Box\\nGoal: Achieve a class-agnostic scalable object detection by predicting a set of \\nbounding boxes.\\nTrain a neural network to directly predict: \\n-\\nThe upper-left and lower-right coordinates of each bounding box\\n-\\nThe confidence score for the box containing an object'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 86, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Train Objective\\nProduce fixed number of bounding boxes with confidence, such as K=100 or 200.'),\n",
              " Document(metadata={'producer': '', 'creator': 'Google', 'creationdate': '', 'source': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'file_path': '..\\\\data\\\\PDFs\\\\object_detection.pdf', 'total_pages': 88, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 87, 'source_file': 'object_detection.pdf', 'file_type': 'pdf'}, page_content='Number of Windows')]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d4fe4a38",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating embeddings for 371 texts.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 12/12 [00:32<00:00,  2.73s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated embeddings with shape: (371, 384)\n",
            "Adding 371 documents to the vector store.\n",
            "Successfully added 371 documents to the vector store.\n",
            "Total documents in collection after addition: 371\n"
          ]
        }
      ],
      "source": [
        "# converts the chunks to texts for embedding generation\n",
        "texts = [chunk.page_content for chunk in chunks]\n",
        "\n",
        "# Generate embeddings for the document chunks\n",
        "embeddings = embedding_store.generate_embeddings(texts)\n",
        "\n",
        "# Add the chunks and their embeddings to the vector store\n",
        "vector_store.add_documents(chunks, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c756fe4c",
      "metadata": {},
      "source": [
        "Retriever Pipeline From VectorStore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3ac457de",
      "metadata": {},
      "outputs": [],
      "source": [
        "class RAGRetriever:\n",
        "    \"\"\"Handles query-based retrieval from the vector store.\"\"\"\n",
        "\n",
        "    def __init__(self, vector_store: VectorStore, embedding_store: EmbeddingStore):\n",
        "        \"\"\"\n",
        "        Initialize the retriever\n",
        "\n",
        "        Args:\n",
        "            vector_store: vector store containing document embeddings\n",
        "            embedding_store: Manager for generating query embeddings\n",
        "        \"\"\"\n",
        "        self.vector_store = vector_store\n",
        "        self.embedding_store = embedding_store\n",
        "\n",
        "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Retrieve relevant documents for a query\n",
        "        \n",
        "        Args:\n",
        "            query: The search query\n",
        "            top_k: Number of top results to return\n",
        "            score_threshold: Minimum similarity score threshold\n",
        "            \n",
        "        Returns:\n",
        "            List of dictionaries containing retrieved documents and metadata\n",
        "        \"\"\"\n",
        "        print(f\"Retrieving documents for query: '{query}'\")\n",
        "        print(f\"Top K: {top_k}, Score threshold: {score_threshold}\")\n",
        "        \n",
        "        # Generate query embedding\n",
        "        query_embedding = self.embedding_store.generate_embeddings([query])[0]\n",
        "        \n",
        "        # Search in vector store\n",
        "        try:\n",
        "            results = self.vector_store.collection.query(\n",
        "                query_embeddings=[query_embedding.tolist()],\n",
        "                n_results=top_k\n",
        "            )\n",
        "            \n",
        "            # Process results\n",
        "            retrieved_docs = []\n",
        "            \n",
        "            if results['documents'] and results['documents'][0]:\n",
        "                documents = results['documents'][0]\n",
        "                metadatas = results['metadatas'][0]\n",
        "                distances = results['distances'][0]\n",
        "                ids = results['ids'][0]\n",
        "                \n",
        "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
        "                    # Convert distance to similarity score (ChromaDB uses cosine distance)\n",
        "                    similarity_score = 1 - distance\n",
        "                    \n",
        "                    if similarity_score >= score_threshold:\n",
        "                        retrieved_docs.append({\n",
        "                            'id': doc_id,\n",
        "                            'content': document,\n",
        "                            'metadata': metadata,\n",
        "                            'similarity_score': similarity_score,\n",
        "                            'distance': distance,\n",
        "                            'rank': i + 1\n",
        "                        })\n",
        "                \n",
        "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
        "            else:\n",
        "                print(\"No documents found\")\n",
        "            \n",
        "            return retrieved_docs\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error during retrieval: {e}\")\n",
        "            return []\n",
        "    \n",
        "\n",
        "rag_retriever = RAGRetriever(vector_store=vector_store, embedding_store=embedding_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6b19fcb0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.RAGRetriever at 0x1feb3d0e660>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "e2e390c5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving documents for query: 'What is embeddings ?'\n",
            "Top K: 5, Score threshold: 0.0\n",
            "Generating embeddings for 1 texts.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 1/1 [00:00<00:00, 27.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated embeddings with shape: (1, 384)\n",
            "Retrieved 5 documents (after filtering)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'id': 'doc_8fca8bb3_56',\n",
              "  'content': 'What do embeddings actually look like? Here is one single embedding,\\nalso called a vector, in three dimensions. We can think of this as a repre-\\nsentation of a single element in our dataset. For example, this hypothetical\\nembedding represents a single word \"fly\", in three dimensions. Generally, we\\nrepresent individual embeddings as row vectors.\\n\\x02\\n1\\n4\\n9\\n\\x03\\n(1)\\nAnd here is a tensor, also known as a matrix3, which is a multidimensional\\ncombination of vector representations of multiple elements. For example, this\\ncould be the representation of \"fly\", and \"bird.\"\\n\\x141\\n4\\n9\\n4\\n5\\n6\\n\\x15\\n(2)\\nThese embeddings are the output of the process of learning embeddings,\\nwhich we do by passing raw input data into a machine learning model. We\\ntransform that multidimensional input data by compressing it, through the\\nalgorithms we discuss in this paper, into a lower-dimensional space. The\\nresult is a set of vectors in an embedding space.\\nWord\\nSentence\\nImage\\nMultimodal data\\n[1, 4, 9]\\n[1, 4, 7]\\n[12, 0, 3]',\n",
              "  'metadata': {'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf',\n",
              "   'creationdate': '2025-09-21T17:36:46+00:00',\n",
              "   'keywords': '',\n",
              "   'source_file': 'embeddings.pdf',\n",
              "   'page': 5,\n",
              "   'title': '',\n",
              "   'file_type': 'pdf',\n",
              "   'creationDate': 'D:20250921173646Z',\n",
              "   'moddate': '2025-09-21T17:36:46+00:00',\n",
              "   'trapped': '',\n",
              "   'modDate': 'D:20250921173646Z',\n",
              "   'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf',\n",
              "   'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
              "   'content_length': 989,\n",
              "   'author': '',\n",
              "   'total_pages': 83,\n",
              "   'subject': '',\n",
              "   'creator': 'LaTeX with hyperref',\n",
              "   'doc_index': 56,\n",
              "   'format': 'PDF 1.5'},\n",
              "  'similarity_score': 0.4357838034629822,\n",
              "  'distance': 0.5642161965370178,\n",
              "  'rank': 1},\n",
              " {'id': 'doc_864fd414_53',\n",
              "  'content': 'Figure 2: Embeddings papers in arXiv by month. It’s interesting to note the decline in\\nfrequency of embeddings-specific papers, possibly in tandem with the rise of deep learning\\narchitectures like GPT source\\nBuilding and expanding on the concepts in Word2Vec, the Transformer\\n[66] architecture, with its self-attention mechanism, a much more specialized\\ncase of calculating context around a given word, has become the de-facto\\nway to learn representations of growing multimodal vocabularies, and its rise\\nin popularity both in academia and in industry has caused embeddings to\\nbecome a staple of deep learning workflows.\\nHowever, the concept of embeddings can be elusive because they’re neither\\ndata flow inputs or output results - they are intermediate elements that live\\nwithin machine learning services to refine models. So it’s helpful to define\\nthem explicitly from the beginning.\\nAs a general definition, embeddings are data that has been transformed',\n",
              "  'metadata': {'trapped': '',\n",
              "   'content_length': 956,\n",
              "   'modDate': 'D:20250921173646Z',\n",
              "   'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf',\n",
              "   'moddate': '2025-09-21T17:36:46+00:00',\n",
              "   'creationdate': '2025-09-21T17:36:46+00:00',\n",
              "   'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf',\n",
              "   'subject': '',\n",
              "   'source_file': 'embeddings.pdf',\n",
              "   'author': '',\n",
              "   'format': 'PDF 1.5',\n",
              "   'doc_index': 53,\n",
              "   'creator': 'LaTeX with hyperref',\n",
              "   'title': '',\n",
              "   'file_type': 'pdf',\n",
              "   'keywords': '',\n",
              "   'creationDate': 'D:20250921173646Z',\n",
              "   'total_pages': 83,\n",
              "   'page': 4,\n",
              "   'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5'},\n",
              "  'similarity_score': 0.31441056728363037,\n",
              "  'distance': 0.6855894327163696,\n",
              "  'rank': 2},\n",
              " {'id': 'doc_5584afea_62',\n",
              "  'content': 'to do so with mathematical rigor and compare words in a shared embedding\\nspace.\\nx\\ny\\nbird\\ndog\\nfly\\nFigure 5: Projecting words into a shared embedding space\\nFigure 6: Embeddings in the context of an application.\\nEngineering systems based on embeddings can be computationally ex-\\npensive to build and maintain [61]. The need to create, store, and manage\\nembeddings has also recently resulted in the explosion of an entire ecosystem\\nof related products. For example, the recent rise in the development of vector\\ndatabases to facilitate production-ready use of nearest neighbors semantic\\nqueries in machine learning systems5, and the rise of embeddings as a service6.\\nAs such, it’s important to understand their context both as end-consumers,\\nproduct management teams, and as developers who work with them. But in\\nmy deep-dive into the embeddings reference material, I found that there are\\ntwo types of resources: very deeply technical academic papers, for people who',\n",
              "  'metadata': {'content_length': 961,\n",
              "   'subject': '',\n",
              "   'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf',\n",
              "   'file_type': 'pdf',\n",
              "   'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf',\n",
              "   'page': 7,\n",
              "   'moddate': '2025-09-21T17:36:46+00:00',\n",
              "   'creator': 'LaTeX with hyperref',\n",
              "   'creationdate': '2025-09-21T17:36:46+00:00',\n",
              "   'doc_index': 62,\n",
              "   'keywords': '',\n",
              "   'format': 'PDF 1.5',\n",
              "   'author': '',\n",
              "   'creationDate': 'D:20250921173646Z',\n",
              "   'modDate': 'D:20250921173646Z',\n",
              "   'source_file': 'embeddings.pdf',\n",
              "   'trapped': '',\n",
              "   'title': '',\n",
              "   'total_pages': 83,\n",
              "   'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5'},\n",
              "  'similarity_score': 0.27660447359085083,\n",
              "  'distance': 0.7233955264091492,\n",
              "  'rank': 3},\n",
              " {'id': 'doc_7528111d_54',\n",
              "  'content': 'within machine learning services to refine models. So it’s helpful to define\\nthem explicitly from the beginning.\\nAs a general definition, embeddings are data that has been transformed\\ninto n-dimensional matrices for use in deep learning computations. The\\nprocess of embedding (as a verb):\\n• Transforms multimodal input into representations that are easier to\\nperform intensive computation on, in the form of vectors, tensors, or\\ngraphs [51]. For the purpose of machine learning, we can think of\\nvectors as a list (or array) of numbers.\\n• Compresses input information for use in a machine learning task — the\\ntype of methods available to us in machine learning to solve specific\\nproblems — such as summarizing a document or identifying tags or\\nlabels for social media posts or performing semantic search on a large\\ntext corpus. The process of compression changes variable feature\\ndimensions into fixed inputs, allowing them to be passed efficiently',\n",
              "  'metadata': {'creationDate': 'D:20250921173646Z',\n",
              "   'author': '',\n",
              "   'file_type': 'pdf',\n",
              "   'source_file': 'embeddings.pdf',\n",
              "   'keywords': '',\n",
              "   'total_pages': 83,\n",
              "   'trapped': '',\n",
              "   'format': 'PDF 1.5',\n",
              "   'title': '',\n",
              "   'creator': 'LaTeX with hyperref',\n",
              "   'subject': '',\n",
              "   'modDate': 'D:20250921173646Z',\n",
              "   'doc_index': 54,\n",
              "   'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
              "   'page': 4,\n",
              "   'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf',\n",
              "   'content_length': 947,\n",
              "   'creationdate': '2025-09-21T17:36:46+00:00',\n",
              "   'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf',\n",
              "   'moddate': '2025-09-21T17:36:46+00:00'},\n",
              "  'similarity_score': 0.27038925886154175,\n",
              "  'distance': 0.7296107411384583,\n",
              "  'rank': 4},\n",
              " {'id': 'doc_53bcf8f6_215',\n",
              "  'content': 'reinforcement learning from Human Feedback, a property which allows it\\nto make inferences from text that feels much closer to what a human would\\nwrite.\\nWe’ve now reached the forefront of what’s possible with embeddings\\nin this paper. With the rise of generative methods and methods based on\\nReinforcement Learning with Human Feedback like OpenAI’s ChatGPT, as\\nwell as the nascent open-source Llama, Alpaca, and other models, anything\\nwritten in this paper would already be impossibly out of date by the time it\\nwas published30.\\n5\\nEmbeddings in Production\\nWith the advent of Transformer models, and more importantly, BERT, gen-\\nerating representations of large, multimodal objects for use in all sorts of\\nmachine learning tasks suddenly became much easier, the representations\\nbecame more accurate, and if the company had GPUs available, computations\\ncould now be computed with speed-up in parallel. Now that we understand\\nwhat embeddings are, what should we do with them? After all, we’re not',\n",
              "  'metadata': {'page': 59,\n",
              "   'creationdate': '2025-09-21T17:36:46+00:00',\n",
              "   'total_pages': 83,\n",
              "   'trapped': '',\n",
              "   'creator': 'LaTeX with hyperref',\n",
              "   'doc_index': 215,\n",
              "   'title': '',\n",
              "   'moddate': '2025-09-21T17:36:46+00:00',\n",
              "   'file_type': 'pdf',\n",
              "   'keywords': '',\n",
              "   'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
              "   'source_file': 'embeddings.pdf',\n",
              "   'source': '..\\\\data\\\\PDFs\\\\embeddings.pdf',\n",
              "   'format': 'PDF 1.5',\n",
              "   'modDate': 'D:20250921173646Z',\n",
              "   'content_length': 992,\n",
              "   'subject': '',\n",
              "   'creationDate': 'D:20250921173646Z',\n",
              "   'file_path': '..\\\\data\\\\PDFs\\\\embeddings.pdf',\n",
              "   'author': ''},\n",
              "  'similarity_score': 0.2505031228065491,\n",
              "  'distance': 0.7494968771934509,\n",
              "  'rank': 5}]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_retriever.retrieve(\"What is embeddings ?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "dd89f5fc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving documents for query: 'Position-wise Feed-Forward Networks'\n",
            "Top K: 5, Score threshold: 0.0\n",
            "Generating embeddings for 1 texts.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 1/1 [00:00<00:00, 26.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated embeddings with shape: (1, 384)\n",
            "Retrieved 1 documents (after filtering)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'id': 'doc_3261b91a_16',\n",
              "  'content': 'position in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[31, 2, 8].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation ﬂow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3\\nPosition-wise Feed-Forward Networks',\n",
              "  'metadata': {'doc_index': 16,\n",
              "   'modDate': \"D:20180212212210-08'00'\",\n",
              "   'title': 'Attention is All you Need',\n",
              "   'keywords': '',\n",
              "   'source': '..\\\\data\\\\PDFs\\\\attention.pdf',\n",
              "   'file_path': '..\\\\data\\\\PDFs\\\\attention.pdf',\n",
              "   'creator': '',\n",
              "   'producer': 'PyPDF2',\n",
              "   'moddate': '2018-02-12T21:22:10-08:00',\n",
              "   'creationdate': '',\n",
              "   'file_type': 'pdf',\n",
              "   'page': 4,\n",
              "   'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin',\n",
              "   'trapped': '',\n",
              "   'creationDate': '',\n",
              "   'content_length': 964,\n",
              "   'total_pages': 11,\n",
              "   'source_file': 'attention.pdf',\n",
              "   'format': 'PDF 1.3',\n",
              "   'subject': 'Neural Information Processing Systems http://nips.cc/'},\n",
              "  'similarity_score': 0.1060757040977478,\n",
              "  'distance': 0.8939242959022522,\n",
              "  'rank': 1}]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_retriever.retrieve(\"Position-wise Feed-Forward Networks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6b9b5a7",
      "metadata": {},
      "source": [
        "Integration VectorDB Context Pipeline with LLM Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fbccb82",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple RAG pipeline with Groq LLM\n",
        "from langchain_groq import ChatGroq\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv\n",
        "\n",
        "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"llama-3.3-70b-versatile\",temperature=0.1,max_tokens=1024)\n",
        "\n",
        "def rag_simple(query,retriever,llm,top_k=3):\n",
        "    results = retriever.retrieve(query,top_k=top_k)\n",
        "    context = \"\\n\\n\".join([doc['content'] for doc in results]) if results else \"\"\n",
        "    if not context:\n",
        "        return \"No relevant context found to answer the question\"\n",
        "    \n",
        "    # generate answer using Groq LLM\n",
        "    prompt=f\"\"\"Use the following context to answer the question concisely\n",
        "        Context:\n",
        "        {context}\n",
        "\n",
        "        Question: {query}\n",
        "\n",
        "        Answer:\"\"\"\n",
        "    \n",
        "    response = llm.invoke([prompt.format(context=context,query=query)])\n",
        "    return response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "7f3fe0fb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving documents for query: 'Explain Position-wise Feed-Forward Networks'\n",
            "Top K: 3, Score threshold: 0.0\n",
            "Generating embeddings for 1 texts.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 1/1 [00:00<00:00, 28.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated embeddings with shape: (1, 384)\n",
            "Retrieved 3 documents (after filtering)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Position-wise Feed-Forward Networks are not explicitly explained in the given context, but it is mentioned in section 3.3. However, based on the Transformer paper, Position-wise Feed-Forward Networks typically refer to a fully connected feed-forward neural network applied to each position in the sequence separately and identically. This consists of two linear layers with a ReLU activation function in between.\n"
          ]
        }
      ],
      "source": [
        "answer = rag_simple(\"Explain Position-wise Feed-Forward Networks\",rag_retriever,llm,top_k=3)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3aea30a3",
      "metadata": {},
      "source": [
        "Enhanced RAG Pipeline Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "49a48dd5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving documents for query: 'Hard Negative Mining Technqiues'\n",
            "Top K: 3, Score threshold: 0.1\n",
            "Generating embeddings for 1 texts.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated embeddings with shape: (1, 384)\n",
            "Retrieved 1 documents (after filtering)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: Selecting negative examples with higher confidence scores to improve model training, focusing on hardest-to-classify negatives.\n",
            "Sources: [{'source': 'object_detection.pdf', 'page': 7, 'score': 0.18127715587615967, 'preview': 'Hard Negative Mining\\nImbalance between positive and negative examples.\\nUse negative examples with higher confidence score.\\nNon Maximum Suppression\\nIf output boxes overlap, only consider the most confident....'}]\n",
            "Confidence: 0.18127715587615967\n",
            "Context Preview: Hard Negative Mining\n",
            "Imbalance between positive and negative examples.\n",
            "Use negative examples with higher confidence score.\n",
            "Non Maximum Suppression\n",
            "If output boxes overlap, only consider the most confident.\n"
          ]
        }
      ],
      "source": [
        "# --- Enhanced RAG Pipeline Features ---\n",
        "def rag_advanced(query, retriever, llm, top_k=5, min_score=0.2, return_context=False):\n",
        "    \"\"\"\n",
        "    RAG pipeline with extra features:\n",
        "    - Returns answer, sources, confidence score, and optionally full context.\n",
        "    \"\"\"\n",
        "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
        "    if not results:\n",
        "        return {'answer': 'No relevant context found.', 'sources': [], 'confidence': 0.0, 'context': ''}\n",
        "    \n",
        "    # Prepare context and sources\n",
        "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
        "    sources = [{\n",
        "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
        "        'page': doc['metadata'].get('page', 'unknown'),\n",
        "        'score': doc['similarity_score'],\n",
        "        'preview': doc['content'][:300] + '...'\n",
        "    } for doc in results]\n",
        "    confidence = max([doc['similarity_score'] for doc in results])\n",
        "    \n",
        "    # Generate answer\n",
        "    prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
        "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
        "    \n",
        "    output = {\n",
        "        'answer': response.content,\n",
        "        'sources': sources,\n",
        "        'confidence': confidence\n",
        "    }\n",
        "    if return_context:\n",
        "        output['context'] = context\n",
        "    return output\n",
        "\n",
        "# Example usage:\n",
        "result = rag_advanced(\"Hard Negative Mining Technqiues\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
        "print(\"Answer:\", result['answer'])\n",
        "print(\"Sources:\", result['sources'])\n",
        "print(\"Confidence:\", result['confidence'])\n",
        "print(\"Context Preview:\", result['context'][:300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "4f36bf80",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving documents for query: 'How embeddings are created ?'\n",
            "Top K: 3, Score threshold: 0.1\n",
            "Generating embeddings for 1 texts.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 1/1 [00:00<00:00, 32.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated embeddings with shape: (1, 384)\n",
            "Retrieved 3 documents (after filtering)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: Embeddings are created by passing raw input data into a machine learning model, which transforms the multidimensional input data into a lower-dimensional space through algorithms, resulting in a set of vectors in an embedding space.\n",
            "Sources: [{'source': 'embeddings.pdf', 'page': 5, 'score': 0.42968595027923584, 'preview': 'What do embeddings actually look like? Here is one single embedding,\\nalso called a vector, in three dimensions. We can think of this as a repre-\\nsentation of a single element in our dataset. For example, this hypothetical\\nembedding represents a single word \"fly\", in three dimensions. Generally, we\\nr...'}, {'source': 'embeddings.pdf', 'page': 4, 'score': 0.26875442266464233, 'preview': 'Figure 2: Embeddings papers in arXiv by month. It’s interesting to note the decline in\\nfrequency of embeddings-specific papers, possibly in tandem with the rise of deep learning\\narchitectures like GPT source\\nBuilding and expanding on the concepts in Word2Vec, the Transformer\\n[66] architecture, with ...'}, {'source': 'embeddings.pdf', 'page': 1, 'score': 0.2413206696510315, 'preview': 'Acknowledgements\\nI’m grateful to everyone who has graciously offered technical feedback but\\nespecially to Nicola Barbieri, Peter Baumgartner, Luca Belli, James Kirk, and\\nRavi Mody. All remaining errors, typos, and bad jokes are mine. Thank you to\\nDan for your patience, encouragement, for parenting w...'}]\n",
            "Confidence: 0.42968595027923584\n",
            "Context Preview: What do embeddings actually look like? Here is one single embedding,\n",
            "also called a vector, in three dimensions. We can think of this as a repre-\n",
            "sentation of a single element in our dataset. For example, this hypothetical\n",
            "embedding represents a single word \"fly\", in three dimensions. Generally, we\n",
            "r\n"
          ]
        }
      ],
      "source": [
        "# --- Enhanced RAG Pipeline Features ---\n",
        "def rag_advanced(query, retriever, llm, top_k=5, min_score=0.2, return_context=False):\n",
        "    \"\"\"\n",
        "    RAG pipeline with extra features:\n",
        "    - Returns answer, sources, confidence score, and optionally full context.\n",
        "    \"\"\"\n",
        "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
        "    if not results:\n",
        "        return {'answer': 'No relevant context found.', 'sources': [], 'confidence': 0.0, 'context': ''}\n",
        "    \n",
        "    # Prepare context and sources\n",
        "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
        "    sources = [{\n",
        "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
        "        'page': doc['metadata'].get('page', 'unknown'),\n",
        "        'score': doc['similarity_score'],\n",
        "        'preview': doc['content'][:300] + '...'\n",
        "    } for doc in results]\n",
        "    confidence = max([doc['similarity_score'] for doc in results])\n",
        "    \n",
        "    # Generate answer\n",
        "    prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
        "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
        "    \n",
        "    output = {\n",
        "        'answer': response.content,\n",
        "        'sources': sources,\n",
        "        'confidence': confidence\n",
        "    }\n",
        "    if return_context:\n",
        "        output['context'] = context\n",
        "    return output\n",
        "\n",
        "# Example usage:\n",
        "result = rag_advanced(\"How embeddings are created ?\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
        "print(\"Answer:\", result['answer'])\n",
        "print(\"Sources:\", result['sources'])\n",
        "print(\"Confidence:\", result['confidence'])\n",
        "print(\"Context Preview:\", result['context'][:300])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "4cc41fe9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving documents for query: 'what is object detection ?'\n",
            "Top K: 3, Score threshold: 0.1\n",
            "Generating embeddings for 1 texts.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 1/1 [00:00<00:00, 27.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated embeddings with shape: (1, 384)\n",
            "Retrieved 3 documents (after filtering)\n",
            "Streaming answer:\n",
            "Use the following context to answer the question concisely.\n",
            "Context:\n",
            "What  is ob"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ject detection\n",
            "http://cs231n.stanford.edu/slides/winter1516_lecture8.pdf\n",
            "\n",
            "Object Detection\n",
            "Sihao Liang\n",
            "Jiajun Lu\n",
            "Kevin Perkins\n",
            "\n",
            "Overview\n",
            "Intro\n",
            "Part I: Two Stage"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Detection\n",
            "Part II: Unified Detection\n",
            "Part III: Others\n",
            "Summary and comparison\n",
            "\n",
            "Question: what is object detection ?\n",
            "\n",
            "Answer:\n",
            "\n",
            "Final Answer: Object detection is the process of locating and classifying objects within an image or video.\n",
            "\n",
            "Citations:\n",
            "[1] object_detection.pdf (page 2)\n",
            "[2] object_detection.pdf (page 0)\n",
            "[3] object_detection.pdf (page 1)\n",
            "Summary: Object detection is a process used to identify and locate objects within visual data, such as images or videos. This process involves both locating the objects and classifying them into specific categories, allowing for a deeper understanding of the visual content.\n",
            "History: {'question': 'what is object detection ?', 'answer': 'Object detection is the process of locating and classifying objects within an image or video.', 'sources': [{'source': 'object_detection.pdf', 'page': 2, 'score': 0.7389722466468811, 'preview': 'What  is object detection\\nhttp://cs231n.stanford.edu/slides/winter1516_lecture8.pdf...'}, {'source': 'object_detection.pdf', 'page': 0, 'score': 0.2110590934753418, 'preview': 'Object Detection\\nSihao Liang\\nJiajun Lu\\nKevin Perkins...'}, {'source': 'object_detection.pdf', 'page': 1, 'score': 0.13058531284332275, 'preview': 'Overview\\nIntro\\nPart I: Two Stage Detection\\nPart II: Unified Detection\\nPart III: Others\\nSummary and comparison...'}], 'summary': 'Object detection is a process used to identify and locate objects within visual data, such as images or videos. This process involves both locating the objects and classifying them into specific categories, allowing for a deeper understanding of the visual content.'}\n"
          ]
        }
      ],
      "source": [
        "# --- Advanced RAG Pipeline: Streaming, Citations, History, Summarization ---\n",
        "from typing import List, Dict, Any\n",
        "import time\n",
        "\n",
        "class AdvancedRAGPipeline:\n",
        "    def __init__(self, retriever, llm):\n",
        "        self.retriever = retriever\n",
        "        self.llm = llm\n",
        "        self.history = []  # Store query history\n",
        "\n",
        "    def query(self, question: str, top_k: int = 5, min_score: float = 0.2, stream: bool = False, summarize: bool = False) -> Dict[str, Any]:\n",
        "        # Retrieve relevant documents\n",
        "        results = self.retriever.retrieve(question, top_k=top_k, score_threshold=min_score)\n",
        "        if not results:\n",
        "            answer = \"No relevant context found.\"\n",
        "            sources = []\n",
        "            context = \"\"\n",
        "        else:\n",
        "            context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
        "            sources = [{\n",
        "                'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
        "                'page': doc['metadata'].get('page', 'unknown'),\n",
        "                'score': doc['similarity_score'],\n",
        "                'preview': doc['content'][:300] + '...'\n",
        "            } for doc in results]\n",
        "            # Streaming answer simulation\n",
        "            prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\"\"\n",
        "            if stream:\n",
        "                print(\"Streaming answer:\")\n",
        "                for i in range(0, len(prompt), 80):\n",
        "                    print(prompt[i:i+80], end='', flush=True)\n",
        "                    time.sleep(0.05)\n",
        "                print()\n",
        "            response = self.llm.invoke([prompt.format(context=context, question=question)])\n",
        "            answer = response.content\n",
        "\n",
        "        # Add citations to answer\n",
        "        citations = [f\"[{i+1}] {src['source']} (page {src['page']})\" for i, src in enumerate(sources)]\n",
        "        answer_with_citations = answer + \"\\n\\nCitations:\\n\" + \"\\n\".join(citations) if citations else answer\n",
        "\n",
        "        # Optionally summarize answer\n",
        "        summary = None\n",
        "        if summarize and answer:\n",
        "            summary_prompt = f\"Summarize the following answer in 2 sentences:\\n{answer}\"\n",
        "            summary_resp = self.llm.invoke([summary_prompt])\n",
        "            summary = summary_resp.content\n",
        "\n",
        "        # Store query history\n",
        "        self.history.append({\n",
        "            'question': question,\n",
        "            'answer': answer,\n",
        "            'sources': sources,\n",
        "            'summary': summary\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            'question': question,\n",
        "            'answer': answer_with_citations,\n",
        "            'sources': sources,\n",
        "            'summary': summary,\n",
        "            'history': self.history\n",
        "        }\n",
        "\n",
        "# Example usage:\n",
        "adv_rag = AdvancedRAGPipeline(rag_retriever, llm)\n",
        "result = adv_rag.query(\"what is object detection ?\", top_k=3, min_score=0.1, stream=True, summarize=True)\n",
        "print(\"\\nFinal Answer:\", result['answer'])\n",
        "print(\"Summary:\", result['summary'])\n",
        "print(\"History:\", result['history'][-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebe42548",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}