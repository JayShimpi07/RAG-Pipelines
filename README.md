# ğŸ§  AI-Powered Document Assistant using RAG

An end-to-end **Retrieval-Augmented Generation (RAG)** system that allows users to upload documents and ask natural language questions, powered by **semantic search + vector embeddings + LLM reasoning**.

This project replicates the architecture behind modern AI tools like **ChatPDF, Perplexity AI, and enterprise knowledge assistants**.

---
ğŸ¥ **Live Demo Video:**  
ğŸ‘‰ [Watch Project Demo](https://drive.google.com/file/d/1X2Z4zIo84fAWSYX0i3il8y4YbnWEDL7O/view?usp=sharing)

## ğŸš€ Key Features

* ğŸ“„ Upload multiple documents (PDF, TXT, CSV, Excel, DOCX, JSON)
* ğŸ§© Automatic document chunking
* ğŸ§  Embedding generation using Sentence Transformers (MiniLM)
* ğŸ—„ Fast vector similarity search with FAISS
* ğŸ¤– LLM-powered answer generation via Groq (LLaMA-3)
* ğŸ“š Source citations with chunk traceability
* ğŸ¬ Visual pipeline animations (Ingestion + Retrieval)
* ğŸŒ Clean AI-style web interface

---

## ğŸ—ï¸ System Architecture

```
User Query
   â†“
Embedding Model (MiniLM)
   â†“
FAISS Vector Search
   â†“
Top Relevant Chunks Retrieved
   â†“
LLM (Groq) Context-based Answer Generation
   â†“
Answer + Citations
```

---

## ğŸ§  Tech Stack

| Layer            | Technology                    |
| ---------------- | ----------------------------- |
| Backend          | Python, Flask                 |
| Embeddings       | SentenceTransformers (MiniLM) |
| Vector Database  | FAISS                         |
| LLM              | Groq (LLaMA-3)                |
| Document Loaders | LangChain Community Loaders   |
| UI               | HTML, CSS, JavaScript         |
| Deployment Ready | Render / HuggingFace Spaces   |

---

## ğŸ“‚ Project Structure

```
RAG-Pipelines/
â”‚
â”œâ”€â”€ app.py                  # Flask application
â”œâ”€â”€ requirements.txt        # Dependencies
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ uploads/            # User uploaded files
â”‚
â”œâ”€â”€ faiss_store/            # Vector index + metadata
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py      # Multi-format ingestion
â”‚   â”œâ”€â”€ embedding.py        # Chunking + embedding logic
â”‚   â”œâ”€â”€ vectorstore.py      # FAISS indexing & search
â”‚   â”œâ”€â”€ search.py           # RAG retrieval + LLM
â”‚   â””â”€â”€ pipeline.py         # Orchestration layer
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html          # Web UI
â”‚
â””â”€â”€ static/
    â””â”€â”€ style.css           # UI styling
```

---

## âš™ï¸ How It Works

### 1ï¸âƒ£ Document Ingestion

* Loads documents of various formats
* Splits them into semantic chunks

### 2ï¸âƒ£ Embedding Creation

* Converts chunks into vector representations

### 3ï¸âƒ£ Vector Storage

* Stores embeddings in FAISS for fast similarity search

### 4ï¸âƒ£ Query Processing

* User question converted into embedding
* Most relevant chunks retrieved

### 5ï¸âƒ£ Answer Generation

* Groq LLM summarizes answer using only retrieved context

### 6ï¸âƒ£ Explainable AI

System returns:

* Answer
* Source file name
* Chunk ID
* Similarity score

---

## ğŸ¬ Pipeline Visualizations

This system uniquely shows **what happens inside AI**:

### ğŸ“¤ Ingestion Pipeline

```
Document â†’ Chunking â†’ Embeddings â†’ Vector DB
```

### ğŸ” Retrieval Pipeline

```
Question â†’ Vector Search â†’ Context Retrieval â†’ LLM â†’ Answer
```

---

## ğŸ–¥ï¸ Run Locally

```bash
git clone <repo-url>
cd RAG-Pipelines
pip install -r requirements.txt

# Add API key
echo "GROQ_API_KEY=your_key_here" > .env

python app.py
```

Visit:

```
http://127.0.0.1:5000
```

---
## ğŸ“¸ Screenshots

### ğŸ–¥ï¸ Main Interface
Clean AI-style interface for document upload and question answering.

![Main UI](screenshots/UI.png)

---

### ğŸ“¤ Document Ingestion Pipeline
Behind-the-scenes visualization of how documents are:
- Split into chunks
- Converted to embeddings
- Stored in FAISS vector database

![Ingestion Pipeline](screenshots/Ingestion.png)

---

### ğŸ§  AI Answer Generation
LLM generates context-aware responses using only retrieved document chunks.

![AI Answer](screenshots/ans.png)

---

### ğŸ“š Source Attribution (Explainable AI)
System shows:
- File name  
- Chunk ID  
- Similarity score  
- Source text snippet  

![Sources Used](screenshots/Sources.png)

---

## ğŸ”® Future Improvements

* Chat-style conversation memory
* Streaming LLM responses
* Persistent cloud storage
* Authentication system
* Advanced ranking algorithms

---

## ğŸ‘¨â€ğŸ’» Author

**Jay Shimpi**

AI & Data Science Engineer

---

â­ If you like this project, give it a star!

---
